{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaQ8tKujmobU"
   },
   "source": [
    "# 2.8. Gradient Descent\n",
    "\n",
    "We have already seen the gradient descent and **update law** in [terminologies : part-2](https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/terminologies_part_2.html) (link to previous chapter). Just for the sake of completeness, let us quickly revisit the same.\n",
    "\n",
    "#### Update law\n",
    "\n",
    "Gradient Descent iteratively calculates the next value of a variable ($p_{n+1}$) using gradient of that variable ($\\frac{\\partial J}{\\partial p_n}$) at the current iteration, scales it (by a learning rate, $\\eta$) and subtracts obtained value from the current position (also called as taking a step). It subtracts the value because we want to minimise the function (to maximise it would be adding). This process can be written as:\n",
    "\n",
    "$$\n",
    "p_{n+1} = p_n - \\eta \\frac{\\partial J}{\\partial p_n}\n",
    "$$\n",
    "\n",
    "There’s an important parameter $\\eta$ which *scales* the gradient and thus controls the step size. In machine and deep learning, it is called **learning rate** and have a strong influence on performance.\n",
    "\n",
    "#### Mini-batch gradient descent\n",
    "\n",
    "This technique consists of dividing the training set to [batches](https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/terminologies_part_2.html#batch-size) (link to previous chapter):\n",
    "\n",
    "Suppose we are given the batches {$(X_1, y_1)$, $(X_2, y_2)$, ... ,$(X_{N_b}, y_{N_b})$} where $N_b$ is the `number of batches`.\n",
    "\n",
    "* for $t=1,2,...N_b$\n",
    "    * Carry out forward propagation on $X_t$\n",
    "    * Compute cost function normalized on the size of batch\n",
    "    * Carry out Backpropagation using $(X_t, y_t, \\hat{y_t})$\n",
    "    * Update weight $W$ and $b$\n",
    "\n",
    "> **Note:** In the case where there is only one data sample (selected randomly) in the batch, the algorithm is called **stochastic gradient descent**\n",
    "\n",
    "#### Gradient descent with momentum\n",
    "\n",
    "Gradient descent with momentum is a variant of gradient descent which includes the notion of `momentum`. \n",
    "\n",
    "It is a method which helps accelerate gradients vectors in the right directions, thus leading to faster converging.\n",
    "\n",
    "The algorithm is as follows:\n",
    "\n",
    "For any layer $l=(1,2,...L)$\n",
    "\n",
    "* Initialize $v_{dW_l}=0$ (size same as $dW_l$) and $v_{db_l}=0$ (size same as $db_l$)\n",
    "\n",
    "* On iteration $k$\n",
    "    * Compute $dW_l$ and $db_l$ on current mini batch\n",
    "    \n",
    "    $$v_{dW_l} = \\alpha \\hspace{0.1cm} v_{dW_l} + (1-\\alpha) \\hspace{0.1cm}dW_l$$\n",
    "    \n",
    "    $$v_{db_l} = \\alpha \\hspace{0.1cm} v_{db_l} + (1-\\alpha) \\hspace{0.1cm}db_l$$\n",
    "    \n",
    "    * Update the parameters\n",
    "    \n",
    "        $$W_l := W_l - \\eta \\hspace{0.1cm} v_{dW_l}$$\n",
    "        \n",
    "        $$b_l := b_l - \\eta \\hspace{0.1cm} v_{db_l}$$\n",
    "\n",
    "The hyper-parameter $\\alpha$ is called the **momentum**. In deep learning, most practitioners set the value of $\\alpha=0.9$ without attempting to further tune this hyperparameter (i.e., this is the default value for momentum in many popular deep learning packages). \n",
    "\n",
    "#### Root Mean Square prop - RMSProp \n",
    "\n",
    "It is very similar to gradient descent with momentum, the only difference is that it includes the second-order momentum instead of the first-order one, plus a slight change on the parameter's update:\n",
    "\n",
    "The algorithm is as follows:\n",
    "\n",
    "For any layer $l=(1,2,...L)$\n",
    "\n",
    "* Initialize $S_{dW_l}=0$ (size same as $dW_l$) and $S_{db_l}=0$ (size same as $db_l$)\n",
    "\n",
    "* On iteration $k$\n",
    "    * Compute $dW_l$ and $db_l$ on current mini batch\n",
    "    \n",
    "    $$S_{dW_l} = \\alpha \\hspace{0.1cm} S_{dW_l} + (1-\\alpha) \\hspace{0.1cm}dW_l^2$$\n",
    "    \n",
    "    $$S_{db_l} = \\alpha \\hspace{0.1cm} S_{db_l} + (1-\\alpha) \\hspace{0.1cm}db_l^2$$\n",
    "    \n",
    "    * Update the parameters\n",
    "    \n",
    "$$W_l := W_l - \\frac{\\eta}{\\sqrt{S_{dW_l}} + \\epsilon} \\hspace{0.1cm} dW_l$$\n",
    "\n",
    "$$b_l := b_l - \\frac{\\eta}{\\sqrt{S_{db_l}} + \\epsilon} \\hspace{0.1cm} db_l$$\n",
    "\n",
    "\n",
    "#### Adam\n",
    "\n",
    "Adam (adaptive learning rate optimization) can be seen as a combination of RMSprop and gradient descent with momentum. The main idea is to avoid oscillations during optimization by accelerating the descent in the right direction.\n",
    "\n",
    "The algorithm is as follows:\n",
    "\n",
    "For any layer $l=(1,2,...L)$\n",
    "\n",
    "* Initialize $v_{dW_l}=0$, $v_{db_l}=0$, $S_{dW_l}=0$ and $S_{db_l}=0$\n",
    "\n",
    "* On iteration $k$\n",
    "    * Compute $dW_l$ and $db_l$ on current mini batch\n",
    "    \n",
    "    * Momentum\n",
    "        \n",
    "        $v_{dW_l} = \\alpha_1 \\hspace{0.1cm} v_{dW_l} + (1-\\alpha_1) \\hspace{0.1cm}dW_l$\n",
    "        \n",
    "        $v_{db_l} = \\alpha_1 \\hspace{0.1cm} v_{db_l} + (1-\\alpha_1) \\hspace{0.1cm}db_l$\n",
    "    \n",
    "    * RMSProp\n",
    "        \n",
    "        $S_{dW_l} = \\alpha_2 \\hspace{0.1cm} S_{dW_l} + (1-\\alpha_2) \\hspace{0.1cm}dW_l^2$\n",
    "        \n",
    "        $S_{db_l} = \\alpha_2 \\hspace{0.1cm} S_{db_l} + (1-\\alpha_2) \\hspace{0.1cm}db_l^2$\n",
    "    \n",
    "    * Correction\n",
    "\n",
    "    $$\n",
    "    v_{dW_l} = \\frac{v_{dW_l}}{1-\\alpha_1^k}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    v_{db_l} = \\frac{v_{db_l}}{1-\\alpha_1^k}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    S_{dW_l} = \\frac{S_{dW_l}}{1-\\alpha_2^k}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    S_{db_l} = \\frac{S_{db_l}}{1-\\alpha_2^k}\n",
    "    $$\n",
    "\n",
    "    * Update the parameters\n",
    "    \n",
    "$$W_l := W_l - \\frac{\\eta}{\\sqrt{S_{dW_l}} + \\epsilon} \\hspace{0.1cm} v_{dW_l}$$\n",
    "\n",
    "$$b_l := b_l - \\frac{\\eta}{\\sqrt{S_{db_l}} + \\epsilon} \\hspace{0.1cm} v_{db_l}$$\n",
    "\n",
    "> **Note:** Good default settings for the tested Machine Learning and Deep learning models are $\\eta = 0.001$, $\\alpha_1 = 0.9$, $\\alpha_2 = 0.999$ and $\\epsilon = 10^{-8}$.\n",
    "\n",
    "#### Learning Rate Decay\n",
    "\n",
    "The main objective of the learning rate decay is to slowly reduce the learning rate over time/iterations. There exist many learning rate decay laws, here are some of the most common:\n",
    "\n",
    "**Time-Based Decay**\n",
    "\n",
    "The mathematical form of time-based decay for learning rate $\\eta_t$ is:\n",
    "\n",
    "$$\n",
    "\\eta_{t+1} = \\frac{\\eta_0}{1+Kt}\n",
    "$$\n",
    "\n",
    "where $t$ is the `iteration number` and $K$ is the hyper-parameter called `Decay rate`. Let $E$ be the total number of epochs, then usually we take $K=\\frac{\\eta_0}{E}$ where $\\eta_0$ is the initial learning rate.\n",
    "\n",
    "**Step Decay**\n",
    "\n",
    "Step decay drops the learning rate by a factor of every few epochs. For example, let’s suppose our initial learning rate is $\\eta_0 = 0.01$.\n",
    "\n",
    "After 10 epochs we drop the learning rate to $\\eta = 0.005$.\n",
    "\n",
    "After another 10 epochs (i.e., the 20th total epoch), $\\eta$ is dropped by a factor of 0.5 again, such that $\\eta = 0.0025$, etc.\n",
    "\n",
    "The mathematical form of step decay is:\n",
    "\n",
    "$$\n",
    "\\eta_{e+1} = \\eta_0 \\hspace{0.12cm} F^{\\left \\lfloor \\frac{1+e}{D} \\right \\rfloor}\n",
    "$$\n",
    "\n",
    "Where $\\eta_0$ is the initial learning rate, $F$ is the factor value controlling the rate in which the learning date drops, $D$ is the “Drop every” epochs value, $e$ is the current epoch and $\\lfloor x \\rfloor$ is the $\\text{floor(x)}$\n",
    "\n",
    "The larger our factor $F$ is, the slower the learning rate will decay and conversely, the smaller the factor $F$, the faster the learning rate will decay.\n",
    "\n",
    "**Exponential Decay**\n",
    "\n",
    "Another common schedule is exponential decay. It has the mathematical form: \n",
    "\n",
    "$$\n",
    "\\eta_{t+1} = \\eta_0 * e^{−kt}\n",
    "$$\n",
    "\n",
    "where $k$ is `hyper-parameter` and $t$ is the `iteration number`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3pYVUXPhKqX"
   },
   "source": [
    "#### Problems related to Gradients\n",
    "\n",
    "**Vanishing gradient**\n",
    "\n",
    "As the number of layers in the neural networks increase, the gradient value (used during back propagation) decreases and eventually it tends to zero. This is called `vanishing gradient problem`. The result is that the weights of the model now stops updating and model cannot learn further.\n",
    "\n",
    "This mostly happens in the case *when number of layers are too high* or the activation function used in the model is `sigmoid` or `tanh`. \n",
    "\n",
    "The remedy for this problem is to use `ReLU activation` function or initialize the parameters in such a way that the weight value doesn’t become zero.\n",
    "\n",
    "**Exploding gradient**\n",
    "\n",
    "In contrast to the vanishing gradient problem, in exploding gradient problem, the gradients instead of vanishing, accumulates and results in a very large value (tending to infinity) during training. \n",
    "\n",
    "This makes the model unstable and leads to a poor prediction reporting nan values (**n**ot **a** **n**umber) most of the time.\n",
    "\n",
    "There are methods to fix exploding gradients, which include `gradient clipping` (where we clip the gradient to certain range), `data normalization`, `weight regularization`, etc."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}