{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8iN7ZT8m5aB"
   },
   "source": [
    "# 3.4. 4 step process to build a CNN model using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5XfhobFnBme"
   },
   "source": [
    "From our previous chapters (including the one where we have coded [CNN model from scratch](https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/cnn_from_scratch.html)), we now have the idea of how CNN works. Today, we will build our very first CNN model using PyTorch (it just takes quite a few lines of code) in just 4 simple steps.\n",
    "\n",
    "#### How to build CNN model using PyTorch\n",
    "\n",
    "#### Step-1\n",
    "\n",
    "Importing all dependencies\n",
    "\n",
    "We first import `torch`, which imports **PyTorch**. Then we import `nn`, which allows us to define a neural network module. \n",
    "\n",
    "Next we import the `DataLoader` with the help of which we can feed data into the convolutional neural network (CNN) during training.\n",
    "\n",
    "Finally we import `transforms`, which allows us to perform [data pre-processing](https://pythonandml.github.io/dlbook/content/preliminaries/data_preprocessing.html) (link to previous chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "orhsxg1DlTui"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# show the progress bar while priting\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8LFYLwfqyjw"
   },
   "source": [
    "#### Step-2\n",
    "\n",
    "Defining the CNN class as a `nn.Module`\n",
    "\n",
    "The CNN class replicates the `nn.Module` class. It has two definitions: __init__, or the constructor, and **forward**, which implements the forward pass.\n",
    "\n",
    "We create a convolution model using `nn.Conv2d` and a pooling layer using `nn.Maxpool2d`.\n",
    "\n",
    "> **Note:** Here `nn.Linear` is similar to the **Dense** class we developed in our scratch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HzreJsrtpRpm"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        The first parameter 3 here represents that the image is colored and in RGB format. \n",
    "        If it was a grayscale image we would have gone for 1.\n",
    "        32 is the size of the initial output channel \n",
    "        '''\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(64*16*16, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ej3GG9ltDcr"
   },
   "source": [
    "#### Step-3\n",
    "\n",
    "Preparing the **CIFAR-10** dataset and compiling the model *(loss function, and optimizer)*.\n",
    "\n",
    "```{note}\n",
    "CIFAR-10 is a dataset that has a collection of images of 10 different classes. This dataset is widely used for research purposes to test different machine learning models and especially for computer vision problems.\n",
    "```\n",
    "\n",
    "The next code we add involves preparing the **CIFAR-10** dataset.\n",
    "\n",
    "We will define the `batch_size` of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "d2275a18a58747479ff7ddcae34e9bb0",
      "b5dacac5567d44dead0f590bfb62b7ab",
      "fa529be24dbf4dcaa93e945817488af9",
      "ae51b213a71446c7970769947208c72e",
      "11347d1a41c24b20b8db173d8a1a02a6",
      "7bc1081df6694d8b8684a5ade5e4268f",
      "3cae5f6519de473699ffba57280cfe79",
      "40151b5ac92c445ba762a72484bf2d07",
      "a4e9ef23563c4397a2e00478a5a45606",
      "a8db0d008df24347a8d36f4630c203fd",
      "44545b7d168c43fdacb6fbc95696850d"
     ]
    },
    "id": "hmKRfuucsidh",
    "outputId": "55c96183-ef2c-4b20-b8c7-ff2c9592f95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2275a18a58747479ff7ddcae34e9bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/cifar-10-python.tar.gz to /content\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(os.getcwd(), download=True, transform=transforms.ToTensor(), train=True)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=1)\n",
    "\n",
    "test_dataset = CIFAR10(os.getcwd(), download=True, transform=transforms.ToTensor(), train=False)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNvgTesJuOn8"
   },
   "source": [
    "Now, we will initialize the CNN model and compile the same by specifying the loss function (categorical crossentropy loss) and the Adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "B2VngNPUuOJN"
   },
   "outputs": [],
   "source": [
    "# Initialize the CNN\n",
    "cnn = CNN()\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss) and optimizer (ADAM)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEYW2IrgvDQW"
   },
   "source": [
    "#### Step-4\n",
    "\n",
    "Defining the training loop\n",
    "\n",
    "The core part of our runtime code is the training loop. In this loop, we perform the epochs, or training iterations. For every iteration, we iterate over the training dataset, perform the entire forward and backward passes, and perform model optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6eO6fWKvAW0",
    "outputId": "5c5c38b7-aa36-4020-a24d-59dc3f3b2212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:27<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.716611654281616\n",
      "Epoch: 2 / "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:01<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3922613124847412\n",
      "Training process has finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "\n",
    "# 2 epochs at maximum\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(0, epochs): \n",
    "  \n",
    "    # Print epoch\n",
    "    print(\"Epoch:\", epoch+1, '/', end=' ')\n",
    "    \n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    \n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(tqdm(trainloader)):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        outputs = cnn(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print results\n",
    "        current_loss += loss.item()\n",
    "    \n",
    "    print(\"Training Loss:\", current_loss/len(trainloader))\n",
    "    \n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFmLYXgzzZ6S"
   },
   "source": [
    "#### Testing time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMsELiMRzZgR",
    "outputId": "5c5a9a7e-fa8d-4346-f69a-ba8fa77d80ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 1.3139171063899995\n",
      "Test Accuracy: 0.5323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()\n",
    "correct = 0                                               \n",
    "total = 0                                                 \n",
    "running_loss = 0.0                                 \n",
    "with torch.no_grad():                                     \n",
    "    for i, data in enumerate(tqdm(testloader)):                     \n",
    "        inputs, targets = data                                                           \n",
    "        outputs = cnn(inputs)                           \n",
    "        loss = loss_function(outputs, targets)  \n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)         \n",
    "        \n",
    "        total += targets.size(0)                           \n",
    "        correct += (predicted == targets).sum().item()     \n",
    "        running_loss = running_loss + loss.item()         \n",
    "accuracy = correct / total\n",
    "running_loss = running_loss/len(testloader)\n",
    "print(\"\\nTest Loss:\", running_loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEaIPqAsljts"
   },
   "source": [
    "With more complex model, we can increase the accuracy of CIFAR-10 as much as we want. The main thing is that we have learnt how to build our very first CNN model using PyTorch in just 4 simple steps."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}