
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3.2.1. Convolutional layers &#8212; Oddly Satisfying Deep Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3.2.2 Forward Propagation Convolution layer (Vectorized)" href="forward_propagation_convolution.html" />
    <link rel="prev" title="3.2. Basic Architecture of CNN" href="cnn_architecture.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Oddly Satisfying Deep Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  1. Preliminaries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../preliminaries/data_preprocessing.html">
   1.1. Data Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../preliminaries/performance_metrics.html">
   1.2. Performance Metrics for ML and DL models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  2. Multilayer Perceptrons
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/activation.html">
   2.1. Activation Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/perceptron.html">
   2.2. Perceptron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/terminologies_part_1.html">
   2.3. Terminologies Part-1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/cost_functions.html">
   2.4. Cost functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/forward_propagation.html">
   2.5. Forward propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/backpropagation.html">
   2.6. Back Propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/terminologies_part_2.html">
   2.7. Terminologies Part-2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/gradient_descent.html">
   2.8. Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/regularization.html">
   2.9. Regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/dropout.html">
   2.10. Dropout regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/batch_normalization.html">
   2.11. Batch Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/numerical_example_forward_backward_propagation.html">
   2.12. Numerical example Forward and Back pass
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/shortcut_to_calculate_forward_back_propagation.html">
   2.13. Shortcut to calculate forward pass and backpropagation across layers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/neural_networks_mlp_scratch_best.html">
   2.14. MLP model from scratch in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/mlp_pytorch.html">
   2.15. 4 step process to build MLP model using PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/mlp_keras.html">
   2.16. MLP model using Tensorflow - Keras
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  3. Convolutional Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_over_mlp.html">
   3.1. Convolutional Neural Networks over MLP
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="cnn_architecture.html">
   3.2. Basic Architecture of CNN
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.2.1. Convolutional layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="forward_propagation_convolution.html">
     3.2.2 Forward Propagation Convolution layer (Vectorized)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backpropagation_convolution.html">
     3.2.3 Backward Propagation Convolution layer (Vectorized)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pooling_layers.html">
     3.2.4. Pooling layers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_from_scratch.html">
   3.3. Convolutional Neural Networks from scratch in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_pytorch.html">
   3.4. 4 step process to build a CNN model using PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_keras.html">
   3.5. CNN model using Tensorflow - Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_state_of_the_art.html">
   3.6. State of the art CNN models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  4. Word Embeddings
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../word_embeddings/traditional_word_embeddings.html">
   4.1. Traditional Word Embeddings
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../word_embeddings/static_word_embeddings.html">
   4.2. Static Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/word2vec.html">
     4.2.1. Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/glove.html">
     4.2.2 GloVe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/fasttext.html">
     4.2.3. FastText
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../word_embeddings/contextual_word_embeddings.html">
   4.3. Contextual Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/elmo.html">
     4.3.1. Embeddings from Language Models (ELMo)
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/pythonandml/dlbook/master?urlpath=tree/content/convolutional_neural_networks/convolutional_layers.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/pythonandml/dlbook/blob/master/content/convolutional_neural_networks/convolutional_layers.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/pythonandml/dlbook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/pythonandml/dlbook/issues/new?title=Issue%20on%20page%20%2Fcontent/convolutional_neural_networks/convolutional_layers.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/content/convolutional_neural_networks/convolutional_layers.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-short-summary-on-convolution-and-cross-correlation">
   A short summary on Convolution and Cross Correlation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-correlation-operation-otimes">
     Cross Correlation operation
     <span class="math notranslate nohighlight">
      \(\otimes\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolution-operation-star">
     Convolution operation (
     <span class="math notranslate nohighlight">
      \(\star\)
     </span>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#padding">
     Padding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stride">
     Stride
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dilation">
     Dilation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-2d-and-3d-cnn">
     1D, 2D and 3D CNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notations">
     Notations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#forward-propagation">
     Forward Propagation
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>3.2.1. Convolutional layers</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-short-summary-on-convolution-and-cross-correlation">
   A short summary on Convolution and Cross Correlation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-correlation-operation-otimes">
     Cross Correlation operation
     <span class="math notranslate nohighlight">
      \(\otimes\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolution-operation-star">
     Convolution operation (
     <span class="math notranslate nohighlight">
      \(\star\)
     </span>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#padding">
     Padding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stride">
     Stride
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dilation">
     Dilation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-2d-and-3d-cnn">
     1D, 2D and 3D CNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notations">
     Notations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#forward-propagation">
     Forward Propagation
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="convolutional-layers">
<h1>3.2.1. Convolutional layers<a class="headerlink" href="#convolutional-layers" title="Permalink to this headline">#</a></h1>
<blockquote>
<div><p>This layer creates a <strong>convolution kernel</strong> that is <code class="docutils literal notranslate"><span class="pre">convolved</span></code> with the layer input to produce a tensor of outputs. It is well known for extracting features from images. Let me explain.</p>
</div></blockquote>
<section id="a-short-summary-on-convolution-and-cross-correlation">
<h2>A short summary on Convolution and Cross Correlation<a class="headerlink" href="#a-short-summary-on-convolution-and-cross-correlation" title="Permalink to this headline">#</a></h2>
<p>Before we even try to understand what the above statement means, let us quickly go through the two important and simple mathematical operations namely <strong>Convolution</strong> and <strong>Cross Correlation</strong> which represents the heart of the convolutional layer.</p>
<section id="cross-correlation-operation-otimes">
<h3>Cross Correlation operation <span class="math notranslate nohighlight">\(\otimes\)</span><a class="headerlink" href="#cross-correlation-operation-otimes" title="Permalink to this headline">#</a></h3>
<p>Suppose we input an arbitrary big matrix <span class="math notranslate nohighlight">\(X\)</span> and we have a smaller matrix <span class="math notranslate nohighlight">\(K\)</span> which we call as <strong>kernel</strong> (or <strong>filter</strong>) as shown in the figure below:</p>
<p><img alt="" src="../../_images/x_correlate_k.png" /></p>
<p>Then, the <code class="docutils literal notranslate"><span class="pre">cross</span> <span class="pre">correlation</span> <span class="pre">operation</span></code> between the input <span class="math notranslate nohighlight">\(X\)</span> and kernel <span class="math notranslate nohighlight">\(K\)</span> (<span class="math notranslate nohighlight">\(X \otimes K\)</span>) will produce an output matrix <span class="math notranslate nohighlight">\(Z\)</span> whose values are obtained by sliding the kernel <span class="math notranslate nohighlight">\(K\)</span> on top of the input <span class="math notranslate nohighlight">\(X\)</span> as shown in the below gif.</p>
<p><img alt="" src="../../_images/cross_correlation.gif" /></p>
<p>Let us compute the first output element and the rest of them can be computed in the similar fashion. In the below figure, the shaded portions are the first output element as well as the input and kernel elements used for the output computation:</p>
<p><img alt="" src="../../_images/cross_corr_1.png" /></p>
<div class="math notranslate nohighlight">
\[
1*1 + 5*(-1) + 2*2 + 6*0 = 0
\]</div>
</section>
<section id="convolution-operation-star">
<h3>Convolution operation (<span class="math notranslate nohighlight">\(\star\)</span>)<a class="headerlink" href="#convolution-operation-star" title="Permalink to this headline">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">convolution</span> <span class="pre">operation</span></code> between input <span class="math notranslate nohighlight">\(X\)</span> and kernel <span class="math notranslate nohighlight">\(K\)</span> (<span class="math notranslate nohighlight">\(X \star K\)</span>) is the same operation as cross correlation operation except that we have to rotate the kernel by 180 degrees to get a new kernel.</p>
<p><img alt="" src="../../_images/rotate_kernel.png" /></p>
<p>This rotation will result into the following output matrix <span class="math notranslate nohighlight">\(Z\)</span>.</p>
<p><img alt="" src="../../_images/convolve.png" /></p>
<p>In other words, we have the following <strong>relation between convolution and cross-correlation</strong> operation.</p>
<div class="math notranslate nohighlight">
\[
X \star K = X \otimes \text{rot180}(K)
\]</div>
<p>Now, before we continue further, let us first define some basic operations such as the <strong>padding</strong>, <strong>stride</strong> and <strong>dilation</strong>.</p>
</section>
<section id="padding">
<h3>Padding<a class="headerlink" href="#padding" title="Permalink to this headline">#</a></h3>
<p>As we have seen in the <code class="docutils literal notranslate"><span class="pre">cross</span> <span class="pre">correlation</span> <span class="pre">operation</span></code> above, the pixels on the corner of the image (2D matrix) are less used than the pixels in the middle of the image which means that the information from the edges are not much used.</p>
<p>To solve this problem, we often add padding around the image in order to take the pixels on the edges into account. Generally we <strong>padde</strong> the matrix with <code class="docutils literal notranslate"><span class="pre">zeros</span></code> and use the variable <span class="math notranslate nohighlight">\(p\)</span> to denote the number of layers of zeros added to the border of the image (see figure below where we have padded the matrix <span class="math notranslate nohighlight">\(X\)</span>, used earlier, with <span class="math notranslate nohighlight">\(p=1\)</span>).</p>
<p><img alt="" src="../../_images/padding.png" /></p>
<blockquote>
<div><p><strong>Note:</strong> After padding our <span class="math notranslate nohighlight">\((N, M)\)</span> image becomes <span class="math notranslate nohighlight">\((N + 2p, M + 2p)\)</span> image.</p>
</div></blockquote>
<p>Mostly there are only 2 types of paddings used widely: One is <strong>valid</strong> and other is <strong>same</strong>.</p>
<p><code class="docutils literal notranslate"><span class="pre">valid</span></code> means no padding. With this type of padding, there’s no “made-up” padding inputs. The layer only uses valid input data.</p>
<p><code class="docutils literal notranslate"><span class="pre">valid</span></code> drops the right-most columns (or bottom-most rows) from the data.</p>
<p><code class="docutils literal notranslate"><span class="pre">same</span></code> padding tries to pad evenly left and right columns, but if the amount of columns to be added is odd, it will add the extra column to the right (the same logic applies vertically: there may be an extra row of zeros at the bottom).</p>
<p>With <code class="docutils literal notranslate"><span class="pre">same</span></code> padding, if you use a <strong>stride of 1</strong>, the layer’s outputs will have the same spatial dimensions as its inputs.</p>
</section>
<section id="stride">
<h3>Stride<a class="headerlink" href="#stride" title="Permalink to this headline">#</a></h3>
<p>Stride simply denotes the number of pixels shifts while sliding the kernel <span class="math notranslate nohighlight">\(K\)</span> over the input matrix <span class="math notranslate nohighlight">\(X\)</span>. By default it is one. We denote with <span class="math notranslate nohighlight">\(s\)</span> the stride parameter.</p>
<p>The following gif illustrates <span class="math notranslate nohighlight">\(s=1\)</span></p>
<p><img alt="" src="../../_images/stride_1.gif" /></p>
<p>and the following gif illustrates <span class="math notranslate nohighlight">\(s=2\)</span></p>
<p><img alt="" src="../../_images/stride_2.gif" /></p>
</section>
<section id="dilation">
<h3>Dilation<a class="headerlink" href="#dilation" title="Permalink to this headline">#</a></h3>
<p>It is a method in which given a matrix <span class="math notranslate nohighlight">\(X\)</span> (for dilation), it is expanded (both horizontally and vertically) by inserting holes between its consecutive elements. In simple terms, we put rows and columns of zeros after every element of <span class="math notranslate nohighlight">\(X\)</span> (except the last one) based on the dilation rate <span class="math notranslate nohighlight">\((D_h, D_w)\)</span> along the height and the width of input respectively. Figure below will help you understand better (check dilated matrix for different values of the dilation rate).</p>
<p><img alt="" src="../../_images/dilation_1.png" /></p>
<p><img alt="" src="../../_images/dilation_2.png" /></p>
</section>
<section id="d-2d-and-3d-cnn">
<h3>1D, 2D and 3D CNN<a class="headerlink" href="#d-2d-and-3d-cnn" title="Permalink to this headline">#</a></h3>
<p><strong>1D CNN</strong></p>
<p>In 1D CNN, kernel moves in 1 direction as shown in the <a class="reference external" href="https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610">figure</a> below. Input and output data of 1D CNN is 2 dimensional. It is mostly used on <code class="docutils literal notranslate"><span class="pre">Time-Series</span> <span class="pre">data</span></code>.</p>
<p><img alt="" src="../../_images/cnn_1d.webp" /></p>
<p><strong>2D CNN</strong></p>
<p>In 2D CNN, the kernel slides along 2 dimensions on the data as shown in the following <a class="reference external" href="https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610">image</a>. Input and output data of 2D CNN is 3 dimensional. Mostly used on Image data.</p>
<p><img alt="" src="../../_images/cnn_2d.webp" /></p>
<p><strong>3D CNN</strong></p>
<p>In 3D CNN, kernel moves in 3 directions (see <a class="reference external" href="https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610">figure</a> below). Input and output data of 3D CNN is 4 dimensional. Mostly used on 3D Image data (MRI, CT Scans, Video).</p>
<p><img alt="" src="../../_images/cnn_3d.webp" /></p>
</section>
<section id="notations">
<h3>Notations<a class="headerlink" href="#notations" title="Permalink to this headline">#</a></h3>
<p><img alt="" src="../../_images/convolution_layer.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">Input</span></code></p>
<ul class="simple">
<li><p>Denoted by: <span class="math notranslate nohighlight">\(X\)</span> (mostly it will be an Image)</p></li>
<li><p>Shape: <span class="math notranslate nohighlight">\((m, N_c, N_h, N_w)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(m\)</span> is the batch size</p></li>
<li><p><span class="math notranslate nohighlight">\(N_c\)</span> is the number of channels (depth of the input)</p></li>
<li><p><span class="math notranslate nohighlight">\(N_h\)</span> is the height of the input</p></li>
<li><p><span class="math notranslate nohighlight">\(N_w\)</span> is the width of input</p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Parameters</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<ul class="simple">
<li><p>Denoted by: <span class="math notranslate nohighlight">\(K\)</span> (also called Kernel or Filter)</p></li>
<li><p>Shape: <span class="math notranslate nohighlight">\((F, K_c, K_h, K_w)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the total number of filters</p></li>
<li><p><span class="math notranslate nohighlight">\(K_c\)</span> is the depth of thw Kernel (it is equal to the depth of input or <span class="math notranslate nohighlight">\(N_c\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(K_h\)</span> is the height of the Kernel</p></li>
<li><p><span class="math notranslate nohighlight">\(K_w\)</span> is the width of the Kernel</p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Bias</span></code></p>
<ul class="simple">
<li><p>Denoted by: <span class="math notranslate nohighlight">\(b\)</span> (also called Bias)</p></li>
<li><p>Shape: <span class="math notranslate nohighlight">\((F, O_h, O_w)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the total number of filters used in Kernel</p></li>
<li><p><span class="math notranslate nohighlight">\(O_h\)</span> is the height of the Output <span class="math notranslate nohighlight">\(Z\)</span> (defined below)</p></li>
<li><p><span class="math notranslate nohighlight">\(O_w\)</span> is the width of the Output <span class="math notranslate nohighlight">\(Z\)</span></p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Padding</span></code></p>
<ul class="simple">
<li><p>Denoted by: <span class="math notranslate nohighlight">\(p\)</span> (also called padding type)</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(p\)</span> can be <code class="docutils literal notranslate"><span class="pre">str</span></code> (“valid” or “same”)</p></li>
<li><p><span class="math notranslate nohighlight">\(p\)</span> can be <code class="docutils literal notranslate"><span class="pre">int</span></code> as described above (for symmetrical padding)</p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Stride</span></code></p>
<ul class="simple">
<li><p>Denoted by: <span class="math notranslate nohighlight">\(s\)</span> a tuple of the form <span class="math notranslate nohighlight">\((s_h, s_w)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(s_h\)</span> is the number of strides along height</p></li>
<li><p><span class="math notranslate nohighlight">\(s_w\)</span> is the number of strides along width</p></li>
</ul>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Output</span></code></p>
<ul class="simple">
<li><p>Denoted by: <span class="math notranslate nohighlight">\(Z\)</span></p></li>
<li><p>Shape: <span class="math notranslate nohighlight">\((m, F, O_h, O_w)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(m\)</span> is the batch size</p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the total number of filters used in Kernel</p></li>
<li><p><span class="math notranslate nohighlight">\(O_h\)</span> is the height of the Output <span class="math notranslate nohighlight">\(Z\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(O_w\)</span> is the width of the Output <span class="math notranslate nohighlight">\(Z\)</span></p></li>
</ul>
</li>
</ul>
<p><strong>Note</strong></p>
<ol class="simple">
<li><p>Instead of using <span class="math notranslate nohighlight">\(p\)</span> (for padding), we can also use <span class="math notranslate nohighlight">\(p_h\)</span> and <span class="math notranslate nohighlight">\(p_w\)</span> which denotes the number of rows and columns of zeros added to the input <span class="math notranslate nohighlight">\(X\)</span> respectively. We can further break <span class="math notranslate nohighlight">\(p_h\)</span> and <span class="math notranslate nohighlight">\(p_w\)</span> into <span class="math notranslate nohighlight">\((p_t, p_b)\)</span> and <span class="math notranslate nohighlight">\((p_l, p_r)\)</span> respectively where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p_t\)</span>: number of rows of zeros padded on top of the input <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p_b\)</span>: number of rows of zeros padded on bottom of the input <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p_l\)</span>: number of columns of zeros padded on left of the input <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p_r\)</span>: number of columns of zeros padded on right of the input <span class="math notranslate nohighlight">\(X\)</span>
<br><br></p></li>
</ul>
</li>
<li><p>Shape of Output is calculated using the following formula: <br><br></p></li>
</ol>
<div class="math notranslate nohighlight">
\[
O_h = \left \lfloor \frac{N_h - K_h + p_h}{s_h} \right \rfloor + 1
\]</div>
<div class="math notranslate nohighlight">
\[
O_w = \left \lfloor \frac{N_w - K_w + p_w}{s_w} \right \rfloor + 1
\]</div>
<ol class="simple">
<li><p>Same padding</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
p_h = (s_h-1) \cdot N_h + K_h - s_h
\]</div>
<div class="math notranslate nohighlight">
\[
p_w = (s_w-1) \cdot N_w + K_w - s_w
\]</div>
<ol class="simple">
<li><p>Valid padding</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
p_h = 0
\]</div>
<div class="math notranslate nohighlight">
\[
p_w = 0
\]</div>
</section>
<section id="forward-propagation">
<h3>Forward Propagation<a class="headerlink" href="#forward-propagation" title="Permalink to this headline">#</a></h3>
<p>Once we have defined the stride and the padding we can define the convolution product between a Input <span class="math notranslate nohighlight">\(X\)</span> (Containing channels, height and width) and a filter <span class="math notranslate nohighlight">\(K\)</span>.</p>
<div class="math notranslate nohighlight">
\[
Z_{x,y} = \sum_{i=1}^{N_h} \sum_{j=1}^{N_w} \sum_{k=1}^{N_c} K_{k,i,j} X_{k, x+i-1, y+j-1}
\]</div>
<p>This we do across every batch and all the filters.</p>
<p>Don’t worry, in our <a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/forward_propagation_convolution.html">forward propagation code</a>, which we will develop from scratch in a step by step manner, we will not be using any for loops and the code will be fully vectorized (written in just few lines using only numpy)!</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/convolutional_neural_networks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="cnn_architecture.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">3.2. Basic Architecture of CNN</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="forward_propagation_convolution.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3.2.2 Forward Propagation Convolution layer (Vectorized)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ujjwal Khandelwal<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>