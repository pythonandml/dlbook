
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3.3. Convolutional Neural Networks from scratch in Python &#8212; Oddly Satisfying Deep Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3.4. 4 step process to build a CNN model using PyTorch" href="cnn_pytorch.html" />
    <link rel="prev" title="3.2.4. Pooling layers" href="pooling_layers.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Oddly Satisfying Deep Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  1. Preliminaries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../preliminaries/data_preprocessing.html">
   1.1. Data Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../preliminaries/performance_metrics.html">
   1.2. Performance Metrics for ML and DL models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  2. Multilayer Perceptrons
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/activation.html">
   2.1. Activation Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/perceptron.html">
   2.2. Perceptron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/terminologies_part_1.html">
   2.3. Terminologies Part-1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/cost_functions.html">
   2.4. Cost functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/forward_propagation.html">
   2.5. Forward propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/backpropagation.html">
   2.6. Back Propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/terminologies_part_2.html">
   2.7. Terminologies Part-2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/gradient_descent.html">
   2.8. Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/regularization.html">
   2.9. Regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/dropout.html">
   2.10. Dropout regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/batch_normalization.html">
   2.11. Batch Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/numerical_example_forward_backward_propagation.html">
   2.12. Numerical example Forward and Back pass
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/shortcut_to_calculate_forward_back_propagation.html">
   2.13. Shortcut to calculate forward pass and backpropagation across layers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/neural_networks_mlp_scratch_best.html">
   2.14. MLP model from scratch in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/mlp_pytorch.html">
   2.15. 4 step process to build MLP model using PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/mlp_keras.html">
   2.16. MLP model using Tensorflow - Keras
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  3. Convolutional Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_over_mlp.html">
   3.1. Convolutional Neural Networks over MLP
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="cnn_architecture.html">
   3.2. Basic Architecture of CNN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="convolutional_layers.html">
     3.2.1. Convolutional layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="forward_propagation_convolution.html">
     3.2.2 Forward Propagation Convolution layer (Vectorized)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="backpropagation_convolution.html">
     3.2.3 Backward Propagation Convolution layer (Vectorized)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pooling_layers.html">
     3.2.4. Pooling layers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3.3. Convolutional Neural Networks from scratch in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_pytorch.html">
   3.4. 4 step process to build a CNN model using PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_keras.html">
   3.5. CNN model using Tensorflow - Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn_state_of_the_art.html">
   3.6. State of the art CNN models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  4. Word Embeddings
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../word_embeddings/traditional_word_embeddings.html">
   4.1. Traditional Word Embeddings
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../word_embeddings/static_word_embeddings.html">
   4.2. Static Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/word2vec.html">
     4.2.1. Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/glove.html">
     4.2.2 GloVe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/fasttext.html">
     4.2.3. FastText
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../word_embeddings/contextual_word_embeddings.html">
   4.3. Contextual Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/elmo.html">
     4.3.1. Embeddings from Language Models (ELMo)
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/pythonandml/dlbook/master?urlpath=tree/content/convolutional_neural_networks/cnn_from_scratch.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/pythonandml/dlbook/blob/master/content/convolutional_neural_networks/cnn_from_scratch.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/pythonandml/dlbook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/pythonandml/dlbook/issues/new?title=Issue%20on%20page%20%2Fcontent/convolutional_neural_networks/cnn_from_scratch.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/content/convolutional_neural_networks/cnn_from_scratch.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-essential-libraries">
   Import essential libraries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activation-class">
   Activation class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cost-function">
   Cost function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizers">
   Optimizers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-rate-decay">
   Learning Rate decay
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utility-function">
   Utility function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weights-initializer-class">
   Weights initializer class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dense-class">
   Dense class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dropout-class">
   Dropout class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batch-normalization-class">
   Batch Normalization class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#padding2d-class">
   Padding2D class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolution2d-class">
   Convolution2D class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maxpool2d-class">
   Maxpool2D class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#flatten-class">
   Flatten class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cnn">
   CNN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validating-model-using-mnist-dataset">
   Validating model using MNIST Dataset
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>3.3. Convolutional Neural Networks from scratch in Python</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-essential-libraries">
   Import essential libraries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activation-class">
   Activation class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cost-function">
   Cost function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizers">
   Optimizers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-rate-decay">
   Learning Rate decay
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utility-function">
   Utility function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weights-initializer-class">
   Weights initializer class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dense-class">
   Dense class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dropout-class">
   Dropout class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batch-normalization-class">
   Batch Normalization class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#padding2d-class">
   Padding2D class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolution2d-class">
   Convolution2D class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maxpool2d-class">
   Maxpool2D class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#flatten-class">
   Flatten class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cnn">
   CNN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validating-model-using-mnist-dataset">
   Validating model using MNIST Dataset
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="convolutional-neural-networks-from-scratch-in-python">
<h1>3.3. Convolutional Neural Networks from scratch in Python<a class="headerlink" href="#convolutional-neural-networks-from-scratch-in-python" title="Permalink to this headline">#</a></h1>
<p>We will be building Convolutional Neural Networks (CNN) model from scratch using Numpy in Python. Please check out the following list of <code class="docutils literal notranslate"><span class="pre">ingredients</span></code> (if you have not already done so), so that you can cook (code) the CNN model from scratch because this is going to be the most general CNN model that you can find anywhere on the net (without using any for loops, except for the epochs part :))!</p>
<blockquote>
<div><p><strong>Note</strong>: I have already explained (in detail) most of the code sections in my previous chapters (like forward and backward propagation in Convolution layers, forward and backward propagation in Pooling layers, and MLP model for Fully connected layers). I will just put the list for you to go and check them out (so that I can skip the tedious work of explaining them again and concentrate more on the fun part).</p>
</div></blockquote>
<p><strong>Ingredients</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/neural_networks_mlp_scratch_best.html">MLP model from scratch in Python</a></p></li>
<li><p><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/cnn_architecture.html">CNN architecture</a></p>
<ul>
<li><p><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/convolutional_layers.html">Convolution Layer</a></p>
<ul>
<li><p><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/forward_propagation_convolution.html">Forward Propagation Convolution layer (Vectorized)</a></p></li>
<li><p><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/backpropagation_convolution.html">Backward Propagation Convolution layer (Vectorized)</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/pooling_layers.html">Pooling Layer</a></p></li>
</ul>
</li>
</ul>
<p>Now that we have all the ingredients available, we are ready to code the most general <code class="docutils literal notranslate"><span class="pre">Convolutional</span> <span class="pre">Neural</span> <span class="pre">Networks</span> <span class="pre">(CNN)</span> <span class="pre">model</span></code> from scratch using Numpy in Python.</p>
<section id="import-essential-libraries">
<h2>Import essential libraries<a class="headerlink" href="#import-essential-libraries" title="Permalink to this headline">#</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># numpy for linear algebra</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># matplotlib for plotting the loss functions and/or accuracy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># confusion matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># accuracy score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># show progress bar</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="activation-class">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/activation.html">Activation class</a><a class="headerlink" href="#activation-class" title="Permalink to this headline">#</a></h2>
<p>This class will contain class methods to calculate activation functions and also it will calculate the forward propagation and backpropagation as per the decsription in the chapter <a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/shortcut_to_calculate_forward_back_propagation.html">Shortcut to calculate forward pass and backpropagation across layers</a> (link to previous chapter).</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Activation</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activation_type</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        activation_type: type of activation</span>
<span class="sd">        available options are &#39;sigmoid&#39;, &#39;linear&#39;, &#39;tanh&#39;, &#39;softmax&#39;, &#39;prelu&#39; and &#39;relu&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">activation_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">=</span> <span class="s1">&#39;linear&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">=</span> <span class="n">activation_type</span>

    <span class="k">def</span> <span class="nf">linear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">d_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">d_sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
     
    <span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">d_tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>

    <span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">d_ReLU</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">PReLU</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        alpha: slope parameter (𝛼)</span>

<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (or rows)</span>
<span class="sd">        and &#39;d&#39; is the number of features (or columns)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> 

    <span class="k">def</span> <span class="nf">d_PReLU</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        alpha: slope parameter (𝛼)</span>

<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (or rows)</span>
<span class="sd">        and &#39;d&#39; is the number of features (or columns)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> 

    <span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">numerator</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">softmax</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
        <span class="k">return</span> <span class="n">softmax</span>

    <span class="k">def</span> <span class="nf">d_softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">tensor1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,ik-&gt;ijk&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
        <span class="n">tensor2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,jk-&gt;ijk&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tensor2</span> <span class="o">-</span> <span class="n">tensor1</span>

    <span class="k">def</span> <span class="nf">get_activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;relu&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;prelu&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;softmax&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Valid Activations are only &#39;sigmoid&#39;, &#39;linear&#39;, &#39;tanh&#39; &#39;softmax&#39;, &#39;prelu&#39; and &#39;relu&#39;&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_d_activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        x: input matrix of shape (m, d) </span>
<span class="sd">        where &#39;m&#39; is the number of samples (in case of batch gradient descent of size m)</span>
<span class="sd">        and &#39;d&#39; is the number of features</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;relu&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_ReLU</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;prelu&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_PReLU</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span> <span class="o">==</span> <span class="s1">&#39;softmax&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Valid Activations are only &#39;sigmoid&#39;, &#39;linear&#39;, &#39;tanh&#39;, &#39;softmax&#39;, &#39;prelu&#39; and &#39;relu&#39;&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_activation</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>
    
    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dz</span><span class="p">):</span>
        <span class="n">f_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_d_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_type</span><span class="o">==</span><span class="s1">&#39;softmax&#39;</span><span class="p">:</span>
            <span class="c1"># because derivative of softmax is a tensor</span>
            <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,ik-&gt;ij&#39;</span><span class="p">,</span> <span class="n">f_prime</span><span class="p">,</span> <span class="n">dz</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dx</span> <span class="o">=</span> <span class="n">dz</span> <span class="o">*</span> <span class="n">f_prime</span>
        <span class="k">return</span> <span class="n">dx</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cost-function">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/cost_functions.html">Cost function</a><a class="headerlink" href="#cost-function" title="Permalink to this headline">#</a></h2>
<p>Follow the lecture to develop the cost function class</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Cost</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cost_type</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        cost_type: type of cost function</span>
<span class="sd">        available options are &#39;mse&#39;, and &#39;cross-entropy&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span> <span class="o">=</span> <span class="n">cost_type</span>

    <span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        a: Predicted output array of shape (m, d)</span>
<span class="sd">        y: Actual output array of shape (m, d)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="o">-</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">d_mse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        represents dJ/da</span>

<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        a: Predicted output array of shape (m, d)</span>
<span class="sd">        y: Actual output array of shape (m, d)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">-</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        a: Predicted output array of shape (m, d)</span>
<span class="sd">        y: Actual output array of shape (m, d)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">d_cross_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        represents dJ/da</span>

<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        a: Predicted output array of shape (m, d)</span>
<span class="sd">        y: Actual output array of shape (m, d)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">y</span><span class="o">/</span><span class="n">a</span>

    <span class="k">def</span> <span class="nf">get_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        a: Predicted output array of shape (m, d)</span>
<span class="sd">        y: Actual output array of shape (m, d)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span> <span class="o">==</span> <span class="s1">&#39;mse&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span> <span class="o">==</span> <span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Valid cost functions are only &#39;mse&#39;, and &#39;cross-entropy&#39;&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_d_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        </span>
<span class="sd">        a: Predicted output array of shape (m, d)</span>
<span class="sd">        y: Actual output array of shape (m, d)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span> <span class="o">==</span> <span class="s1">&#39;mse&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_mse</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span> <span class="o">==</span> <span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_cross_entropy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Valid cost functions are only &#39;mse&#39;, and &#39;cross-entropy&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="optimizers">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/gradient_descent.html">Optimizers</a><a class="headerlink" href="#optimizers" title="Permalink to this headline">#</a></h2>
<p>This class contains different optimizers (such as RMSProp, Adam, etc) used for updating the parameters.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Optimizer</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape_W</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape_b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">momentum1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">momentum2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>

<span class="sd">        momentum1: float hyperparameter &gt;= 0 that accelerates gradient descent in the relevant </span>
<span class="sd">                   direction and dampens oscillations. Defaults to 0, i.e., vanilla gradient descent.</span>
<span class="sd">                   Also used in RMSProp</span>
<span class="sd">        momentum2: used in Adam only</span>
<span class="sd">        optimizer_type: type of optimizer</span>
<span class="sd">                        available options are &#39;gd&#39;, &#39;sgd&#39; (This also includes momentum), &#39;adam&#39;, and &#39;rmsprop&#39;</span>
<span class="sd">        shape_W: Shape of the weight matrix W/ Kernel K</span>
<span class="sd">        shape_b: Shape of the bias matrix b</span>
<span class="sd">        epsilon: parameter used in RMSProp and Adam to avoid division by zero error</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="k">if</span> <span class="n">optimizer_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">=</span> <span class="s1">&#39;adam&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">=</span> <span class="n">optimizer_type</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span> <span class="o">=</span> <span class="n">momentum1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span> <span class="o">=</span> <span class="n">momentum2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vdW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape_W</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vdb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape_b</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">SdW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape_W</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape_b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">GD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        dW: gradient of Weight W for iteration k</span>
<span class="sd">        db: gradient of bias b for iteration k</span>
<span class="sd">        k: iteration number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span>
 
    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        dW: gradient of Weight W for iteration k</span>
<span class="sd">        db: gradient of bias b for iteration k</span>
<span class="sd">        k: iteration number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vdW</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">vdW</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="p">)</span><span class="o">*</span><span class="n">dW</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vdb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">vdb</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="p">)</span><span class="o">*</span><span class="n">db</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vdW</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vdb</span>

    <span class="k">def</span> <span class="nf">RMSProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        dW: gradient of Weight W for iteration k</span>
<span class="sd">        db: gradient of bias b for iteration k</span>
<span class="sd">        k: iteration number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">SdW</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">SdW</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">dW</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">db</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">den_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">SdW</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="n">den_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span>

        <span class="k">return</span> <span class="n">dW</span><span class="o">/</span><span class="n">den_W</span><span class="p">,</span> <span class="n">db</span><span class="o">/</span><span class="n">den_b</span>
 
    <span class="k">def</span> <span class="nf">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        dW: gradient of Weight W for iteration k</span>
<span class="sd">        db: gradient of bias b for iteration k</span>
<span class="sd">        k: iteration number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vdW</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">vdW</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="p">)</span><span class="o">*</span><span class="n">dW</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vdb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">vdb</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="p">)</span><span class="o">*</span><span class="n">db</span>

        <span class="c1"># rmsprop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">SdW</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">SdW</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">dW</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">db</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># correction</span>
        <span class="k">if</span> <span class="n">k</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">vdW_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vdW</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="o">**</span><span class="n">k</span><span class="p">))</span>
            <span class="n">vdb_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vdb</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1</span><span class="o">**</span><span class="n">k</span><span class="p">))</span>
            <span class="n">SdW_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SdW</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="o">**</span><span class="n">k</span><span class="p">))</span>
            <span class="n">Sdb_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2</span><span class="o">**</span><span class="n">k</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vdW_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vdW</span> 
            <span class="n">vdb_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vdb</span>
            <span class="n">SdW_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SdW</span>
            <span class="n">Sdb_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Sdb</span>

        <span class="n">den_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SdW_h</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="n">den_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Sdb_h</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span>

        <span class="k">return</span> <span class="n">vdW_h</span><span class="o">/</span><span class="n">den_W</span><span class="p">,</span> <span class="n">vdb_h</span><span class="o">/</span><span class="n">den_b</span>

    <span class="k">def</span> <span class="nf">get_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">==</span> <span class="s1">&#39;gd&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">GD</span><span class="p">(</span><span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">==</span> <span class="s1">&#39;sgd&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">==</span> <span class="s1">&#39;rmsprop&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">RMSProp</span><span class="p">(</span><span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">==</span> <span class="s1">&#39;adam&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">dW</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Valid optimizer options are only &#39;gd&#39;, &#39;sgd&#39;, &#39;rmsprop&#39;, and &#39;adam&#39;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="learning-rate-decay">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/gradient_descent.html#learning-rate-decay">Learning Rate decay</a><a class="headerlink" href="#learning-rate-decay" title="Permalink to this headline">#</a></h2>
<p>This class contains different methods to implement the learning rate decay scheduler.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LearningRateDecay</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">constant</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lr_0</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        t: iteration</span>
<span class="sd">        lr_0: initial learning rate</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">lr_0</span>

    <span class="k">def</span> <span class="nf">time_decay</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lr_0</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        lr_0: initial learning rate</span>
<span class="sd">        k: Decay rate</span>
<span class="sd">        t: iteration number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_0</span> <span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">t</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">lr</span>

    <span class="k">def</span> <span class="nf">step_decay</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lr_0</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        lr_0: initial learning rate</span>
<span class="sd">        F: factor value controlling the rate in which the learning date drops</span>
<span class="sd">        D: “Drop every” iteration</span>
<span class="sd">        t: current iteration</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">mult</span> <span class="o">=</span> <span class="n">F</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="mi">1</span><span class="o">+</span><span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="n">D</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_0</span> <span class="o">*</span> <span class="n">mult</span>
        <span class="k">return</span> <span class="n">lr</span>

    <span class="k">def</span> <span class="nf">exponential_decay</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lr_0</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        lr_0: initial learning rate</span>
<span class="sd">        k: Exponential Decay rate</span>
<span class="sd">        t: iteration number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">k</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lr</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="utility-function">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/preliminaries/data_preprocessing.html">Utility function</a><a class="headerlink" href="#utility-function" title="Permalink to this headline">#</a></h2>
<p>This class contains several utility functions such as one-hot vector, label encoder, normalization, etc</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Utility</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">label_encoding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>
<span class="sd">        Y: (m,d) shape matrix with categorical data</span>
<span class="sd">        Return</span>
<span class="sd">        result: label encoded data of 𝑌</span>
<span class="sd">        idx_list: list of the dictionaries containing the unique values </span>
<span class="sd">                  of the columns and their mapping to the integer.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">idx_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">indexes</span> <span class="o">=</span> <span class="p">{</span><span class="n">val</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="n">col</span><span class="p">]))}</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">indexes</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">[:,</span> <span class="n">col</span><span class="p">]])</span>
            <span class="n">idx_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">idx_list</span>

    <span class="k">def</span> <span class="nf">onehot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>
<span class="sd">        X: 1D array of labels of length &quot;m&quot;</span>
<span class="sd">        Return</span>
<span class="sd">        X_onehot: (m,d) one hot encoded matrix (one-hot of X) </span>
<span class="sd">                  (where d is the number of unique values in X)</span>
<span class="sd">        indexes: dictionary containing the unique values of X and their mapping to the integer column</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">indexes</span> <span class="o">=</span> <span class="p">{</span><span class="n">val</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">))}</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">indexes</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
        <span class="n">X_onehot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)))</span>
        <span class="n">X_onehot</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">X_onehot</span><span class="p">,</span> <span class="n">indexes</span>

    <span class="k">def</span> <span class="nf">minmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">min_X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_X</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">min_X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">min_X</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">max_X</span> <span class="o">-</span> <span class="n">min_X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">min_X</span><span class="p">,</span> <span class="n">max_X</span>

    <span class="k">def</span> <span class="nf">standardize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">mu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">std</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
        <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">inv_standardize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">Z</span><span class="o">*</span><span class="n">std</span> <span class="o">+</span> <span class="n">mu</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">train_ratio</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">test_ratio</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">train_ratio</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))],</span> <span class="n">indices</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">train_ratio</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):]</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">,:],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">,:]</span>
        <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="weights-initializer-class">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/terminologies_part_1.html#parameter-s-initialization">Weights initializer class</a><a class="headerlink" href="#weights-initializer-class" title="Permalink to this headline">#</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Weights_initializer</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">initializer_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>
<span class="sd">        shape: Shape of the weight matrix</span>

<span class="sd">        initializer_type: type of weight initializer</span>
<span class="sd">        available options are &#39;zeros&#39;, &#39;ones&#39;, &#39;random_normal&#39;, &#39;random_uniform&#39;, </span>
<span class="sd">        &#39;he_normal&#39;, &#39;xavier_normal&#39; and &#39;glorot_normal&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">if</span> <span class="n">initializer_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">=</span> <span class="s2">&quot;he_normal&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">=</span> <span class="n">initializer_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        
    <span class="k">def</span> <span class="nf">zeros_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">ones_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">random_normal_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">random_uniform_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">he_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">F</span><span class="p">,</span> <span class="n">Kc</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">Kh</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">xavier_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        shape: Shape of the Kernel matrix.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">F</span><span class="p">,</span> <span class="n">Kc</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">Kh</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">glorot_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        shape: Shape of the weight matrix.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">F</span><span class="p">,</span> <span class="n">Kc</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">Kh</span><span class="o">+</span><span class="n">Kw</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">get_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">==</span> <span class="s1">&#39;zeros&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">==</span> <span class="s1">&#39;ones&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ones_initializer</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">==</span> <span class="s1">&#39;random_normal&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">==</span> <span class="s1">&#39;random_uniform&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">==</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">he_initializer</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">==</span> <span class="s1">&#39;xavier_normal&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">initializer_type</span> <span class="o">==</span> <span class="s1">&#39;glorot_normal&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">glorot_initializer</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Valid initializer options are &#39;zeros&#39;, &#39;ones&#39;, &#39;random_normal&#39;, &#39;random_uniform&#39;, &#39;he_normal&#39;, &#39;xavier_normal&#39;, and &#39;glorot_normal&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dense-class">
<h2>Dense class<a class="headerlink" href="#dense-class" title="Permalink to this headline">#</a></h2>
<p>Dense class implements the operation:</p>
<div class="math notranslate nohighlight">
\[
z = XW + b^T
\]</div>
<div class="math notranslate nohighlight">
\[
a = f(z) 
\]</div>
<p>where activation <span class="math notranslate nohighlight">\(f(.)\)</span> is used if specified, else we do not use it. <span class="math notranslate nohighlight">\(W\)</span> is a weights matrix created by the Dense layer based on <a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/terminologies_part_1.html#parameter-s-initialization">type of initialization</a> (link to previous chapter) provided, and <span class="math notranslate nohighlight">\(b\)</span> is a bias vector created by the layer (only applicable if use_bias is True). These are all attributes of Dense.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neurons</span><span class="p">,</span> <span class="n">activation_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                 <span class="n">weight_initializer_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>

<span class="sd">        neurons: Positive integer (number of neurons), dimensionality of the output</span>

<span class="sd">        activation_type: type of activation</span>
<span class="sd">                         available options are &#39;sigmoid&#39;, &#39;linear&#39;, &#39;tanh&#39;, &#39;softmax&#39;, &#39;prelu&#39; and &#39;relu&#39;</span>
<span class="sd">                         If you don&#39;t specify anything, no activation is applied (ie. &quot;linear&quot; activation: a(x) = x).</span>

<span class="sd">        use_bias: Boolean, whether the layer uses a bias vector.</span>
<span class="sd">        </span>
<span class="sd">        weight_initializer_type: Initializer for the kernel weights matrix.</span>
<span class="sd">        </span>
<span class="sd">        weight_regularizer: Tuple, Regularizer function applied to the weights matrix (&#39;L2&#39;, 0.01) or (&#39;L1&#39;, 2)</span>

<span class="sd">        seed: To generate reproducable results</span>

<span class="sd">        input_dim: integer showing number of neurons in input layer </span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span> <span class="o">=</span> <span class="n">neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="n">activation_type</span><span class="o">=</span><span class="n">activation_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_initializer_type</span> <span class="o">=</span> <span class="n">weight_initializer_type</span> <span class="c1"># none is handled</span>
        <span class="k">if</span> <span class="n">weight_regularizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_regularizer</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;L2&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_regularizer</span> <span class="o">=</span> <span class="n">weight_regularizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>


    <span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hl</span><span class="p">,</span> <span class="n">optimizer_type</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        hl: Number of neurons in layer l-1</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">shape_W</span> <span class="o">=</span> <span class="p">(</span><span class="n">hl</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span><span class="p">)</span>
        <span class="n">shape_b</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">initializer</span> <span class="o">=</span> <span class="n">Weights_initializer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape_W</span><span class="p">,</span>
                                          <span class="n">initializer_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_initializer_type</span><span class="p">,</span>
                                          <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">initializer</span><span class="o">.</span><span class="n">get_initializer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape_b</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="p">(</span><span class="n">optimizer_type</span><span class="o">=</span><span class="n">optimizer_type</span><span class="p">,</span> <span class="n">shape_W</span><span class="o">=</span><span class="n">shape_W</span><span class="p">,</span> <span class="n">shape_b</span><span class="o">=</span><span class="n">shape_b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">r</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">T</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>
    
    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">da</span><span class="p">):</span>
        <span class="n">dz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">backpropagation</span><span class="p">(</span><span class="n">da</span><span class="p">)</span>
        <span class="n">dr</span> <span class="o">=</span> <span class="n">dz</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dz</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dW</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">@</span> <span class="n">dr</span>
        <span class="n">dX</span> <span class="o">=</span> <span class="n">dr</span> <span class="o">@</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dX</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>

<span class="sd">        lr: learning rate</span>
<span class="sd">        m: batch_size (sumber of samples in batch)</span>
<span class="sd">        k: iteration_number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">dW</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">get_optimization</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dW</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_regularizer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">==</span><span class="s1">&#39;l2&#39;</span><span class="p">:</span>
            <span class="n">dW</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_regularizer</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_regularizer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">==</span><span class="s1">&#39;l1&#39;</span><span class="p">:</span>
            <span class="n">dW</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_regularizer</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">-=</span> <span class="n">dW</span><span class="o">*</span><span class="p">(</span><span class="n">lr</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">db</span><span class="o">*</span><span class="p">(</span><span class="n">lr</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dropout-class">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/dropout.html">Dropout class</a><a class="headerlink" href="#dropout-class" title="Permalink to this headline">#</a></h2>
<p>This class will perform forward and backpropagation for a Dropout layer</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dropout</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>

<span class="sd">        p: Dropout probability</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">+=</span> <span class="mf">1e-6</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">-=</span> <span class="mf">1e-6</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> 
        <span class="n">Z</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span>
        <span class="k">return</span> <span class="n">Z</span>
    
    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dZ</span><span class="p">):</span>
        <span class="n">dX</span> <span class="o">=</span> <span class="n">dZ</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span>
        <span class="k">return</span> <span class="n">dX</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="batch-normalization-class">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/batch_normalization.html">Batch Normalization class</a><a class="headerlink" href="#batch-normalization-class" title="Permalink to this headline">#</a></h2>
<p>This class will perform forward and backpropagation for Batch Normalization layer. Right now it is only prepared for 1D data (that is it can be used only in Fully Connected or MLP layers and not in Convolution or Maxpool).</p>
<blockquote>
<div><p><strong>Note:</strong> We will initialise <span class="math notranslate nohighlight">\(\gamma\)</span> as ones and <span class="math notranslate nohighlight">\(\beta\)</span> as zeroes so that the output of the linear batch-norm transformation initially follows the standard zero-mean unit-variance normal distribution. This provides a normalised starting point, for which the model can update the <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> to scale and shift the distribution(s) of each input accordingly (for the current layer).</p>
</div></blockquote>
<p><strong>Forward pass</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">eps</span></code> represents: <span class="math notranslate nohighlight">\(\epsilon\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">mu</span></code> represents: <span class="math notranslate nohighlight">\(\mu\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">var</span></code> represents: <span class="math notranslate nohighlight">\(\sigma^2\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">zmu</span></code> represents: <span class="math notranslate nohighlight">\(\bar{z_l}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">ivar</span></code> represents: <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{\sigma^2 + \epsilon}}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">zhat</span></code> represents: <span class="math notranslate nohighlight">\(\hat{z_l}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">q</span></code> represents: <span class="math notranslate nohighlight">\(q_l\)</span></p>
<p><strong>Backpropagation</strong></p>
<p>This <code class="docutils literal notranslate"><span class="pre">dq</span></code> variable below represents <span class="math notranslate nohighlight">\(\frac{\partial J}{\partial q_l}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">dgamma</span></code> represents: <span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \gamma}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">dbeta</span></code> represents: <span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \beta}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">dzhat</span></code> represents: <span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \hat{z_l}}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">dvar</span></code> represents: <span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \sigma^2}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">dmu</span></code> represents: <span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \mu}\)</span></p>
<p><code class="docutils literal notranslate"><span class="pre">dz</span></code> represents: <span class="math notranslate nohighlight">\(\frac{\partial J}{\partial z_l}\)</span></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BatchNormalization</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters</span>

<span class="sd">        momentum: Momentum for the moving average</span>
<span class="sd">        epsilon: 𝜖, Small float added to variance to avoid dividing by zero</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
    
    <span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        d: Shape of input to BN layer</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">d</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        z: Input to BN layer</span>
<span class="sd">        mode: forward pass used for train or test</span>
<span class="sd">        &#39;&#39;&#39;</span> 
        <span class="k">if</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;train&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># 𝜇</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 𝜎^2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">zmu</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="c1"># z - 𝜇</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ivar</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="c1"># 𝜎𝑖𝑛𝑣</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">zhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">zmu</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivar</span> 
            <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">zhat</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="c1"># ql</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">var</span>
        <span class="k">elif</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;test&#39;</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
            <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="o">*</span><span class="n">q</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid forward batchnorm mode &quot;</span><span class="si">%s</span><span class="s1">&quot;&#39;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q</span>

    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dq</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dgamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dq</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">zhat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dbeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dq</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">dzhat</span> <span class="o">=</span> <span class="n">dq</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span>
        <span class="n">dvar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dzhat</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">zmu</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ivar</span><span class="o">**</span><span class="mi">3</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">dmu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dzhat</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">ivar</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">dz</span> <span class="o">=</span> <span class="n">dzhat</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivar</span> <span class="o">+</span> <span class="n">dvar</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">zmu</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">dmu</span>
        <span class="k">return</span> <span class="n">dz</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>

<span class="sd">        lr: learning rate</span>
<span class="sd">        m: batch_size (sumber of samples in batch)</span>
<span class="sd">        k: iteration_number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dgamma</span><span class="o">*</span><span class="p">(</span><span class="n">lr</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbeta</span><span class="o">*</span><span class="p">(</span><span class="n">lr</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="padding2d-class">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/convolutional_layers.html">Padding2D class</a><a class="headerlink" href="#padding2d-class" title="Permalink to this headline">#</a></h2>
<p>This class will perform padding on a batch of 2D image with channels. We will be considering padding as a separate layer only which contains its own forward and backpropagation operations.</p>
<p>We need a small function such that we can extract the original input errors from the padding ones. This you can consider as <strong>backpropagation through padding operation</strong></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Padding2D</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>

<span class="sd">        p: padding type</span>
<span class="sd">        Allowed types are only &#39;same&#39;, &#39;valid&#39;, an integer or a tuple of length 2.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        
    <span class="k">def</span> <span class="nf">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Utility function to help get the dimension of the output after padding</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">4</span><span class="p">:</span>
            <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">input_shape</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">input_shape</span>
        
        <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="n">sh</span><span class="p">,</span> <span class="n">sw</span> <span class="o">=</span> <span class="n">s</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span>
        
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">==</span><span class="nb">int</span><span class="p">:</span>
            <span class="n">pt</span><span class="p">,</span> <span class="n">pb</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span> <span class="n">p</span>
            <span class="n">pl</span><span class="p">,</span> <span class="n">pr</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span> <span class="n">p</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">==</span><span class="nb">tuple</span><span class="p">:</span>
            <span class="n">ph</span><span class="p">,</span> <span class="n">pw</span> <span class="o">=</span> <span class="n">p</span>
            <span class="n">pt</span><span class="p">,</span> <span class="n">pb</span> <span class="o">=</span> <span class="n">ph</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">ph</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>
            <span class="n">pl</span><span class="p">,</span> <span class="n">pr</span> <span class="o">=</span> <span class="n">pw</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">pw</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>

        <span class="k">elif</span> <span class="n">p</span><span class="o">==</span><span class="s1">&#39;valid&#39;</span><span class="p">:</span>
            <span class="n">pt</span><span class="p">,</span> <span class="n">pb</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
            <span class="n">pl</span><span class="p">,</span> <span class="n">pr</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

        <span class="k">elif</span> <span class="n">p</span><span class="o">==</span><span class="s1">&#39;same&#39;</span><span class="p">:</span>
            <span class="c1"># calculating how much padding is required in all 4 directions </span>
            <span class="c1"># (top, bottom, left and right)</span>
            <span class="n">ph</span> <span class="o">=</span> <span class="p">(</span><span class="n">sh</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">Nh</span> <span class="o">+</span> <span class="n">Kh</span> <span class="o">-</span> <span class="n">sh</span>
            <span class="n">pw</span> <span class="o">=</span> <span class="p">(</span><span class="n">sw</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">Nw</span> <span class="o">+</span> <span class="n">Kw</span> <span class="o">-</span> <span class="n">sw</span>

            <span class="n">pt</span><span class="p">,</span> <span class="n">pb</span> <span class="o">=</span> <span class="n">ph</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">ph</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>
            <span class="n">pl</span><span class="p">,</span> <span class="n">pr</span> <span class="o">=</span> <span class="n">pw</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">pw</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Incorrect padding type. Allowed types are only &#39;same&#39;, &#39;valid&#39;, an integer or a tuple of length 2.&quot;</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">4</span><span class="p">:</span>
            <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="o">+</span><span class="n">pt</span><span class="o">+</span><span class="n">pb</span><span class="p">,</span> <span class="n">Nw</span><span class="o">+</span><span class="n">pl</span><span class="o">+</span><span class="n">pr</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="o">+</span><span class="n">pt</span><span class="o">+</span><span class="n">pb</span><span class="p">,</span> <span class="n">Nw</span><span class="o">+</span><span class="n">pl</span><span class="o">+</span><span class="n">pr</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output_shape</span><span class="p">,</span> <span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">pb</span><span class="p">,</span> <span class="n">pl</span><span class="p">,</span> <span class="n">pr</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>
<span class="sd">        </span>
<span class="sd">        X: input of shape (m, Nc, Nh, Nw)</span>
<span class="sd">        </span>
<span class="sd">        s: strides along height and width (sh, sw)</span>
<span class="sd">        </span>
<span class="sd">        kernel_size: kernel size as specified in Conv2D layer</span>
<span class="sd">        </span>
<span class="sd">        Returns: </span>
<span class="sd">        </span>
<span class="sd">        Xp: padded X</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pl</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">,</span> 
                                                                                      <span class="n">kernel_size</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
        
        <span class="n">zeros_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">))</span>
        <span class="n">zeros_l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pl</span><span class="p">))</span>
        <span class="n">zeros_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pt</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pl</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">))</span>
        <span class="n">zeros_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pb</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pl</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">))</span>

        <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">zeros_r</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">zeros_l</span><span class="p">,</span> <span class="n">Xp</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">zeros_t</span><span class="p">,</span> <span class="n">Xp</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Xp</span><span class="p">,</span> <span class="n">zeros_b</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">Xp</span>
    
    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dXp</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters: </span>
<span class="sd">        </span>
<span class="sd">        dXp: Backprop Error of padded X (Xp)</span>
<span class="sd">        </span>
<span class="sd">        Return:</span>
<span class="sd">        </span>
<span class="sd">        dX: Backprop Error of X</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span>
        <span class="n">dX</span> <span class="o">=</span> <span class="n">dXp</span><span class="p">[:,</span> <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pt</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">pt</span><span class="o">+</span><span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pl</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">pl</span><span class="o">+</span><span class="n">Nw</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">dX</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="convolution2d-class">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/convolutional_layers.html">Convolution2D class</a><a class="headerlink" href="#convolution2d-class" title="Permalink to this headline">#</a></h2>
<p>This class will perform forward and backpropagation for a Convolution layer on a batch of 2D image with channels.</p>
<p>We have an Input with batch of images (with channels) and multiple filters.</p>
<p>Shape of Image will be <span class="math notranslate nohighlight">\((m, N_c, N_h, N_w)\)</span>.</p>
<p>The shape of Kernel will be <span class="math notranslate nohighlight">\((F, K_c, K_h, K_w)\)</span> where <span class="math notranslate nohighlight">\(F\)</span> is the total number of filters.</p>
<p><img alt="" src="../../_images/input_batch_channels_and_filters.png" /></p>
<p><img alt="" src="../../_images/convolution_layer.png" /></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Conv2D</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
                 <span class="n">activation_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">weight_initializer_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">kernel_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>

<span class="sd">        filters: Integer, the number of output filters in the convolution (F).</span>
<span class="sd">        </span>
<span class="sd">        kernel_size: An integer or tuple/list of 2 integers, </span>
<span class="sd">                     specifying the height and width of the 2D convolution window.</span>
<span class="sd">                     </span>
<span class="sd">        s: strides along height and width (sh, sw)</span>
<span class="sd">        </span>
<span class="sd">        p: padding type</span>
<span class="sd">           Allowed types are only &#39;same&#39;, &#39;valid&#39;, an integer or a tuple of length 2.</span>

<span class="sd">        activation_type: type of activation</span>
<span class="sd">                         available options are &#39;sigmoid&#39;, &#39;linear&#39;, &#39;tanh&#39;, &#39;softmax&#39;, &#39;prelu&#39; and &#39;relu&#39;</span>
<span class="sd">                         If you don&#39;t specify anything, no activation is applied (ie. &quot;linear&quot; activation: a(x) = x).</span>

<span class="sd">        use_bias: Boolean, whether the layer uses a bias vector.</span>
<span class="sd">        </span>
<span class="sd">        weight_initializer_type: Initializer for the kernel weights matrix.</span>
<span class="sd">        </span>
<span class="sd">        kernel_regularizer: Tuple, Regularizer function applied to the kernel matrix (&#39;L2&#39;, 0.01) or (&#39;L1&#39;, 2)</span>

<span class="sd">        seed: To generate reproducable results</span>

<span class="sd">        input_shape: tuple showing size of input: (batch_size, channels, rows, cols) -&gt; (m, Nc, Nh, Nw)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">Padding2D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">filters</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape_x</span> <span class="o">=</span> <span class="n">input_shape</span>
        
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span><span class="o">==</span><span class="nb">int</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span><span class="o">==</span><span class="nb">tuple</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">Kh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kw</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span>
        
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">==</span><span class="nb">int</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">==</span><span class="nb">tuple</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">s</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">sh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="n">activation_type</span><span class="o">=</span><span class="n">activation_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_initializer_type</span> <span class="o">=</span> <span class="n">weight_initializer_type</span> <span class="c1"># none is handled</span>
        <span class="k">if</span> <span class="n">kernel_regularizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;L2&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">kernel_regularizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        
    <span class="k">def</span> <span class="nf">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape_x</span> <span class="o">=</span> <span class="n">input_shape</span> <span class="c1"># (3D or 4D)</span>
        
        <span class="c1"># Padded X will be actual input to this Conv2D</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_shape_x</span><span class="p">,</span> 
                                                          <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">4</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span>
        
        <span class="c1"># Output shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Oh</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Nh</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kh</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">sh</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ow</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Nw</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kw</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">sw</span> <span class="o">+</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Oh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ow</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">4</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Oh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ow</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">optimizer_type</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">get_dimensions</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        
        <span class="n">shape_b</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Oh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ow</span><span class="p">)</span>
        
        <span class="n">shape_K</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kw</span><span class="p">)</span>
        
        <span class="n">initializer</span> <span class="o">=</span> <span class="n">Weights_initializer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape_K</span><span class="p">,</span>
                                          <span class="n">initializer_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_initializer_type</span><span class="p">,</span>
                                          <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">initializer</span><span class="o">.</span><span class="n">get_initializer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape_b</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="p">(</span><span class="n">optimizer_type</span><span class="o">=</span><span class="n">optimizer_type</span><span class="p">,</span> <span class="n">shape_W</span><span class="o">=</span><span class="n">shape_K</span><span class="p">,</span> <span class="n">shape_b</span><span class="o">=</span><span class="n">shape_b</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">dilate2D</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Dr</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
        <span class="n">dh</span><span class="p">,</span> <span class="n">dw</span> <span class="o">=</span> <span class="n">Dr</span> <span class="c1"># Dilate rate</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">Xd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">W</span><span class="p">),</span> <span class="n">dw</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">values</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">Xd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">Xd</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">H</span><span class="p">),</span> <span class="n">dh</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">values</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Xd</span>

    <span class="k">def</span> <span class="nf">prepare_subMatrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">sh</span><span class="p">,</span> <span class="n">sw</span> <span class="o">=</span> <span class="n">s</span>

        <span class="n">Oh</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nh</span><span class="o">-</span><span class="n">Kh</span><span class="p">)</span><span class="o">//</span><span class="n">sh</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">Ow</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nw</span><span class="o">-</span><span class="n">Kw</span><span class="p">)</span><span class="o">//</span><span class="n">sw</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nc</span><span class="o">*</span><span class="n">Nh</span><span class="o">*</span><span class="n">Nw</span><span class="p">,</span> <span class="n">Nw</span><span class="o">*</span><span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span><span class="o">*</span><span class="n">sh</span><span class="p">,</span> <span class="n">sw</span><span class="p">,</span> <span class="n">Nw</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">itemsize</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">)</span>

        <span class="n">subM</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">as_strided</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> 
                                               <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Oh</span><span class="p">,</span> <span class="n">Ow</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">),</span>
                                               <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">subM</span>
         
    <span class="k">def</span> <span class="nf">convolve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;front&#39;</span><span class="p">):</span>

        <span class="n">F</span><span class="p">,</span> <span class="n">Kc</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">subM</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_subMatrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;front&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;fckl,mcijkl-&gt;mfij&#39;</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">subM</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;back&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;fdkl,mcijkl-&gt;mdij&#39;</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">subM</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span><span class="o">==</span><span class="s1">&#39;param&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;mfkl,mcijkl-&gt;fcij&#39;</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">subM</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">dZ_D_dX</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dZ_D</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span><span class="p">):</span>

        <span class="c1"># Pad the dilated dZ (dZ_D -&gt; dZ_Dp)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">Hd</span><span class="p">,</span> <span class="n">Wd</span> <span class="o">=</span> <span class="n">dZ_D</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">ph</span> <span class="o">=</span> <span class="n">Nh</span> <span class="o">-</span> <span class="n">Hd</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kh</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">pw</span> <span class="o">=</span> <span class="n">Nw</span> <span class="o">-</span> <span class="n">Wd</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kw</span> <span class="o">-</span> <span class="mi">1</span>
        
        <span class="n">padding_back</span> <span class="o">=</span> <span class="n">Padding2D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="p">(</span><span class="n">ph</span><span class="p">,</span> <span class="n">pw</span><span class="p">))</span>

        <span class="n">dZ_Dp</span> <span class="o">=</span> <span class="n">padding_back</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dZ_D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>

        <span class="c1"># Rotate K by 180 degrees</span>
        
        <span class="n">K_rotated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># convolve dZ_Dp with K_rotated</span>
        
        <span class="n">dXp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">dZ_Dp</span><span class="p">,</span> <span class="n">K_rotated</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;back&#39;</span><span class="p">)</span>
        
        <span class="n">dX</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">backpropagation</span><span class="p">(</span><span class="n">dXp</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dX</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># padding</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>

        <span class="n">Xp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        
        <span class="c1"># convolve Xp with K</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
    
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">a</span>
     
    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">da</span><span class="p">):</span>

        <span class="n">Xp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>

        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">Xp</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">dZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">backpropagation</span><span class="p">(</span><span class="n">da</span><span class="p">)</span>
        
        <span class="c1"># Dilate dZ (dZ-&gt; dZ_D)</span>
        
        <span class="n">dZ_D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilate2D</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">Dr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        
        <span class="n">dX</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ_D_dX</span><span class="p">(</span><span class="n">dZ_D</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span><span class="p">)</span>
        
        <span class="c1"># Gradient dK</span>
        
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">Hd</span><span class="p">,</span> <span class="n">Wd</span> <span class="o">=</span> <span class="n">dZ_D</span><span class="o">.</span><span class="n">shape</span>
        
        <span class="n">ph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span> <span class="o">-</span> <span class="n">Hd</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kh</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">pw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span> <span class="o">-</span> <span class="n">Wd</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kw</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">padding_back</span> <span class="o">=</span> <span class="n">Padding2D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="p">(</span><span class="n">ph</span><span class="p">,</span> <span class="n">pw</span><span class="p">))</span>

        <span class="n">dZ_Dp</span> <span class="o">=</span> <span class="n">padding_back</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dZ_D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dK</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">dZ_Dp</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;param&#39;</span><span class="p">)</span>
        
        <span class="c1"># Gradient db</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">dX</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>

<span class="sd">        lr: learning rate</span>
<span class="sd">        m: batch_size (sumber of samples in batch)</span>
<span class="sd">        k: iteration_number</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">dK</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">get_optimization</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dK</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">db</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">==</span><span class="s1">&#39;l2&#39;</span><span class="p">:</span>
            <span class="n">dK</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_regularizer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">==</span><span class="s1">&#39;l1&#39;</span><span class="p">:</span>
            <span class="n">dK</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dK</span><span class="o">*</span><span class="p">(</span><span class="n">lr</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">db</span><span class="o">*</span><span class="p">(</span><span class="n">lr</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="maxpool2d-class">
<h2><a class="reference external" href="https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/pooling_layers.html">Maxpool2D class</a><a class="headerlink" href="#maxpool2d-class" title="Permalink to this headline">#</a></h2>
<p>This class will perform forward and backpropagation for a Pooling layer on a batch of 2D image with channels.</p>
<p>Type of Pooling available are: <code class="docutils literal notranslate"><span class="pre">Max</span></code> and <code class="docutils literal notranslate"><span class="pre">Mean</span></code></p>
<p><img alt="" src="../../_images/pooling_layer.png" /></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Pooling2D</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span> <span class="n">pool_type</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>
<span class="sd">        </span>
<span class="sd">        pool_size: An integer or tuple/list of 2 integers, </span>
<span class="sd">                     specifying the height and width of the 2D convolution window.</span>
<span class="sd">                     </span>
<span class="sd">        s: strides along height and width (sh, sw)</span>
<span class="sd">        </span>
<span class="sd">        p: padding type</span>
<span class="sd">           Allowed types are only &#39;same&#39;, &#39;valid&#39;, an integer or a tuple of length 2.</span>

<span class="sd">        pool_type: pooling type</span>
<span class="sd">        Allowed types are only &#39;max&#39;, or &#39;mean&#39;</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">Padding2D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">pool_size</span><span class="p">)</span><span class="o">==</span><span class="nb">int</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">pool_size</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">pool_size</span><span class="p">)</span><span class="o">==</span><span class="nb">tuple</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pool_size</span><span class="p">)</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span> <span class="o">=</span> <span class="n">pool_size</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">Kh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kw</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span>
        
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">==</span><span class="nb">int</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">==</span><span class="nb">tuple</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">s</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">sh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">pool_type</span> <span class="o">=</span> <span class="n">pool_type</span>    

    <span class="k">def</span> <span class="nf">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">4</span><span class="p">:</span>
            <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">input_shape</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">input_shape</span>

        <span class="n">Oh</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nh</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Kh</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">sh</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">Ow</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nw</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Kw</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">sw</span> <span class="o">+</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">4</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Oh</span><span class="p">,</span> <span class="n">Ow</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nc</span><span class="p">,</span> <span class="n">Oh</span><span class="p">,</span> <span class="n">Ow</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prepare_subMatrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">sh</span><span class="p">,</span> <span class="n">sw</span> <span class="o">=</span> <span class="n">s</span>
        <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="n">pool_size</span>

        <span class="n">Oh</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nh</span><span class="o">-</span><span class="n">Kh</span><span class="p">)</span><span class="o">//</span><span class="n">sh</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">Ow</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nw</span><span class="o">-</span><span class="n">Kw</span><span class="p">)</span><span class="o">//</span><span class="n">sw</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nc</span><span class="o">*</span><span class="n">Nh</span><span class="o">*</span><span class="n">Nw</span><span class="p">,</span> <span class="n">Nh</span><span class="o">*</span><span class="n">Nw</span><span class="p">,</span> <span class="n">Nw</span><span class="o">*</span><span class="n">sh</span><span class="p">,</span> <span class="n">sw</span><span class="p">,</span> <span class="n">Nw</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">itemsize</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">)</span>

        <span class="n">subM</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">as_strided</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> 
                                               <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Oh</span><span class="p">,</span> <span class="n">Ow</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">),</span>
                                               <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">subM</span>
    
    <span class="k">def</span> <span class="nf">pooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)):</span>
        
        <span class="n">subM</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_subMatrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_type</span><span class="o">==</span><span class="s1">&#39;max&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">subM</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_type</span><span class="o">==</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">subM</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Allowed pool types are only &#39;max&#39; or &#39;mean&#39;.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prepare_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">subM</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">):</span>
        
        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Oh</span><span class="p">,</span> <span class="n">Ow</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="n">subM</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">a</span> <span class="o">=</span> <span class="n">subM</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">Kh</span><span class="o">*</span><span class="n">Kw</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">b</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Oh</span><span class="p">,</span> <span class="n">Ow</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">mask_dXp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">Xp</span><span class="p">,</span> <span class="n">dZ</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">):</span>
        <span class="n">dA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;i,ijk-&gt;ijk&#39;</span><span class="p">,</span> <span class="n">dZ</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">mask</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">Kh</span><span class="p">,</span><span class="n">Kw</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">Xp</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="n">Nc</span><span class="o">*</span><span class="n">Nh</span><span class="o">*</span><span class="n">Nw</span><span class="p">,</span> <span class="n">Nh</span><span class="o">*</span><span class="n">Nw</span><span class="p">,</span> <span class="n">Nw</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">Xp</span><span class="o">.</span><span class="n">itemsize</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">)</span>
        <span class="n">dXp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">as_strided</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">Xp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">strides</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dXp</span>
            
    <span class="k">def</span> <span class="nf">maxpool_backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dZ</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        
        <span class="n">Xp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>

        <span class="n">subM</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_subMatrix</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>

        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Oh</span><span class="p">,</span> <span class="n">Ow</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="n">subM</span><span class="o">.</span><span class="n">shape</span>
        
        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">Xp</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_mask</span><span class="p">(</span><span class="n">subM</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">)</span>
        
        <span class="n">dXp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_dXp</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">Xp</span><span class="p">,</span> <span class="n">dZ</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">dXp</span>

    <span class="k">def</span> <span class="nf">dZ_dZp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dZ</span><span class="p">):</span>
        <span class="n">sh</span><span class="p">,</span> <span class="n">sw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span>
        <span class="n">Kh</span><span class="p">,</span> <span class="n">Kw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span>

        <span class="n">dZp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">Kh</span><span class="p">,</span><span class="n">Kw</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dZ</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span> <span class="c1"># similar to repelem in matlab</span>

        <span class="n">jh</span><span class="p">,</span> <span class="n">jw</span> <span class="o">=</span> <span class="n">Kh</span><span class="o">-</span><span class="n">sh</span><span class="p">,</span> <span class="n">Kw</span><span class="o">-</span><span class="n">sw</span> <span class="c1"># jump along height and width</span>

        <span class="k">if</span> <span class="n">jw</span><span class="o">!=</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">dZp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span>

            <span class="n">l1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">sw</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
            <span class="n">l2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">sw</span> <span class="o">+</span> <span class="n">jw</span><span class="p">,</span> <span class="n">L</span> <span class="o">+</span> <span class="n">jw</span><span class="p">)</span>

            <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">([</span><span class="kc">True</span><span class="p">]</span><span class="o">*</span><span class="n">jw</span> <span class="o">+</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span><span class="o">*</span><span class="n">jw</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span><span class="o">//</span><span class="n">jw</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>

            <span class="n">r1</span> <span class="o">=</span> <span class="n">l1</span><span class="p">[</span><span class="n">mask</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">l1</span><span class="p">)]]</span>
            <span class="n">r2</span> <span class="o">=</span> <span class="n">l2</span><span class="p">[</span><span class="n">mask</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">l2</span><span class="p">)]]</span>

            <span class="n">dZp</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">r1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dZp</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">r2</span><span class="p">]</span>
            <span class="n">dZp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">dZp</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">jh</span><span class="o">!=</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">dZp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span>

            <span class="n">l1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">sh</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
            <span class="n">l2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">sh</span> <span class="o">+</span> <span class="n">jh</span><span class="p">,</span> <span class="n">L</span> <span class="o">+</span> <span class="n">jh</span><span class="p">)</span>

            <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">([</span><span class="kc">True</span><span class="p">]</span><span class="o">*</span><span class="n">jh</span> <span class="o">+</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span><span class="o">*</span><span class="n">jh</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span><span class="o">//</span><span class="n">jh</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>

            <span class="n">r1</span> <span class="o">=</span> <span class="n">l1</span><span class="p">[</span><span class="n">mask</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">l1</span><span class="p">)]]</span>
            <span class="n">r2</span> <span class="o">=</span> <span class="n">l2</span><span class="p">[</span><span class="n">mask</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">l2</span><span class="p">)]]</span>

            <span class="n">dZp</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">r1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">dZp</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">r2</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">dZp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">dZp</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dZp</span>

    <span class="k">def</span> <span class="nf">averagepool_backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dZ</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        
        <span class="n">Xp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>

        <span class="n">m</span><span class="p">,</span> <span class="n">Nc</span><span class="p">,</span> <span class="n">Nh</span><span class="p">,</span> <span class="n">Nw</span> <span class="o">=</span> <span class="n">Xp</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">dZp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ_dZp</span><span class="p">(</span><span class="n">dZ</span><span class="p">)</span>

        <span class="n">ph</span> <span class="o">=</span> <span class="n">Nh</span> <span class="o">-</span> <span class="n">dZp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">pw</span> <span class="o">=</span> <span class="n">Nw</span> <span class="o">-</span> <span class="n">dZp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">padding_back</span> <span class="o">=</span> <span class="n">Padding2D</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="p">(</span><span class="n">ph</span><span class="p">,</span> <span class="n">pw</span><span class="p">))</span>
        
        <span class="n">dXp</span> <span class="o">=</span> <span class="n">padding_back</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dZp</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dXp</span> <span class="o">/</span> <span class="p">(</span><span class="n">Nh</span><span class="o">*</span><span class="n">Nw</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters:</span>
<span class="sd">        </span>
<span class="sd">        X: input of shape (m, Nc, Nh, Nw)</span>
<span class="sd">        </span>
<span class="sd">        Returns: </span>
<span class="sd">        </span>
<span class="sd">        Z: pooled X</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>

        <span class="c1"># padding</span>
        <span class="n">Xp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>

        <span class="n">Z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">Z</span>
    
    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dZ</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parameters: </span>
<span class="sd">        </span>
<span class="sd">        dZ: Output Error</span>
<span class="sd">        </span>
<span class="sd">        Return:</span>
<span class="sd">        </span>
<span class="sd">        dX: Backprop Error of X</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_type</span><span class="o">==</span><span class="s1">&#39;max&#39;</span><span class="p">:</span>
            <span class="n">dXp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool_backprop</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_type</span><span class="o">==</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span>
            <span class="n">dXp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">averagepool_backprop</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
        <span class="n">dX</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">backpropagation</span><span class="p">(</span><span class="n">dXp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dX</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="flatten-class">
<h2>Flatten class<a class="headerlink" href="#flatten-class" title="Permalink to this headline">#</a></h2>
<p>Converts 4D image <span class="math notranslate nohighlight">\((m, N_c, N_h, N_w)\)</span> to a 2D array of shape <span class="math notranslate nohighlight">\((m, N_c \times N_h \times N_w)\)</span> so that it can be sent to the Dense layer</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Flatten</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">X_flat</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">X_flat</span>
     
    <span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dZ</span><span class="p">):</span>
        <span class="n">dX</span> <span class="o">=</span> <span class="n">dZ</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">dX</span>
    
    <span class="k">def</span> <span class="nf">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">4</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span> <span class="o">=</span> <span class="n">input_shape</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span> <span class="o">=</span> <span class="n">input_shape</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nc</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nh</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nw</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cnn">
<h2>CNN<a class="headerlink" href="#cnn" title="Permalink to this headline">#</a></h2>
<p>This class finally contains the compile, summary, fit, predict, etc methods for executing our CNN model. Apart from <code class="docutils literal notranslate"><span class="pre">network_architecture</span></code>, <code class="docutils literal notranslate"><span class="pre">summary</span></code> and <code class="docutils literal notranslate"><span class="pre">initialize_parameters</span></code> all other functions are almost same to that of the functions used in <a class="reference external" href="https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/neural_networks_mlp_scratch_best.html">MLP model</a></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CNN</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This is a sequential CNN model</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network_architecture_called</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
        <span class="c1"># adds a layer to CNN model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">Input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">input_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">]</span> <span class="c1"># output architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Input&quot;</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">network_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;Conv2D&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_shape_x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">input_shape_x</span><span class="p">)</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">output_shape</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Flatten&#39;</span><span class="p">,</span> <span class="s1">&#39;Pooling2D&#39;</span><span class="p">]:</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">get_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">output_shape</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;Dense&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">neurons</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="k">if</span> <span class="n">layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layer_name</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;NoneType&quot;</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">model</span><span class="o">.</span><span class="n">layer_name</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">model</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_architecture_called</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network_architecture</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network_architecture_called</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">len_assigned</span> <span class="o">=</span> <span class="p">[</span><span class="mi">45</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
        <span class="n">count</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Dense&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Activation&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Input&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                <span class="s1">&#39;BatchNormalization&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Dropout&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Conv2D&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                <span class="s1">&#39;Pooling2D&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Flatten&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

        <span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Layer (type)&#39;</span><span class="p">,</span> <span class="s1">&#39;Output Shape&#39;</span><span class="p">,</span> <span class="s1">&#39;# of Parameters&#39;</span><span class="p">]</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model: CNN&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">len_assigned</span><span class="p">))</span>

        <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">+=</span> <span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span><span class="o">*</span><span class="p">(</span><span class="n">len_assigned</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">len_assigned</span><span class="p">))</span>

        <span class="n">total_params</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">trainable_params</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">non_trainable_params</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span><span class="p">)):</span>
            <span class="c1"># layer name</span>
            <span class="n">layer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">layer_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">count</span><span class="p">[</span><span class="n">layer_name</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="s1">&#39;(&#39;</span> <span class="o">+</span> <span class="n">layer_name</span> <span class="o">+</span> <span class="s1">&#39;)&#39;</span>
            <span class="n">count</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># output shape</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="s1">&#39;(None, &#39;</span> 
                <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">out</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">n</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;, &#39;</span>
                <span class="n">out</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;)&#39;</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="s1">&#39;(None, &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;)&#39;</span>

            <span class="c1"># number of params</span>
            <span class="k">if</span> <span class="n">layer_name</span><span class="o">==</span><span class="s1">&#39;Dense&#39;</span><span class="p">:</span>
                <span class="n">h0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">h1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
                    <span class="n">params</span> <span class="o">=</span> <span class="n">h0</span><span class="o">*</span><span class="n">h1</span> <span class="o">+</span> <span class="n">h1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">params</span> <span class="o">=</span> <span class="n">h0</span><span class="o">*</span><span class="n">h1</span>
                <span class="n">total_params</span> <span class="o">+=</span> <span class="n">params</span>
                <span class="n">trainable_params</span> <span class="o">+=</span> <span class="n">params</span>
            <span class="k">elif</span> <span class="n">layer_name</span><span class="o">==</span><span class="s1">&#39;BatchNormalization&#39;</span><span class="p">:</span>
                <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">params</span> <span class="o">=</span> <span class="mi">4</span><span class="o">*</span><span class="n">h</span>
                <span class="n">trainable_params</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">h</span>
                <span class="n">non_trainable_params</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">h</span>
                <span class="n">total_params</span> <span class="o">+=</span> <span class="n">params</span>
            <span class="k">elif</span> <span class="n">layer_name</span><span class="o">==</span><span class="s1">&#39;Conv2D&#39;</span><span class="p">:</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
                    <span class="n">add_b</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">add_b</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">params</span> <span class="o">=</span> <span class="p">((</span><span class="n">layer</span><span class="o">.</span><span class="n">Nc</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">Kh</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">Kw</span><span class="p">)</span> <span class="o">+</span> <span class="n">add_b</span><span class="p">)</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">F</span>
                <span class="n">trainable_params</span> <span class="o">+=</span> <span class="n">params</span>
                <span class="n">total_params</span> <span class="o">+=</span> <span class="n">params</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Pooling, Dropout, Flatten, Input</span>
                <span class="n">params</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">params</span><span class="p">)]</span>

            <span class="c1"># print this row</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
                <span class="n">text</span> <span class="o">+=</span> <span class="n">names</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span><span class="o">*</span><span class="p">(</span><span class="n">len_assigned</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span><span class="o">!=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_name</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">len_assigned</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">len_assigned</span><span class="p">))</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total params:&quot;</span><span class="p">,</span> <span class="n">total_params</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trainable params:&quot;</span><span class="p">,</span> <span class="n">trainable_params</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Non-trainable params:&quot;</span><span class="p">,</span> <span class="n">non_trainable_params</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">len_assigned</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cost_type</span><span class="p">,</span> <span class="n">optimizer_type</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost</span> <span class="o">=</span> <span class="n">Cost</span><span class="p">(</span><span class="n">cost_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span> <span class="o">=</span> <span class="n">cost_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">=</span> <span class="n">optimizer_type</span>

    <span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_architecture_called</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network_architecture</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network_architecture_called</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># initialize parameters for different layers</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Dense&#39;</span><span class="p">,</span> <span class="s1">&#39;Conv2D&#39;</span><span class="p">]:</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;BatchNormalization&#39;</span><span class="p">:</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">X_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
                        <span class="s1">&#39;Validation Loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
                        <span class="s1">&#39;Training Accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span>
                        <span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">:</span> <span class="p">[]}</span>

        <span class="n">iterations</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_parameters</span><span class="p">()</span>

        <span class="n">total_num_batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">cost_train</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">y_pred_train</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)):</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                
                <span class="n">Z</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

                <span class="c1"># feed-forward</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                    <span class="n">Z</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

                <span class="c1"># calculating training accuracy</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span><span class="o">==</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
                    <span class="n">y_pred_train</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                    <span class="n">y_train</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                
                <span class="c1"># calculating the loss</span>
                <span class="n">cost_train</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="o">.</span><span class="n">get_cost</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span>

                <span class="c1"># calculating dL/daL (last layer backprop error)</span>
                <span class="n">dZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="o">.</span><span class="n">get_d_cost</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
                
                <span class="c1"># backpropagation</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="n">dZ</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">backpropagation</span><span class="p">(</span><span class="n">dZ</span><span class="p">)</span>

                <span class="c1"># Parameters update</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Dense&#39;</span><span class="p">,</span> <span class="s1">&#39;BatchNormalization&#39;</span><span class="p">,</span> <span class="s1">&#39;Conv2D&#39;</span><span class="p">]:</span>
                        <span class="n">layer</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>

                <span class="c1"># Learning rate decay</span>
                <span class="k">if</span> <span class="n">lr_decay</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_decay</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

                <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">iterations</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="n">cost_train</span> <span class="o">/=</span> <span class="n">num_batches</span>

            <span class="c1"># printing purpose only (Training Accuracy, Validation loss and accuracy)</span>

            <span class="n">text</span>  <span class="o">=</span> <span class="s1">&#39;Training Loss: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">cost_train</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; - &#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_train</span><span class="p">)</span>

            <span class="c1"># training accuracy</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span><span class="o">==</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
                <span class="n">accuracy_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_pred_train</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
                <span class="n">text</span> <span class="o">+=</span> <span class="s1">&#39;Training Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy_train</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_train</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">text</span> <span class="o">+=</span> <span class="s1">&#39;Training Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">cost_train</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_train</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">X_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cost_val</span><span class="p">,</span> <span class="n">accuracy_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
                <span class="n">text</span> <span class="o">+=</span> <span class="s1">&#39; - Validation Loss: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">cost_val</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; - &#39;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_val</span><span class="p">)</span>
                <span class="n">text</span> <span class="o">+=</span> <span class="s1">&#39;Validation Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy_val</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_val</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">utility</span> <span class="o">=</span> <span class="n">Utility</span><span class="p">()</span>
        <span class="n">Y_1hot</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">utility</span><span class="o">.</span><span class="n">onehot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
            <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
            <span class="n">Y_1hot_batch</span> <span class="o">=</span> <span class="n">Y_1hot</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;BatchNormalization&#39;</span><span class="p">:</span>
                    <span class="n">Z</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">Z</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span><span class="o">==</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
                <span class="n">cost</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="o">.</span><span class="n">get_cost</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">Y_1hot_batch</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_batch</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cost</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="o">.</span><span class="n">get_cost</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>

            <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span><span class="o">==</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">cost</span> <span class="o">/=</span> <span class="n">num_batches</span>
            <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cost</span> <span class="o">/=</span> <span class="n">num_batches</span>
            <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="n">cost</span>

    <span class="k">def</span> <span class="nf">loss_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">],</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">])</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">accuracy_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">])</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="n">batch_size</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;BatchNormalization&#39;</span><span class="p">:</span>
                    <span class="n">Z</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">Z</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span><span class="o">==</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">Z</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_type</span><span class="o">==</span><span class="s1">&#39;cross-entropy&#39;</span><span class="p">:</span>
                    <span class="n">y_pred</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">Z</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="validating-model-using-mnist-dataset">
<h2>Validating model using MNIST Dataset<a class="headerlink" href="#validating-model-using-mnist-dataset" title="Permalink to this headline">#</a></h2>
<p>Check this <a class="reference external" href="https://en.wikipedia.org/wiki/MNIST_database">page</a> (link to an external website) to know more about <strong>MNIST dataset</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>

<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">samples</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:</span><span class="n">samples</span><span class="p">,</span> <span class="p">:]</span><span class="o">/</span><span class="mi">255</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:</span><span class="n">samples</span><span class="p">,</span> <span class="p">:]</span><span class="o">/</span><span class="mi">255</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="n">samples</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[:</span><span class="n">samples</span><span class="p">]</span>

<span class="n">utility</span> <span class="o">=</span> <span class="n">Utility</span><span class="p">()</span>

<span class="c1"># train validation split</span>
<span class="n">X_train_new</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train_new</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">utility</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">Y_1hot_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">utility</span><span class="o">.</span><span class="n">onehot</span><span class="p">(</span><span class="n">y_train_new</span><span class="p">)</span>

<span class="n">input_shape</span> <span class="o">=</span> <span class="n">X_train_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="n">Y_1hot_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">input_shape</span><span class="p">,</span> <span class="n">output_dim</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((1, 28, 28), 10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation_type</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Pooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">activation_type</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: CNN
--------------------------------------------------------------------------------------
Layer (type)                                 Output Shape              # of Parameters
======================================================================================
input_1 (Input)                              (None, 3, 32, 32)         0              
--------------------------------------------------------------------------------------
conv2d_1 (Conv2D)                            (None, 32, 32, 32)        2432           
--------------------------------------------------------------------------------------
pooling2d_1 (Pooling2D)                      (None, 32, 16, 16)        0              
--------------------------------------------------------------------------------------
flatten_1 (Flatten)                          (None, 8192)              0              
--------------------------------------------------------------------------------------
dropout_1 (Dropout)                          (None, 8192)              0              
--------------------------------------------------------------------------------------
dense_1 (Dense)                              (None, 10)                81930          
======================================================================================
Total params: 84362
Trainable params: 84362
Non-trainable params: 0
--------------------------------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">cost_type</span><span class="o">=</span><span class="s2">&quot;cross-entropy&quot;</span><span class="p">,</span> <span class="n">optimizer_type</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LR_decay</span> <span class="o">=</span> <span class="n">LearningRateDecay</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_new</span><span class="p">,</span> <span class="n">Y_1hot_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_val</span><span class="o">=</span><span class="n">X_val</span><span class="p">,</span> 
          <span class="n">y_val</span><span class="o">=</span><span class="n">y_val</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="n">LR_decay</span><span class="o">.</span><span class="n">constant</span><span class="p">,</span> <span class="n">lr_0</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 1/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [06:06&lt;00:00, 22.88s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 2.2061 - Training Accuracy: 0.3025 - Validation Loss: 1.6472 - Validation Accuracy: 0.454

Epoch: 2/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:43&lt;00:00, 21.45s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 1.3552 - Training Accuracy: 0.535 - Validation Loss: 1.121 - Validation Accuracy: 0.648

Epoch: 3/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:36&lt;00:00, 21.02s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 1.0117 - Training Accuracy: 0.6577 - Validation Loss: 0.9004 - Validation Accuracy: 0.694

Epoch: 4/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:50&lt;00:00, 21.88s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.7985 - Training Accuracy: 0.727 - Validation Loss: 0.7702 - Validation Accuracy: 0.751

Epoch: 5/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:30&lt;00:00, 20.66s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.6912 - Training Accuracy: 0.766 - Validation Loss: 0.677 - Validation Accuracy: 0.77

Epoch: 6/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:33&lt;00:00, 20.87s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.6056 - Training Accuracy: 0.7988 - Validation Loss: 0.6384 - Validation Accuracy: 0.799

Epoch: 7/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:35&lt;00:00, 20.99s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.5665 - Training Accuracy: 0.81 - Validation Loss: 0.572 - Validation Accuracy: 0.806

Epoch: 8/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:30&lt;00:00, 20.68s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.5072 - Training Accuracy: 0.8355 - Validation Loss: 0.5284 - Validation Accuracy: 0.839

Epoch: 9/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:31&lt;00:00, 20.73s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.4754 - Training Accuracy: 0.8448 - Validation Loss: 0.5172 - Validation Accuracy: 0.843

Epoch: 10/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 16/16 [05:31&lt;00:00, 20.73s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.4364 - Training Accuracy: 0.8615 - Validation Loss: 0.501 - Validation Accuracy: 0.853
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">loss_plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/cnn_from_scratch_38_0.png" src="../../_images/cnn_from_scratch_38_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">accuracy_plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/cnn_from_scratch_39_0.png" src="../../_images/cnn_from_scratch_39_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[403,   0,   6,   5,   3,  10,  11,   1,  13,   8],
       [  0, 547,   5,   3,   3,   3,   3,   1,   6,   0],
       [  7,  14, 401,  36,   6,   7,   6,  15,  37,   1],
       [  1,   6,  15, 387,   1,  37,   5,  20,  23,   5],
       [  2,   2,   4,   0, 418,   2,   8,   8,   8,  48],
       [ 12,   4,   6,  38,  10, 304,  11,  10,  51,  10],
       [ 11,  10,  15,   1,  12,  22, 383,   1,   7,   0],
       [  1,  10,  18,  12,  11,   1,   0, 415,   4,  40],
       [ 10,   7,  13,  31,  20,  26,   2,  11, 350,  19],
       [  2,   5,   4,   9,  47,   7,   2,  25,  11, 408]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error Rate =&#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">acc</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy =&#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">((</span><span class="n">acc</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Error Rate = 19.68
Accuracy = 80.32
</pre></div>
</div>
</div>
</div>
<p>Losses are converging and with more complex model (along with more time complexity), we can achieve very high accuracy on <strong>MNIST</strong>. But for now, the model is working as expected!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/convolutional_neural_networks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="pooling_layers.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">3.2.4. Pooling layers</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="cnn_pytorch.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3.4. 4 step process to build a CNN model using PyTorch</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ujjwal Khandelwal<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>