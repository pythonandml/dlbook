
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>1.2. Performance Metrics for ML and DL models &#8212; Oddly Satisfying Deep Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2.1. Activation Functions" href="../multilayer_perceptrons/activation.html" />
    <link rel="prev" title="1.1. Data Preprocessing" href="data_preprocessing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Oddly Satisfying Deep Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  1. Preliminaries
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="data_preprocessing.html">
   1.1. Data Preprocessing
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1.2. Performance Metrics for ML and DL models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  2. Multilayer Perceptrons
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/activation.html">
   2.1. Activation Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/perceptron.html">
   2.2. Perceptron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/terminologies_part_1.html">
   2.3. Terminologies Part-1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/cost_functions.html">
   2.4. Cost functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/forward_propagation.html">
   2.5. Forward propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/backpropagation.html">
   2.6. Back Propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/terminologies_part_2.html">
   2.7. Terminologies Part-2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/gradient_descent.html">
   2.8. Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/regularization.html">
   2.9. Regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/dropout.html">
   2.10. Dropout regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/batch_normalization.html">
   2.11. Batch Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/numerical_example_forward_backward_propagation.html">
   2.12. Numerical example Forward and Back pass
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/shortcut_to_calculate_forward_back_propagation.html">
   2.13. Shortcut to calculate forward pass and backpropagation across layers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/neural_networks_mlp_scratch_best.html">
   2.14. MLP model from scratch in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/mlp_pytorch.html">
   2.15. 4 step process to build MLP model using PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multilayer_perceptrons/mlp_keras.html">
   2.16. MLP model using Tensorflow - Keras
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  3. Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../convolutional_neural_networks/cnn_over_mlp.html">
   3.1. Convolutional Neural Networks over MLP
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../convolutional_neural_networks/cnn_architecture.html">
   3.2. Basic Architecture of CNN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../convolutional_neural_networks/convolutional_layers.html">
     3.2.1. Convolutional layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../convolutional_neural_networks/forward_propagation_convolution.html">
     3.2.2 Forward Propagation Convolution layer (Vectorized)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../convolutional_neural_networks/backpropagation_convolution.html">
     3.2.3 Backward Propagation Convolution layer (Vectorized)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../convolutional_neural_networks/pooling_layers.html">
     3.2.4. Pooling layers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../convolutional_neural_networks/cnn_from_scratch.html">
   3.3. Convolutional Neural Networks from scratch in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../convolutional_neural_networks/cnn_pytorch.html">
   3.4. 4 step process to build a CNN model using PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../convolutional_neural_networks/cnn_keras.html">
   3.5. CNN model using Tensorflow - Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../convolutional_neural_networks/cnn_state_of_the_art.html">
   3.6. State of the art CNN models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  4. Word Embeddings
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../word_embeddings/traditional_word_embeddings.html">
   4.1. Traditional Word Embeddings
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../word_embeddings/static_word_embeddings.html">
   4.2. Static Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/word2vec.html">
     4.2.1. Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/glove.html">
     4.2.2 GloVe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/fasttext.html">
     4.2.3. FastText
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../word_embeddings/contextual_word_embeddings.html">
   4.3. Contextual Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../word_embeddings/elmo.html">
     4.3.1. Embeddings from Language Models (ELMo)
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/pythonandml/dlbook/master?urlpath=tree/content/preliminaries/performance_metrics.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/pythonandml/dlbook/blob/master/content/preliminaries/performance_metrics.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/pythonandml/dlbook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/pythonandml/dlbook/issues/new?title=Issue%20on%20page%20%2Fcontent/preliminaries/performance_metrics.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/content/preliminaries/performance_metrics.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-we-require-evaluation-metrics">
   Why We require Evaluation Metrics?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-evaluation-metrics-for-regression">
   A) Evaluation Metrics for Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-absolute-error-mae">
     1) Mean Absolute Error (MAE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-absolute-percentage-error-mape">
     2) Mean Absolute Percentage Error (MAPE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-mse">
     3) Mean Squared Error (MSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#root-mean-squared-error-rmse">
     4) Root Mean Squared Error (RMSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#coefficient-of-determination-r-squared-or-r-2">
     5) Coefficient of Determination (R-squared or
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
     )**
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#y-actual-output">
     y = actual output
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hat-y-predicted-output">
     <span class="math notranslate nohighlight">
      \(\hat y\)
     </span>
     = predicted output
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bar-y-mean-value-of-y">
     <span class="math notranslate nohighlight">
      \(\bar y\)
     </span>
     = mean value of y
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-number-of-samples-or-data-points">
     n = number of samples or data points
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adjusted-r-squared">
     6) Adjusted R-squared
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-2-r-squared-value">
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
     = R-squared value
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     n = number of samples or data points
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-number-of-independent-variables-or-number-of-predictors-features">
     k = number of independent variables or number of predictors/ features
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#b-evaluation-metrics-for-classification">
   B) Evaluation Metrics for Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix">
   1) Confusion Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-does-the-confusion-matrix-look-like">
   How does the confusion matrix look like?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix-for-binary-classification">
   Confusion matrix for Binary Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example">
     Example
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#true-positive-tp">
   True Positive (TP)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#true-negative-tn">
   True Negative (TN)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#false-positive-fp-type-1-error">
   False Positive (FP, Type 1 Error)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#false-negative-fn-type-2-error">
   False Negative (FN, Type 2 Error)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix-for-multiclass-classification">
   Confusion Matrix for Multiclass Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tp-tn-fp-fn-values-using-numpy-and-pandas">
     TP, TN, FP, FN values using numpy and pandas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#well-known-performance-metrics-calculated-using-tp-tn-fp-and-fn">
   Well known performance metrics calculated using TP, TN, FP and FN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy">
     1) Accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-accuracy-for-each-class">
     a) Accuracy for each class
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-global-accuracy">
     b) Global Accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     2) Precision
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     3) Recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specificity">
     4) Specificity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fall-out-or-false-positive-rate-fpr-and-false-negative-rate-fnr">
     5) Fall out or False Positive Rate (FPR) and False Negative Rate (FNR)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f1-score">
     6) F1-score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#micro-scores-micro-precision-recall-and-f1">
     7) Micro scores (Micro Precision, Recall and F1)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#macro-scores-macro-precision-recall-and-f1">
     8) Macro scores (Macro Precision, Recall and F1)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weighted-scores-weighted-precision-recall-and-f1">
     9) Weighted scores (Weighted Precision, Recall and F1)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confirming-the-values-using-sklearn-s-classification-report">
   Confirming the values using sklearn’s classification report
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f-beta-score">
     10) F-beta score
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confirm-using-sklearn-s-fbeta-score-metric">
   Confirm using sklearn’s fbeta_score metric
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cohen-s-kappa-statistic">
     <strong>
      11) Cohen’s kappa statistic
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confirm-the-same-using-sklearn-s-cohen-kappa-score">
   Confirm the same using Sklearn’s cohen_kappa_score
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-the-same-on-3-classes">
   Testing the same on 3-classes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jaccard-similarity-index">
     12) Jaccard Similarity Index
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matthews-correlation-coefficient-mcc">
     13) Matthew’s correlation coefficient (MCC)
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>1.2. Performance Metrics for ML and DL models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-we-require-evaluation-metrics">
   Why We require Evaluation Metrics?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-evaluation-metrics-for-regression">
   A) Evaluation Metrics for Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-absolute-error-mae">
     1) Mean Absolute Error (MAE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-absolute-percentage-error-mape">
     2) Mean Absolute Percentage Error (MAPE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-mse">
     3) Mean Squared Error (MSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#root-mean-squared-error-rmse">
     4) Root Mean Squared Error (RMSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#coefficient-of-determination-r-squared-or-r-2">
     5) Coefficient of Determination (R-squared or
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
     )**
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#y-actual-output">
     y = actual output
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hat-y-predicted-output">
     <span class="math notranslate nohighlight">
      \(\hat y\)
     </span>
     = predicted output
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bar-y-mean-value-of-y">
     <span class="math notranslate nohighlight">
      \(\bar y\)
     </span>
     = mean value of y
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-number-of-samples-or-data-points">
     n = number of samples or data points
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adjusted-r-squared">
     6) Adjusted R-squared
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-2-r-squared-value">
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
     = R-squared value
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     n = number of samples or data points
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-number-of-independent-variables-or-number-of-predictors-features">
     k = number of independent variables or number of predictors/ features
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#b-evaluation-metrics-for-classification">
   B) Evaluation Metrics for Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix">
   1) Confusion Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-does-the-confusion-matrix-look-like">
   How does the confusion matrix look like?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix-for-binary-classification">
   Confusion matrix for Binary Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example">
     Example
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#true-positive-tp">
   True Positive (TP)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#true-negative-tn">
   True Negative (TN)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#false-positive-fp-type-1-error">
   False Positive (FP, Type 1 Error)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#false-negative-fn-type-2-error">
   False Negative (FN, Type 2 Error)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix-for-multiclass-classification">
   Confusion Matrix for Multiclass Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tp-tn-fp-fn-values-using-numpy-and-pandas">
     TP, TN, FP, FN values using numpy and pandas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#well-known-performance-metrics-calculated-using-tp-tn-fp-and-fn">
   Well known performance metrics calculated using TP, TN, FP and FN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy">
     1) Accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-accuracy-for-each-class">
     a) Accuracy for each class
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-global-accuracy">
     b) Global Accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     2) Precision
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     3) Recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specificity">
     4) Specificity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fall-out-or-false-positive-rate-fpr-and-false-negative-rate-fnr">
     5) Fall out or False Positive Rate (FPR) and False Negative Rate (FNR)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f1-score">
     6) F1-score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#micro-scores-micro-precision-recall-and-f1">
     7) Micro scores (Micro Precision, Recall and F1)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#macro-scores-macro-precision-recall-and-f1">
     8) Macro scores (Macro Precision, Recall and F1)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weighted-scores-weighted-precision-recall-and-f1">
     9) Weighted scores (Weighted Precision, Recall and F1)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confirming-the-values-using-sklearn-s-classification-report">
   Confirming the values using sklearn’s classification report
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f-beta-score">
     10) F-beta score
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confirm-using-sklearn-s-fbeta-score-metric">
   Confirm using sklearn’s fbeta_score metric
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cohen-s-kappa-statistic">
     <strong>
      11) Cohen’s kappa statistic
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confirm-the-same-using-sklearn-s-cohen-kappa-score">
   Confirm the same using Sklearn’s cohen_kappa_score
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-the-same-on-3-classes">
   Testing the same on 3-classes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jaccard-similarity-index">
     12) Jaccard Similarity Index
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matthews-correlation-coefficient-mcc">
     13) Matthew’s correlation coefficient (MCC)
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="performance-metrics-for-ml-and-dl-models">
<h1>1.2. Performance Metrics for ML and DL models<a class="headerlink" href="#performance-metrics-for-ml-and-dl-models" title="Permalink to this headline">#</a></h1>
<section id="why-we-require-evaluation-metrics">
<h2>Why We require Evaluation Metrics?<a class="headerlink" href="#why-we-require-evaluation-metrics" title="Permalink to this headline">#</a></h2>
<p>Any model in real world cannot have 100% efficiency otherwise the model is known as a biased model. Although it is necessary to obtain the accuracy on training data, it is also important to get a genuine and approximate result on unseen data otherwise Model is of no use.</p>
<p>So to build and deploy a generalized model we require to Evaluate the model on different metrics which helps us to better optimize the performance, fine-tune it, and obtain a better result. So, let’s start exploring different Evaluation metrics.</p>
</section>
<section id="a-evaluation-metrics-for-regression">
<h2>A) Evaluation Metrics for Regression<a class="headerlink" href="#a-evaluation-metrics-for-regression" title="Permalink to this headline">#</a></h2>
<p>Suppose we have the actual (<span class="math notranslate nohighlight">\(y\)</span>) and the predicted (<span class="math notranslate nohighlight">\(\hat{y}\)</span>) values of the target variable <span class="math notranslate nohighlight">\(y\)</span> (from any model) and we want to evaluate it using different metrics</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">9</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<section id="mean-absolute-error-mae">
<h3>1) Mean Absolute Error (MAE)<a class="headerlink" href="#mean-absolute-error-mae" title="Permalink to this headline">#</a></h3>
<p>MAE is a very simple metric which calculates the absolute difference between actual and predicted values. Basically, sum all the errors and divide them by a total number of observations and this is MAE.</p>
<p><img alt="" src="../../_images/mae.jpeg" /></p>
<p><strong>Advantages of MAE</strong></p>
<ul class="simple">
<li><p>The MAE you get is in the same unit as the output variable</p></li>
<li><p>It is most Robust to outliers</p></li>
</ul>
<p><strong>Disadvantages of MAE</strong></p>
<ul class="simple">
<li><p>The graph of MAE is not differentiable so we have to apply various optimizers like Gradient descent</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">mae</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    <span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actual</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">actual</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAE =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mae</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">),</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MAE = 0.833
</pre></div>
</div>
</div>
</div>
</section>
<section id="mean-absolute-percentage-error-mape">
<h3>2) Mean Absolute Percentage Error (MAPE)<a class="headerlink" href="#mean-absolute-percentage-error-mape" title="Permalink to this headline">#</a></h3>
<p>MAPE is the mean absolute percentage error, which is a relative measure that essentially scales MAE to be in percentage units instead of the variable’s units.</p>
<p><img alt="" src="../../_images/mape.png" /></p>
<p><strong>Advantages of MAPE</strong></p>
<ul class="simple">
<li><p>It is one of the most widely used measures of forecast accuracy, due to its advantages of <strong>scale-independency</strong> and <strong>interpretability</strong>.</p></li>
</ul>
<p><strong>Disadvantages of MAPE</strong></p>
<ul class="simple">
<li><p>It has the significant disadvantage that it produces infinite or undefined values for zero or close-to-zero actual values</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">mape</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    <span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actual</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">)</span><span class="o">/</span><span class="n">actual</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MAPE =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mape</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">),</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MAPE = 0.222
</pre></div>
</div>
</div>
</div>
</section>
<section id="mean-squared-error-mse">
<h3>3) Mean Squared Error (MSE)<a class="headerlink" href="#mean-squared-error-mse" title="Permalink to this headline">#</a></h3>
<p>MSE is a most used and very simple metric with a little bit of change in mean absolute error. Mean squared error states that finding the squared difference between actual and predicted value.</p>
<p><img alt="" src="../../_images/mse.png" /></p>
<p><strong>Advantages of MSE</strong></p>
<ul class="simple">
<li><p>The graph of MSE is differentiable, so you can easily use it as a loss function</p></li>
</ul>
<p><strong>Disadvantages of MSE</strong></p>
<ul class="simple">
<li><p>The value you get after calculating MSE is a squared unit of output. for example, the output variable is in meter(m) then after calculating MSE the output we get is in meter squared</p></li>
<li><p>If you have outliers in the dataset then it penalizes the outliers most and the calculated MSE is bigger. So, in short, It is not robust to outliers which were an advantage in MAE</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    <span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actual</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mse</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">),</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MSE = 1.833
</pre></div>
</div>
</div>
</div>
</section>
<section id="root-mean-squared-error-rmse">
<h3>4) Root Mean Squared Error (RMSE)<a class="headerlink" href="#root-mean-squared-error-rmse" title="Permalink to this headline">#</a></h3>
<p>As the name itself suggests, RMSE is simply the square root of MSE</p>
<p><img alt="" src="../../_images/rmse.png" /></p>
<p><strong>Advantages of RMSE</strong></p>
<ul class="simple">
<li><p>The output value you get is in the same unit as the required output variable which makes interpretation of loss easy.</p></li>
</ul>
<p><strong>Disadvantages of MSE</strong></p>
<ul class="simple">
<li><p>It is also not that robust to outliers as compared to MAE.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    <span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actual</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RMSE =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">),</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSE = 1.354
</pre></div>
</div>
</div>
</div>
</section>
<section id="coefficient-of-determination-r-squared-or-r-2">
<h3>5) Coefficient of Determination (R-squared or <span class="math notranslate nohighlight">\(R^2\)</span>)**<a class="headerlink" href="#coefficient-of-determination-r-squared-or-r-2" title="Permalink to this headline">#</a></h3>
<p>Coefficient of Determination or R-squared value measures the strength of the relationship between your linear model and the dependent variables on a 0 - 1 scale. It represents the proportion of the variance for a dependent variable that’s explained by an independent variable.</p>
<div class="math notranslate nohighlight">
\[
R^2 = 1-\frac{\sum_{i=1}^{n}(y_i-\hat y_i )^2}{\sum_{i=1}^{n}(y_i-\bar y)^2}
\]</div>
</section>
<section id="y-actual-output">
<h3>y = actual output<a class="headerlink" href="#y-actual-output" title="Permalink to this headline">#</a></h3>
</section>
<section id="hat-y-predicted-output">
<h3><span class="math notranslate nohighlight">\(\hat y\)</span> = predicted output<a class="headerlink" href="#hat-y-predicted-output" title="Permalink to this headline">#</a></h3>
</section>
<section id="bar-y-mean-value-of-y">
<h3><span class="math notranslate nohighlight">\(\bar y\)</span> = mean value of y<a class="headerlink" href="#bar-y-mean-value-of-y" title="Permalink to this headline">#</a></h3>
</section>
<section id="n-number-of-samples-or-data-points">
<h3>n = number of samples or data points<a class="headerlink" href="#n-number-of-samples-or-data-points" title="Permalink to this headline">#</a></h3>
<p><strong><font color='darkgreen'>How to interpret <span class="math notranslate nohighlight">\(R^2\)</span> value</font></strong></p>
<p>Now if this <span class="math notranslate nohighlight">\(R^2\)</span> score is 0, then there is no correlation between <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(\hat y\)</span> and if it is 1, then we have 100% correlation between these values (best model).</p>
<p>The normal case is when the <span class="math notranslate nohighlight">\(R^2\)</span> score is between 0 and 1 like 0.8 which means our model is capable to explain 80% variation for a dependent variable by an independent variable.</p>
<p><strong>Note:</strong> Negative values of <span class="math notranslate nohighlight">\(𝑅^2\)</span> may occur when fitting non-linear functions to data. In cases where negative values arise, the mean of the data provides a better fit to the outcomes than do the fitted function values, according to this particular criterion.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    <span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actual</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="n">rss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">tss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">actual</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="n">rss</span><span class="o">/</span><span class="n">tss</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2 score =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">),</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2 score = 0.371
</pre></div>
</div>
</div>
</div>
</section>
<section id="adjusted-r-squared">
<h3>6) Adjusted R-squared<a class="headerlink" href="#adjusted-r-squared" title="Permalink to this headline">#</a></h3>
<p>The disadvantage of the <span class="math notranslate nohighlight">\(R^2\)</span> score is that while adding new features in data the <span class="math notranslate nohighlight">\(R^2\)</span> score starts increasing or remains constant but it never decreases because It assumes that while adding more data, variance of data increases.</p>
<p>But when we add an irrelevant feature in the dataset then at that time <span class="math notranslate nohighlight">\(R^2\)</span> sometimes starts increasing which is incorrect.</p>
<p>Hence, to control this situation Adjusted R-Squared <span class="math notranslate nohighlight">\(R_a^2\)</span> came into existence.</p>
<div class="math notranslate nohighlight">
\[
R_a^2 = 1-\frac{(1-R^2)(n-1)}{(n-k-1)}
\]</div>
</section>
<section id="r-2-r-squared-value">
<h3><span class="math notranslate nohighlight">\(R^2\)</span> = R-squared value<a class="headerlink" href="#r-2-r-squared-value" title="Permalink to this headline">#</a></h3>
</section>
<section id="id1">
<h3>n = number of samples or data points<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
</section>
<section id="k-number-of-independent-variables-or-number-of-predictors-features">
<h3>k = number of independent variables or number of predictors/ features<a class="headerlink" href="#k-number-of-independent-variables-or-number-of-predictors-features" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">adjusted_r2_score</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">R2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">),</span> <span class="mi">3</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;adjusted R2 score =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">adjusted_r2_score</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>adjusted R2 score = -0.571
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="b-evaluation-metrics-for-classification">
<h2>B) Evaluation Metrics for Classification<a class="headerlink" href="#b-evaluation-metrics-for-classification" title="Permalink to this headline">#</a></h2>
</section>
<section id="confusion-matrix">
<h2>1) Confusion Matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">#</a></h2>
<p>Confusion matrix is a table with combinations of predicted and actual values. It is a matrix that compares the number of predictions for each class that are correct and those that are incorrect.</p>
<p>The confusion matrix is a <strong>N x N matrix</strong>, where <font color='blue'>N is the number of classes</font> or outputs.</p>
<p>For 2 class, we get 2 x 2 confusion matrix.</p>
<p>For 3 class, we get 3 X 3 confusion matrix.</p>
<p>In a confusion matrix, there are 4 numbers to pay attention which are <strong>True Positive(TP), False Positive(FP), True Negative(TN) and False Negative(FN)</strong>.</p>
</section>
<section id="how-does-the-confusion-matrix-look-like">
<h2>How does the confusion matrix look like?<a class="headerlink" href="#how-does-the-confusion-matrix-look-like" title="Permalink to this headline">#</a></h2>
<p>Below is the representation of the confusion matrix.</p>
<p><img alt="" src="../../_images/cm.jpeg" /></p>
</section>
<section id="confusion-matrix-for-binary-classification">
<h2>Confusion matrix for Binary Classification<a class="headerlink" href="#confusion-matrix-for-binary-classification" title="Permalink to this headline">#</a></h2>
<p>Let us understand the confusion matrix for a <strong>simple binary classification example</strong>.</p>
<p>Binary classification has 2 outputs, the inputs for this classification will fall in either of the 2 outputs or classes. Let us see how to construct a confusion matrix and understand its terminologies.</p>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline">#</a></h3>
<p>Consider we have to model a classifier that classifies 2 kinds of fruits.</p>
<p>Suppose have <strong><font color='black'>2 types of fruits Apples and Grapes</font></strong> and we want our machine learning model to identify or classify the given fruit as an Apple or Grape.</p>
<p>Assume we take <strong>15 samples</strong>, out of which <strong><font color='red'>8 belong to Apples</font></strong> and <strong><font color='green'>7 belong to the Grapes</font></strong>. We will <strong>represent Apple as 1</strong> (we can also call it as <em>Negative class</em>) and <strong>Grape as 0</strong> (we can also call it as <em>Positive class</em>).</p>
<p>Let the actual class for 8 apples and 7 grapes, be represented as</p>
<p><font color='blue'>actual = [1,1,1,1,1,1,1,1,0,0,0,0,0,0,0]</font></p>
<p>Assume that the <strong>classifier</strong> takes all the 15 inputs and, makes the following <strong>predictions</strong>:</p>
<ul class="simple">
<li><p>Out of <strong><font color='red'>8 Apples</font></strong>, it will classify <strong><font color='red'>5 correctly as Apples</font></strong> and <strong><font color='green'>wrongly predict 3 as grapes</font></strong></p></li>
<li><p>Out of <strong><font color='green'>7 grapes</font></strong>, it will classify <strong><font color='green'>5 correctly as grapes</font></strong> and <strong><font color='red'>wrongly predicts 2 as apples</font></strong></p></li>
</ul>
<p>The prediction of the classifier may be as follows:</p>
<p><font color='blue'>predicted = [1,0,0,0,1,1,1,1,0,0,0,0,0,1,1]</font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">label_name</span><span class="p">,</span> <span class="n">margins</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
    <span class="n">df_confusion</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">],</span> <span class="n">margins</span><span class="o">=</span><span class="n">margins</span><span class="p">)</span>
    <span class="n">df_confusion</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">label_name</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">label_name</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df_confusion</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_name</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;Grapes&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Apples&#39;</span><span class="p">}</span>
<span class="n">actual</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_confusion</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">label_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">df_confusion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix
</pre></div>
</div>
<div class="output text_html">
  <div id="df-f7b82903-453a-41d7-8d4c-bc79540dfdf6">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Predicted</th>
      <th>Grapes</th>
      <th>Apples</th>
    </tr>
    <tr>
      <th>Actual</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Grapes</th>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Apples</th>
      <td>3</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-f7b82903-453a-41d7-8d4c-bc79540dfdf6')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-f7b82903-453a-41d7-8d4c-bc79540dfdf6 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-f7b82903-453a-41d7-8d4c-bc79540dfdf6');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
</section>
<section id="true-positive-tp">
<h2>True Positive (TP)<a class="headerlink" href="#true-positive-tp" title="Permalink to this headline">#</a></h2>
<p>We predicted positive class (here grapes) and the actual class is also grape. So, from the above example, <strong>TP=5</strong></p>
</section>
<section id="true-negative-tn">
<h2>True Negative (TN)<a class="headerlink" href="#true-negative-tn" title="Permalink to this headline">#</a></h2>
<p>We predicted negative class (here an apple) and the actual class is also an apple. So, from the above example, <strong>TN=5</strong></p>
</section>
<section id="false-positive-fp-type-1-error">
<h2>False Positive (FP, Type 1 Error)<a class="headerlink" href="#false-positive-fp-type-1-error" title="Permalink to this headline">#</a></h2>
<p>We predicted positive class (grape) and it is <strong>false</strong>, the actual class is an apple (negative class). So, from the above example, <strong>FP=3</strong></p>
</section>
<section id="false-negative-fn-type-2-error">
<h2>False Negative (FN, Type 2 Error)<a class="headerlink" href="#false-negative-fn-type-2-error" title="Permalink to this headline">#</a></h2>
<p>We predicted negative class (apple) and it is false, the actual class is a grape (positive class). So, from the above example, <strong>FN=2</strong></p>
</section>
<section id="confusion-matrix-for-multiclass-classification">
<h2>Confusion Matrix for Multiclass Classification<a class="headerlink" href="#confusion-matrix-for-multiclass-classification" title="Permalink to this headline">#</a></h2>
<p>In the multi-class classification problem, we won’t get TP, TN, FP, and FN values directly as in the binary classification problem. We need to calculate them separately for each class and this makes sense as well (if we have properly understood the definitions of these terms).</p>
<p><strong>FN</strong>: The False-negative value for a class will be the sum of values of corresponding rows except for the TP value.</p>
<p><strong>FP</strong>: The False-positive value for a class will be the sum of values of the corresponding column except for the TP value.</p>
<p><strong>TN</strong>: The True Negative value for a class will be the sum of values of all columns and rows except the values of that class that we are calculating the values for (because we are not bothered with any other class except for the class in consideration).</p>
<p><strong>TP</strong>: The True positive value is where the actual value and predicted value are the same.</p>
<p>Consider the table below showing TP, TN, FP, and FN values for class-0 (where we have 3 classes namely <strong>class-0</strong>, <strong>class-1</strong> and <strong>class-2</strong>)</p>
<p><img alt="" src="../../_images/tpfp.png" /></p>
<section id="tp-tn-fp-fn-values-using-numpy-and-pandas">
<h3>TP, TN, FP, FN values using numpy and pandas<a class="headerlink" href="#tp-tn-fp-fn-values-using-numpy-and-pandas" title="Permalink to this headline">#</a></h3>
<p>Consider the following actual and predicted values</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">CM_parameters</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">):</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">cnf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">)</span>  
    <span class="n">FN</span> <span class="o">=</span> <span class="n">cnf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">)</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">)</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">cnf_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TP</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">TN</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">FP</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">FN</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example</span>

<span class="n">actual</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">label_name</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;Class-0&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Class-1&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Class-2&#39;</span><span class="p">}</span>

<span class="n">df_confusion</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">label_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">df_confusion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion Matrix
</pre></div>
</div>
<div class="output text_html">
  <div id="df-bd632939-ca8e-4665-bcea-8a9e998c40e3">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Predicted</th>
      <th>Class-0</th>
      <th>Class-1</th>
      <th>Class-2</th>
    </tr>
    <tr>
      <th>Actual</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Class-0</th>
      <td>2</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Class-1</th>
      <td>3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Class-2</th>
      <td>1</td>
      <td>3</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-bd632939-ca8e-4665-bcea-8a9e998c40e3')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-bd632939-ca8e-4665-bcea-8a9e998c40e3 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-bd632939-ca8e-4665-bcea-8a9e998c40e3');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">df_confusion</span><span class="o">.</span><span class="n">values</span>
<span class="n">TP</span><span class="p">,</span> <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span> <span class="o">=</span> <span class="n">CM_parameters</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TP</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2., 1., 1.])
</pre></div>
</div>
</div>
</div>
<p>So, for <strong>class-0</strong>, TP is 2, for <strong>class-1</strong>, TP is 1 and for <strong>class-2</strong> also, TP = 1. Similarly we get TN, FP and FN values</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TN</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([6., 7., 8.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FP</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([4., 5., 4.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FN</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([5., 4., 4.])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="well-known-performance-metrics-calculated-using-tp-tn-fp-and-fn">
<h2>Well known performance metrics calculated using TP, TN, FP and FN<a class="headerlink" href="#well-known-performance-metrics-calculated-using-tp-tn-fp-and-fn" title="Permalink to this headline">#</a></h2>
<section id="accuracy">
<h3>1) Accuracy<a class="headerlink" href="#accuracy" title="Permalink to this headline">#</a></h3>
<p>Accuracy simply measures how often the classifier correctly predicts. We can define accuracy as the ratio of the number of correct predictions and the total number of predictions. We can calculate accuracy both globally (for the entire model) and individually for each class.</p>
<p><strong>Note:</strong> Let us assume we have <strong><font color='red'>C</font></strong> number of classes and number of samples or data points is <strong><font color='red'>N</font></strong></p>
</section>
<section id="a-accuracy-for-each-class">
<h3>a) Accuracy for each class<a class="headerlink" href="#a-accuracy-for-each-class" title="Permalink to this headline">#</a></h3>
<div class="math notranslate nohighlight">
\[
Accuracy = \frac{TP+TN}{TP+TN+FP+FN}
\]</div>
<br>
</section>
<section id="b-global-accuracy">
<h3>b) Global Accuracy<a class="headerlink" href="#b-global-accuracy" title="Permalink to this headline">#</a></h3>
<div class="math notranslate nohighlight">
\[
Accuracy_g = \frac{\sum_{i=1}^{C} TP_i}{N}
\]</div>
<br>
<p>When any model gives an accuracy rate of 99%, you might think that model is performing very good but this is not always true and can be misleading in some situations.</p>
<p>Accuracy is useful when the output class is <strong>well balanced</strong> but is not a good choice for the <strong>imbalanced data</strong>. Imagine the scenario where we have <font color='blue'>98 images of the dog</font> and only <font color='green'>2 images of a cat</font> present in our training data. If our model predicted all the images as dogs, then our model achieved <strong>98% accuracy</strong> which is mis-leading.</p>
<p>Hence, if we want to do a better model evaluation and have a full picture of the model evaluation, other metrics such as recall, precision, etc should also be considered.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for each class = [0.471 0.471 0.529]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">TP</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Global Accuracy =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">accuracy_g</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Global Accuracy = 0.235
</pre></div>
</div>
</div>
</div>
</section>
<section id="precision">
<h3>2) Precision<a class="headerlink" href="#precision" title="Permalink to this headline">#</a></h3>
<p>It tells you what fraction of predictions as a positive class were actually positive. Precision is useful in the cases where <strong>False Positive is a higher concern than False Negatives</strong>. It is also known as <strong>Positive Predictive Value</strong></p>
<p>The importance of Precision is in music or video recommendation systems, e-commerce websites, etc. where wrong results could lead to customer churn and this could be harmful to the business.</p>
<div class="math notranslate nohighlight">
\[
Precision = \frac{TP}{TP+FP}
\]</div>
<br>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precision for each class = [0.333 0.167 0.2  ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="recall">
<h3>3) Recall<a class="headerlink" href="#recall" title="Permalink to this headline">#</a></h3>
<p>It tells you what fraction of all positive samples were correctly predicted as positive by the classifier. It is also known as <strong>True Positive Rate (TPR), Sensitivity, Probability of Detection and Hit rate</strong>.</p>
<p>It is a useful metric in cases where <strong>False Negative is of higher concern than False Positive</strong>. It is important in medical cases where it doesn’t matter whether we raise a false alarm but the actual positive cases should not go undetected!</p>
<div class="math notranslate nohighlight">
\[
Recall = \frac{TP}{TP+FN}
\]</div>
<br>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recall</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recall for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Recall for each class = [0.286 0.2   0.2  ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="specificity">
<h3>4) Specificity<a class="headerlink" href="#specificity" title="Permalink to this headline">#</a></h3>
<p>It tells you what fraction of all negative samples are correctly predicted as negative by the classifier. It is also known as <strong>True Negative Rate (TNR)</strong>.</p>
<div class="math notranslate nohighlight">
\[
Specificity = \frac{TN}{TN+FP}
\]</div>
<br>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">specificity</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Specificity for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">specificity</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Specificity for each class = [0.6   0.583 0.667]
</pre></div>
</div>
</div>
</div>
</section>
<section id="fall-out-or-false-positive-rate-fpr-and-false-negative-rate-fnr">
<h3>5) Fall out or False Positive Rate (FPR) and False Negative Rate (FNR)<a class="headerlink" href="#fall-out-or-false-positive-rate-fpr-and-false-negative-rate-fnr" title="Permalink to this headline">#</a></h3>
<div class="math notranslate nohighlight">
\[
FPR = \frac{FP}{FP+TN}
\]</div>
<br>
<div class="math notranslate nohighlight">
\[
FNR = \frac{FN}{TP+FN}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FPR</span> <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span><span class="o">+</span><span class="n">TN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Positive Rate for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">FPR</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">FNR</span> <span class="o">=</span> <span class="n">FN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Negative Rate for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">FNR</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False Positive Rate for each class = [0.4   0.417 0.333]
False Negative Rate for each class = [0.714 0.8   0.8  ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="f1-score">
<h3>6) F1-score<a class="headerlink" href="#f1-score" title="Permalink to this headline">#</a></h3>
<p>It gives a combined idea about Precision and Recall metrics. It is maximum when Precision is equal to Recall. F1 Score is the <strong>harmonic mean of precision and recall</strong>. The F1 score punishes extreme values more.</p>
<div class="math notranslate nohighlight">
\[
F1 = \frac{2*Precision*Recall}{Precision+Recall}
\]</div>
<br>
<p>We can <strong>combine the F1-score of each class</strong> to have a single measure for the whole model. There are a few ways to do that, let’s look at them now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">precision</span><span class="o">*</span><span class="n">recall</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span><span class="o">+</span><span class="n">recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1-score for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>F1-score for each class = [0.308 0.182 0.2  ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="micro-scores-micro-precision-recall-and-f1">
<h3>7) Micro scores (Micro Precision, Recall and F1)<a class="headerlink" href="#micro-scores-micro-precision-recall-and-f1" title="Permalink to this headline">#</a></h3>
<p>This is called <strong>micro-averaged score</strong>. It is calculated by considering the total TP, total FP and total FN of the model. It does not consider each class individually, It calculates the metrics globally. So for our example,</p>
<p><strong>Total TP</strong> <span class="math notranslate nohighlight">\(= \sum TP = 2 + 1 + 1 = 4\)</span></p>
<p><strong>Total FP</strong> <span class="math notranslate nohighlight">\(= \sum FP = 4+5+4 = 13\)</span></p>
<p><strong>Total FN</strong> <span class="math notranslate nohighlight">\(= \sum FN = 5+4+4 = 13\)</span></p>
<p>So,</p>
<p><strong>Total Precision</strong> <span class="math notranslate nohighlight">\(= 4/(4+13) = 4/17\)</span></p>
<p><strong>Total Recall</strong> <span class="math notranslate nohighlight">\(= 4/(4+13) = 4/17\)</span></p>
<p>Now we can use the regular formula for F1-score and get the Micro F1-score using the above precision and recall.</p>
<p><strong>Micro-F1</strong> <span class="math notranslate nohighlight">\(= 0.2353\)</span></p>
<p>As you can see When we are calculating the metrics globally all the measures become equal. Also if you calculate accuracy you will see that,</p>
<p><strong>Total Precision = Total Recall = Micro-F1 = Global Accuracy</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Total_TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">TP</span><span class="p">)</span>
<span class="n">Total_FP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">FP</span><span class="p">)</span>
<span class="n">Total_FN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">FN</span><span class="p">)</span>

<span class="n">micro_precision</span> <span class="o">=</span> <span class="n">Total_TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">Total_TP</span> <span class="o">+</span> <span class="n">Total_FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Micro Precision =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">micro_precision</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">micro_recall</span> <span class="o">=</span> <span class="n">Total_TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">Total_TP</span> <span class="o">+</span> <span class="n">Total_FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Micro Recall =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">micro_recall</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">micro_f1</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">micro_precision</span><span class="o">*</span><span class="n">micro_recall</span> <span class="o">/</span> <span class="p">(</span><span class="n">micro_precision</span> <span class="o">+</span> <span class="n">micro_recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Micro F1-score =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">micro_f1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Micro Precision = 0.235
Micro Recall = 0.235
Micro F1-score = 0.235
</pre></div>
</div>
</div>
</div>
</section>
<section id="macro-scores-macro-precision-recall-and-f1">
<h3>8) Macro scores (Macro Precision, Recall and F1)<a class="headerlink" href="#macro-scores-macro-precision-recall-and-f1" title="Permalink to this headline">#</a></h3>
<p>It calculates metrics for each class individually and then takes unweighted mean of the measures. For example if,</p>
<p>Class-0 F1-score = 0.308</p>
<p>Class-1 F1-score = 0.182</p>
<p>Class-2 F1-score = 0.2</p>
<p>Hence,</p>
<p><strong>Macro F1</strong> <span class="math notranslate nohighlight">\(= (0.308+0.182+0.2)/3 = 0.23\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">macro_precision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Macro Precision =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">macro_precision</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">macro_recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Macro Recall =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">macro_recall</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">macro_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Macro F1-score =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">macro_f1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Macro Precision = 0.233
Macro Recall = 0.229
Macro F1-score = 0.23
</pre></div>
</div>
</div>
</div>
</section>
<section id="weighted-scores-weighted-precision-recall-and-f1">
<h3>9) Weighted scores (Weighted Precision, Recall and F1)<a class="headerlink" href="#weighted-scores-weighted-precision-recall-and-f1" title="Permalink to this headline">#</a></h3>
<p>Unlike Macro F1, it takes a weighted mean of the measures. The weights for each class are the total number of samples of that class.</p>
<p>Suppose we have <strong>7 Class-0 samples, 5 Class-1 samples and 5 Class-2 samples</strong>, and</p>
<p>Class-0 F1-score = 0.308</p>
<p>Class-1 F1-score = 0.182</p>
<p>Class-2 F1-score = 0.2</p>
<p>Hence,</p>
<p><strong>Weighted F1</strong> <span class="math notranslate nohighlight">\(= ((0.308*7)+(0.182*5)+(0.2*5))/(7+5+5) = 0.24\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_samples</span> <span class="o">=</span> <span class="n">TP</span><span class="o">+</span><span class="n">FN</span>

<span class="n">weighted_precision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="o">*</span><span class="n">precision</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighted Precision =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">weighted_precision</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">weighted_recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="o">*</span><span class="n">recall</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighted Recall =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">weighted_recall</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">weighted_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="o">*</span><span class="n">f1</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighted F1-score =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">weighted_f1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Weighted Precision = 0.245
Weighted Recall = 0.235
Weighted F1-score = 0.239
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="confirming-the-values-using-sklearn-s-classification-report">
<h2>Confirming the values using sklearn’s classification report<a class="headerlink" href="#confirming-the-values-using-sklearn-s-classification-report" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;class-0&#39;</span><span class="p">,</span> <span class="s1">&#39;class-1&#39;</span><span class="p">,</span> <span class="s1">&#39;class-2&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

     class-0       0.33      0.29      0.31         7
     class-1       0.17      0.20      0.18         5
     class-2       0.20      0.20      0.20         5

    accuracy                           0.24        17
   macro avg       0.23      0.23      0.23        17
weighted avg       0.25      0.24      0.24        17
</pre></div>
</div>
</div>
</div>
<p>Perfect! The values turn out to be same</p>
<section id="f-beta-score">
<h3>10) F-beta score<a class="headerlink" href="#f-beta-score" title="Permalink to this headline">#</a></h3>
<p>It measures the effectiveness of retrieval with respect to a user who attaches <span class="math notranslate nohighlight">\(β^2\)</span> times as much importance to recall as precision. That is: <span class="math notranslate nohighlight">\(\mathrm{weight_{Recall}} = \beta^2 \times \mathrm{weight_{Precision}}\)</span>. Check out this <a class="reference external" href="https://stats.stackexchange.com/questions/221997/why-f-beta-score-define-beta-like-that/379474#379474">link</a> for more detail.</p>
<div class="math notranslate nohighlight">
\[
F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{precision} \cdot \mathrm{recall}}{(\beta^2 \cdot \mathrm{precision}) + \mathrm{recall}}
\]</div>
<br>
<p>So, if <strong>β = 1</strong>, equal weights are attached to both:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
F_1 = \frac{1}{\frac{1}{2}\frac{1}{\text{precision}}+\frac{1}{2}\frac{1}{\text{recall}}} \\
= 2\frac{\text{precision}\cdot\text{recall}}{\text{precision}+\text{recall}}
\end{split}\]</div>
<br>
<p>If <strong>β = 2</strong>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
F_2 = \frac{1}{\frac{1}{5}\frac{1}{\text{precision}}+\frac{4}{5}\frac{1}{\text{recall}}} \\
= 5 \cdot\frac{\text{precision}\cdot\text{recall}}{(4 \cdot\text{precision})+\text{recall}}
\end{split}\]</div>
<br><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">beta</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">fbeta</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">precision</span><span class="o">*</span><span class="n">recall</span> <span class="o">/</span> <span class="p">(((</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">precision</span><span class="p">)</span><span class="o">+</span><span class="n">recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F-(beta=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;) score for each class =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">fbeta</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>F-(beta=2) score for each class = [0.294 0.192 0.2  ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">macro_fbeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fbeta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Macro F-(beta=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;) =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">macro_fbeta</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Macro F-(beta=2) = 0.229
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weighted_fbeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="o">*</span><span class="n">fbeta</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighted F-(beta=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;) =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">weighted_fbeta</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Weighted F-(beta=2) = 0.236
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="confirm-using-sklearn-s-fbeta-score-metric">
<h2>Confirm using sklearn’s fbeta_score metric<a class="headerlink" href="#confirm-using-sklearn-s-fbeta-score-metric" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span>

<span class="n">weighted_fbeta_sk</span> <span class="o">=</span> <span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">actual</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">predicted</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sklearn&#39;s Weighted F-(beta=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;) =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">weighted_fbeta_sk</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sklearn&#39;s Weighted F-(beta=2) = 0.236
</pre></div>
</div>
</div>
</div>
<section id="cohen-s-kappa-statistic">
<h3><strong>11) Cohen’s kappa statistic</strong><a class="headerlink" href="#cohen-s-kappa-statistic" title="Permalink to this headline">#</a></h3>
<p>The Kappa statistic (or value) is a metric that compares an <strong>Observed Accuracy</strong> with an <strong>Expected Accuracy</strong> (random chance). The kappa statistic is used not only to evaluate a single classifier, but also to evaluate classifiers amongst themselves.</p>
<p>Cohen’s kappa measures the agreement between <strong>two raters who each classify N items into C mutually exclusive categories</strong>.</p>
<p>Computation of <strong>Observed Accuracy</strong> and <strong>Expected Accuracy</strong> is integral to comprehension of the kappa statistic, and is most easily illustrated through use of a confusion matrix. Lets begin with a simple confusion matrix from a simple binary classification of Apples and Grapes (our original example):</p>
<p><img alt="" src="../../_images/cross_tab.png" /></p>
<p>From the <strong>confusion matrix</strong> we can see there are <strong>15 instances total</strong> (5 + 2 + 3 + 5 = 15). According to the first row <strong>7 were labeled as Grapes</strong> (5 + 2 = 7), and according to the second row <strong>8 were labeled as Apples</strong> (3 + 5 = 8). We can also see that the <strong><font color='green'>model classified 8 instances as Grapes</font></strong> (5 + 3 = 8) and <strong><font color='red'>7 instances as Apples</font></strong> (2 + 5 = 7).</p>
<p>To calculate <strong>Cohen’s kappa</strong>, <strong>Observed Accuracy</strong> and <strong>Expected Accuracy</strong> are required.</p>
<p><strong>Observed Accuracy (OA)</strong></p>
<p>Observed accuracy is simply the <strong>Global Accuracy of the model</strong> which we have mentioned above. Here, <strong>OA = (5+5)/(5+5+2+3) = 10/15= 0.667</strong></p>
<p><strong>Expected Accuracy (EA)</strong></p>
<p>This value is defined as the accuracy that any random classifier would be expected to achieve based on the confusion matrix.</p>
<p><strong>Follow these steps to calculate Expected Accuracy (EA)</strong></p>
<p>In our case, <strong>7 samples were labeled as Grapes</strong> (5 + 2 = 7) which is marginal frequency of ground label, and the <strong><font color='green'>model classified 8 instances as Grapes</font></strong> (5 + 3 = 8) which is marginal frequency of the predicted label.</p>
<p>This results in a value of <strong>3.734</strong> (7 * 8 / Total samples = 7 * 8 / 15 = 3.734) which is <strong>marginal frequency of Grapes</strong>.</p>
<p>This is then done for the second class as well (and can be repeated for each additional class if there are more than 2).</p>
<p>Then <strong>3.734</strong> (8 * 7 / Total samples = 8 * 7 / 15 = 3.734) is the <strong>marginal frequency of Apples</strong>.</p>
<p>The final step is to add all these values together, and finally divide again by the total number of instances, resulting in an <strong>Expected Accuracy (EA) of 0.4977</strong> ((3.734 + 3.734)/15)</p>
<div class="math notranslate nohighlight">
\[
\mathrm{kappa} = \frac{OA-EA}{1-EA}
\]</div>
<br>
<p>So, in our case, the <strong>kappa statistic</strong> equals: (0.667 - 0.4977)/(1 - 0.4977) = <strong>0.3363</strong>.</p>
<p><strong>Interpreting the Kappa value obtained</strong></p>
<p>There is not a standardized interpretation of the kappa statistic. According to Wikipedia (citing their paper):</p>
<p>Landis and Koch considers <strong>0-0.20 as slight, 0.21-0.40 as fair, 0.41-0.60 as moderate, 0.61-0.80 as substantial, and 0.81-1 as almost perfect</strong>.</p>
<p>Fleiss considers <strong>kappas &gt; 0.75 as excellent, 0.40-0.75 as fair to good, and &lt; 0.40 as poor</strong>. It is important to note that both scales are somewhat arbitrary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cohen_kappa</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">label_name</span><span class="o">=</span><span class="p">{}):</span>
    <span class="n">df_confusion</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">label_name</span><span class="p">,</span> <span class="n">margins</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
    <span class="n">OA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">df_confusion</span><span class="o">.</span><span class="n">values</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">n</span>
    <span class="n">col_comb</span> <span class="o">=</span> <span class="n">df_confusion</span><span class="p">[</span><span class="s1">&#39;All&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">row_comb</span> <span class="o">=</span> <span class="n">df_confusion</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;All&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">EA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">row_comb</span><span class="o">*</span><span class="n">col_comb</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="p">(</span><span class="n">OA</span><span class="o">-</span><span class="n">EA</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">EA</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">kappa</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_name</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;Grapes&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Apples&#39;</span><span class="p">}</span>
<span class="n">actual</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kappa</span> <span class="o">=</span> <span class="n">cohen_kappa</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cohen&#39;s Kappa =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">kappa</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cohen&#39;s Kappa = 0.336
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="confirm-the-same-using-sklearn-s-cohen-kappa-score">
<h2>Confirm the same using Sklearn’s cohen_kappa_score<a class="headerlink" href="#confirm-the-same-using-sklearn-s-cohen-kappa-score" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">cohen_kappa_score</span>

<span class="n">kappa_sk</span> <span class="o">=</span> <span class="n">cohen_kappa_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sklearn&#39;s Cohen&#39;s Kappa =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">kappa_sk</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sklearn&#39;s Cohen&#39;s Kappa = 0.336
</pre></div>
</div>
</div>
</div>
</section>
<section id="testing-the-same-on-3-classes">
<h2>Testing the same on 3-classes<a class="headerlink" href="#testing-the-same-on-3-classes" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">label_name</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;Class-0&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Class-1&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Class-2&#39;</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kappa</span> <span class="o">=</span> <span class="n">cohen_kappa</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cohen&#39;s Kappa =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">kappa</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cohen&#39;s Kappa = -0.151
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kappa_sk</span> <span class="o">=</span> <span class="n">cohen_kappa_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sklearn&#39;s Cohen&#39;s Kappa =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">kappa_sk</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sklearn&#39;s Cohen&#39;s Kappa = -0.151
</pre></div>
</div>
</div>
</div>
<section id="jaccard-similarity-index">
<h3>12) Jaccard Similarity Index<a class="headerlink" href="#jaccard-similarity-index" title="Permalink to this headline">#</a></h3>
<p>If two sets share the <strong>exact same members</strong>, their <strong>Jaccard Similarity Index will be 1</strong>. Conversely, if they have <strong>no members in common</strong> then their <strong>similarity will be 0</strong>.</p>
<p>So, the idea behind this index is that higher the similarity of these two groups (actual and predicted labels) the higher the index.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">jaccard_similarity</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">))</span>
    <span class="n">L</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">n</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="o">-</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jaccard Similarity index =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">jaccard_similarity</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jaccard Similarity index = 0.133
</pre></div>
</div>
</div>
</div>
</section>
<section id="matthews-correlation-coefficient-mcc">
<h3>13) Matthew’s correlation coefficient (MCC)<a class="headerlink" href="#matthews-correlation-coefficient-mcc" title="Permalink to this headline">#</a></h3>
<p>So far, we’ve seen some issues with the classic metrics: accuracy is sensitive to class imbalance; precision, recall, and F1-score are asymmetric.</p>
<p>For binary classification, treat the <strong>true class</strong> and the <strong>predicted class</strong> as <strong>two (binary) variables</strong>, and compute their <strong>correlation coefficient</strong> (in a similar way to computing correlation coefficient between any two variables). <strong>The higher the correlation between true and predicted values, the better the prediction</strong>. This is the phi-coefficient (φ), rechristened <code class="docutils literal notranslate"><span class="pre">Matthews</span> <span class="pre">Correlation</span> <span class="pre">Coefficient</span> <span class="pre">(MCC)</span></code> when applied to classifiers:</p>
<p><img alt="" src="../../_images/mcc.png" /></p>
<p>Some nice properties of MCC can be easily derived from this formula: when the classifier is perfect (FP = FN = 0) the value of MCC is 1, indicating perfect positive correlation. Conversely, when the classifier always misclassifies (TP = TN = 0), we get a value of -1, representing perfect negative correlation (in this case, you can simply reverse the classifier’s outcome to get the ideal classifier). In fact, MCC value is always between -1 and 1, with 0 meaning that the classifier is no better than a random flip of a fair coin. MCC is also perfectly symmetric, so no class is more important than the other; if you switch the positive and negative, you’ll still get the same value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num</span> <span class="o">=</span> <span class="n">TP</span><span class="o">*</span><span class="n">TN</span> <span class="o">-</span> <span class="n">FP</span><span class="o">*</span><span class="n">FN</span>
<span class="n">den</span> <span class="o">=</span> <span class="p">((</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FN</span><span class="p">))</span><span class="o">**</span><span class="mf">0.5</span>
<span class="n">mcc</span> <span class="o">=</span> <span class="n">num</span><span class="o">/</span><span class="n">den</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MCC =&quot;</span><span class="p">,</span> <span class="n">mcc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean of MCC =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mcc</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MCC = [-0.11769798 -0.20658356 -0.13333333]
Mean of MCC = -0.153
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">matthews_corrcoef</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MCC sklearn =&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MCC sklearn = -0.152
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/preliminaries"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="data_preprocessing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">1.1. Data Preprocessing</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../multilayer_perceptrons/activation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">2.1. Activation Functions</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ujjwal Khandelwal<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>