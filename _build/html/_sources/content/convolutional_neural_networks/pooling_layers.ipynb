{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8p4I3bOm_d1"
   },
   "source": [
    "# 3.2.4. Pooling layers\n",
    "\n",
    "![](images/pooling_layer.png)\n",
    "\n",
    "A major problem with convolutional layer is that the `feature map` (output) produced by the convolution between input and kernel is **translation variant (that is location-dependent)**. \n",
    "\n",
    "This means that if an object in an image has shifted a bit it might not be recognizable by the convolutional layer. So, it means that the feature map (output) records the precise positions of features in the input.\n",
    "\n",
    "Therefore we want a layer which can take as input this feature map (output from convolution) and make it **translation invariant (which means location of the feature should not matter)**. This is done by a `pooling layer`.\n",
    "\n",
    "### How does Pooling work?\n",
    "\n",
    "We select a Kernel and slide it over the feature map (output from the preceding convolution layer after activation is applied) \n",
    "and based on the type of pooling operation weâ€™ve selected, the pooling kernel calculates an output.\n",
    "\n",
    "The most commonly used Kernel size is $(2,2)$ along with a stride of 2. \n",
    "\n",
    "#### Max Pooling\n",
    "\n",
    "In max pooling, the filter simply selects the maximum pixel value in the receptive field. From the below gif, we see that the kernel is selecting only the maximum value from the receptive field (like in the first slot, we have 4 pixels in the field with values 1, 5, 2, and 6, and we select 6).\n",
    "\n",
    "![](images/maxpool.gif)\n",
    "\n",
    "#### Average Pooling\n",
    "\n",
    "In average pooling, the filter simply selects the average value of all the pixels in the receptive field.\n",
    "\n",
    "![](images/averagepool.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation for Pooling layer\n",
    "\n",
    "Let us write the python code (using only numpy) to implement forward propagation in pooling layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YemeradDi_r_"
   },
   "source": [
    "#### Simple Input (no channels and batch)\n",
    "\n",
    "We will start with a simple Input (with no channels and batch) of shape $(N_h, N_w)$ and then progress further.\n",
    "\n",
    "![](images/maxpool_input.png)\n",
    "\n",
    "The function `pad_input2D(X,K,s,p)` performs padding on input $X$ (with no channels and batch) and returns the padded matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def pad_input2D(X, K=None, s=(1,1), p='valid', K_size=None):\n",
    "\n",
    "    if type(p)==int:\n",
    "        Nh, Nw = X.shape\n",
    "        pt, pb = p, p\n",
    "        pl, pr = p, p\n",
    "        \n",
    "    if type(p)==tuple:\n",
    "        Nh, Nw = X.shape\n",
    "        \n",
    "        ph,pw = p\n",
    "        pt, pb = ph//2, (ph+1)//2\n",
    "        pl, pr = pw//2, (pw+1)//2\n",
    "        \n",
    "    elif p=='valid':\n",
    "        Nh, Nw = X.shape\n",
    "        pt, pb = 0, 0\n",
    "        pl, pr = 0, 0\n",
    "\n",
    "    elif p=='same':\n",
    "        Nh, Nw = X.shape\n",
    "        if K is not None:\n",
    "            Kh, Kw = K.shape\n",
    "        else:\n",
    "            Kh, Kw = K_size\n",
    "        sh, sw = s\n",
    "\n",
    "        ph = (sh-1)*Nh + Kh - sh\n",
    "        pw = (sw-1)*Nw + Kw - sw\n",
    "\n",
    "        pt, pb = ph//2, (ph+1)//2\n",
    "        pl, pr = pw//2, (pw+1)//2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Incorrect padding type. Allowed types are only 'same' or 'valid' or an integer.\")\n",
    "\n",
    "    Xp = np.vstack((np.zeros((pt, Nw)), X))\n",
    "    Xp = np.vstack((Xp, np.zeros((pb, Nw))))\n",
    "    Xp = np.hstack((np.zeros((Nh+pt+pb, pl)), Xp))\n",
    "    Xp = np.hstack((Xp, np.zeros((Nh+pt+pb, pr))))\n",
    "\n",
    "    return Xp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `pooling2d(X, pool_size, s, p, pool_type)` performs max/mean pooling on a 2d array using numpy.\n",
    "\n",
    "So, the idea is to create a sub-matrices of the input using the given kernel size and stride (with the help of `as_stride()` of numpy) and then simply take the maximum along the height and width axes.\n",
    "\n",
    "> **Note**: The main benefit of using this method is that it can be extended for input with channels (depth) and batches as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling2d(X, pool_size=(2,2), s=(2,2), p='valid', pool_type='max'):\n",
    "    \n",
    "    # padding\n",
    "    Xp = pad_input2D(X, s=s, p=p, K_size=pool_size)\n",
    "    \n",
    "    print('Xp (padded X)' + ' for padding=' + str(p) + ' = \\n\\n', Xp, '\\n')\n",
    "\n",
    "    Nh, Nw = Xp.shape\n",
    "    sh, sw = s # strides along height and width\n",
    "    Kh, Kw = pool_size\n",
    "\n",
    "    Oh = (Nh-Kh)//sh + 1\n",
    "    Ow = (Nw-Kw)//sw + 1\n",
    "\n",
    "    strides = (sh*Nw, sw, Nw, 1)\n",
    "    strides = tuple(i * Xp.itemsize for i in strides)\n",
    "\n",
    "    subM = np.lib.stride_tricks.as_strided(Xp, shape=(Oh, Ow, Kh, Kw),\n",
    "                                           strides=strides)\n",
    "    if pool_type=='max':\n",
    "        return np.max(subM, axis=(-2,-1)) # maximum along height and width\n",
    "    elif pool_type=='mean':\n",
    "        return np.mean(subM, axis=(-2,-1))\n",
    "    else:\n",
    "        raise ValueError(\"Allowed pool types are only 'max' or 'mean'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try `pool_type=\"max\"`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "\n",
      " [[ 1  5  3 -3]\n",
      " [ 2  6 -1  1]\n",
      " [ 0  4  7  2]\n",
      " [11 -5  8  6]] \n",
      "\n",
      "Xp (padded X) for padding=same = \n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  5.  3. -3.  0.  0.]\n",
      " [ 0.  0.  2.  6. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  4.  7.  2.  0.  0.]\n",
      " [ 0.  0. 11. -5.  8.  6.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]] \n",
      "\n",
      "Z = \n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      " [ 0.  6.  3.  0.]\n",
      " [ 0. 11.  8.  0.]\n",
      " [ 0.  0.  0.  0.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.array([[1,5,3,-3],\n",
    "              [2,6,-1,1],\n",
    "              [0,4,7,2],\n",
    "              [11,-5,8,6]])\n",
    "\n",
    "pool_size = (2,2) # Kernel size\n",
    "\n",
    "s = (2,2) # strides along height and width\n",
    "\n",
    "print('X = \\n\\n', X, '\\n')\n",
    "\n",
    "Z = pooling2d(X, pool_size, s, p='same', pool_type='max')\n",
    "\n",
    "print('Z = \\n\\n', Z, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try `pool_type=\"mean\"`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "\n",
      " [[ 1  5  3 -3]\n",
      " [ 2  6 -1  1]\n",
      " [ 0  4  7  2]\n",
      " [11 -5  8  7]] \n",
      "\n",
      "Xp (padded X) for padding=same = \n",
      "\n",
      " [[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  5.  3. -3.  0.  0.]\n",
      " [ 0.  0.  2.  6. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  4.  7.  2.  0.  0.]\n",
      " [ 0.  0. 11. -5.  8.  7.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]] \n",
      "\n",
      "Z = \n",
      "\n",
      " [[0.  0.  0.  0. ]\n",
      " [0.  3.5 0.  0. ]\n",
      " [0.  2.5 6.  0. ]\n",
      " [0.  0.  0.  0. ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.array([[1,5,3,-3],\n",
    "              [2,6,-1,1],\n",
    "              [0,4,7,2],\n",
    "              [11,-5,8,7]])\n",
    "\n",
    "pool_size = (2,2) # Kernel size\n",
    "\n",
    "s = (2,2) # strides along height and width\n",
    "\n",
    "print('X = \\n\\n', X, '\\n')\n",
    "\n",
    "Z = pooling2d(X, pool_size, s, p='same', pool_type='mean')\n",
    "\n",
    "print('Z = \\n\\n', Z, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked like a charm! Let us now extend the same using input (with channels or depth and batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input with batch of images (with channels)\n",
    "\n",
    "**Next we will also include channels to image as Input**\n",
    "\n",
    "A batch of images (with channels) as input of shape $(m, N_c, N_h, N_w)$ is used.\n",
    "\n",
    "> **Note:** See how the depth of the pool is same as the number of channels (one 2D pool for each channel).\n",
    "\n",
    "![](images/input_batch_channels.png)\n",
    "\n",
    "The function `pad_input2D_with_channels_batch(X,K,s,p)` performs padding on input $X$ (with channels) and returns the padded matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_input2D_with_channels_batch(X, K=None, s=(1,1), p='valid', K_size=None):\n",
    "    \n",
    "    if type(p)==int:\n",
    "        m, Nc, Nh, Nw = X.shape\n",
    "        pt, pb = p, p\n",
    "        pl, pr = p, p\n",
    "        \n",
    "    if type(p)==tuple:\n",
    "        m, Nc, Nh, Nw = X.shape\n",
    "        \n",
    "        ph, pw = p\n",
    "        pt, pb = ph//2, (ph+1)//2\n",
    "        pl, pr = pw//2, (pw+1)//2\n",
    "    \n",
    "    elif p=='valid':\n",
    "        m, Nc, Nh, Nw = X.shape\n",
    "        pt, pb = 0, 0\n",
    "        pl, pr = 0, 0\n",
    "    \n",
    "    elif p=='same':\n",
    "        m, Nc, Nh, Nw = X.shape\n",
    "        \n",
    "        if K is not None:\n",
    "            Kc, Kh, Kw = K.shape\n",
    "        else:\n",
    "            Kh, Kw = K_size\n",
    "            \n",
    "        sh, sw = s\n",
    "\n",
    "        ph = (sh-1)*Nh + Kh - sh\n",
    "        pw = (sw-1)*Nw + Kw - sw\n",
    "\n",
    "        pt, pb = ph//2, (ph+1)//2\n",
    "        pl, pr = pw//2, (pw+1)//2\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Incorrect padding type. Allowed types are only 'same' or 'valid'.\")\n",
    "\n",
    "    zeros_r = np.zeros((m, Nc, Nh, pr))\n",
    "    zeros_l = np.zeros((m, Nc, Nh, pl))\n",
    "    zeros_t = np.zeros((m, Nc, pt, Nw+pl+pr))\n",
    "    zeros_b = np.zeros((m, Nc, pb, Nw+pl+pr))\n",
    "\n",
    "    Xp = np.concatenate((X, zeros_r), axis=3)\n",
    "    Xp = np.concatenate((zeros_l, Xp), axis=3)\n",
    "    Xp = np.concatenate((zeros_t, Xp), axis=2)\n",
    "    Xp = np.concatenate((Xp, zeros_b), axis=2)\n",
    "\n",
    "    return Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling2d_with_channels_batch(X, pool_size=(2,2), s=(2,2), p='valid', pool_type='max'):\n",
    "    \n",
    "    # padding\n",
    "    Xp = pad_input2D_with_channels_batch(X, s=s, p=p, K_size=pool_size)\n",
    "    \n",
    "    print('Xp (padded X)' + ' for padding=' + str(p) + ' = \\n\\n', Xp, '\\n')\n",
    "\n",
    "    m, Nc, Nh, Nw = Xp.shape\n",
    "    sh, sw = s # strides along height and width\n",
    "    Kh, Kw = pool_size\n",
    "\n",
    "    Oh = (Nh-Kh)//sh + 1\n",
    "    Ow = (Nw-Kw)//sw + 1\n",
    "\n",
    "    strides = (Nc*Nh*Nw, Nh*Nw, Nw*sh, sw, Nw, 1)\n",
    "    strides = tuple(i * Xp.itemsize for i in strides)\n",
    "\n",
    "    subM = np.lib.stride_tricks.as_strided(Xp, shape=(m, Nc, Oh, Ow, Kh, Kw),\n",
    "                                            strides=strides)\n",
    "    \n",
    "    a = subM.reshape(-1,Kh*Kw)\n",
    "    idx = np.argmax(a, axis=1)\n",
    "    b = np.zeros(a.shape)\n",
    "    b[np.arange(b.shape[0]), idx] = 1\n",
    "    mask = b.reshape((m, Nc, Oh, Ow, Kh, Kw))\n",
    "    \n",
    "    if pool_type=='max':\n",
    "        return np.max(subM, axis=(-2,-1)), mask, Xp # maximum along height and width of submatrix\n",
    "    elif pool_type=='mean':\n",
    "        return np.mean(subM, axis=(-2,-1)), mask, Xp\n",
    "    else:\n",
    "        raise ValueError(\"Allowed pool types are only 'max' or 'mean'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try `pool_type=\"max\"`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "\n",
      " [[[[9 4 0]\n",
      "   [1 9 0]\n",
      "   [1 8 9]]\n",
      "\n",
      "  [[0 8 6]\n",
      "   [4 3 0]\n",
      "   [4 6 8]]]\n",
      "\n",
      "\n",
      " [[[1 8 4]\n",
      "   [1 3 6]\n",
      "   [5 3 9]]\n",
      "\n",
      "  [[6 9 1]\n",
      "   [9 4 2]\n",
      "   [6 7 8]]]] \n",
      "\n",
      "Xp (padded X) for padding=same = \n",
      "\n",
      " [[[[0. 9. 4. 0. 0. 0.]\n",
      "   [0. 1. 9. 0. 0. 0.]\n",
      "   [0. 1. 8. 9. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 8. 6. 0. 0.]\n",
      "   [0. 4. 3. 0. 0. 0.]\n",
      "   [0. 4. 6. 8. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 1. 8. 4. 0. 0.]\n",
      "   [0. 1. 3. 6. 0. 0.]\n",
      "   [0. 5. 3. 9. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 6. 9. 1. 0. 0.]\n",
      "   [0. 9. 4. 2. 0. 0.]\n",
      "   [0. 6. 7. 8. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]]] \n",
      "\n",
      "Z = \n",
      "\n",
      " [[[[9. 9. 0.]\n",
      "   [1. 9. 0.]\n",
      "   [1. 9. 0.]]\n",
      "\n",
      "  [[4. 8. 0.]\n",
      "   [4. 8. 0.]\n",
      "   [4. 8. 0.]]]\n",
      "\n",
      "\n",
      " [[[1. 8. 0.]\n",
      "   [5. 9. 0.]\n",
      "   [5. 9. 0.]]\n",
      "\n",
      "  [[9. 9. 0.]\n",
      "   [9. 8. 0.]\n",
      "   [6. 8. 0.]]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.random.randint(0,10, size=(2,2,3,3))\n",
    "\n",
    "pool_size = (2,2) # Kernel size\n",
    "\n",
    "s = (1,2) # strides along height and width\n",
    "\n",
    "print('X = \\n\\n', X, '\\n')\n",
    "\n",
    "Z, mask, Xp = pooling2d_with_channels_batch(X, pool_size, s, p='same', pool_type='max')\n",
    "\n",
    "print('Z = \\n\\n', Z, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try `pool_type=\"mean\"`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "\n",
      " [[[[9 4 0]\n",
      "   [1 9 0]\n",
      "   [1 8 9]]\n",
      "\n",
      "  [[0 8 6]\n",
      "   [4 3 0]\n",
      "   [4 6 8]]]\n",
      "\n",
      "\n",
      " [[[1 8 4]\n",
      "   [1 3 6]\n",
      "   [5 3 9]]\n",
      "\n",
      "  [[6 9 1]\n",
      "   [9 4 2]\n",
      "   [6 7 8]]]] \n",
      "\n",
      "Xp (padded X) for padding=same = \n",
      "\n",
      " [[[[0. 9. 4. 0. 0. 0.]\n",
      "   [0. 1. 9. 0. 0. 0.]\n",
      "   [0. 1. 8. 9. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 8. 6. 0. 0.]\n",
      "   [0. 4. 3. 0. 0. 0.]\n",
      "   [0. 4. 6. 8. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 1. 8. 4. 0. 0.]\n",
      "   [0. 1. 3. 6. 0. 0.]\n",
      "   [0. 5. 3. 9. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 6. 9. 1. 0. 0.]\n",
      "   [0. 9. 4. 2. 0. 0.]\n",
      "   [0. 6. 7. 8. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]]] \n",
      "\n",
      "Z = \n",
      "\n",
      " [[[[2.5  3.25 0.  ]\n",
      "   [0.5  6.5  0.  ]\n",
      "   [0.25 4.25 0.  ]]\n",
      "\n",
      "  [[1.   4.25 0.  ]\n",
      "   [2.   4.25 0.  ]\n",
      "   [1.   3.5  0.  ]]]\n",
      "\n",
      "\n",
      " [[[0.5  5.25 0.  ]\n",
      "   [1.5  5.25 0.  ]\n",
      "   [1.25 3.   0.  ]]\n",
      "\n",
      "  [[3.75 4.   0.  ]\n",
      "   [3.75 5.25 0.  ]\n",
      "   [1.5  3.75 0.  ]]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.random.randint(0,10, size=(2,2,3,3))\n",
    "\n",
    "pool_size = (2,2) # Kernel size\n",
    "\n",
    "s = (1,2) # strides along height and width\n",
    "\n",
    "print('X = \\n\\n', X, '\\n')\n",
    "\n",
    "Z, mask, Xp = pooling2d_with_channels_batch(X, pool_size, s, p='same', pool_type='mean')\n",
    "\n",
    "print('Z = \\n\\n', Z, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation for Pooling layer\n",
    "\n",
    "Now let us write the python code (using only numpy) to implement backpropagation in the pooling layer!\n",
    "\n",
    "#### Maxpool\n",
    "\n",
    "Suppose we have the following maxpool operation (forward) where the shaded pixels (in red) represents the maximum value of that receptive field.\n",
    "\n",
    "![](images/maxpool_2d.png)\n",
    "\n",
    "Now, let the output error that we receive into this maxpool system be $dZ$ such that:\n",
    "\n",
    "$$\n",
    "dZ = \\begin{bmatrix}\n",
    "dZ_{1} & dZ_{2} \\\\ \n",
    "dZ_{3} & dZ_{4}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "> The gradient of the error $dX$ with respect to the input features is nonzero only if the input feature has the maximum value in the pooling kernel.\n",
    "\n",
    "Using this strategy, we can compute the full backward pass (to compute $dX$) as follows:\n",
    "\n",
    "\n",
    "![](images/maxpool_backpass.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xp (padded X) for padding=same = \n",
      "\n",
      " [[[[0. 9. 4. 0. 0. 0.]\n",
      "   [0. 1. 9. 0. 0. 0.]\n",
      "   [0. 1. 8. 9. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 8. 6. 0. 0.]\n",
      "   [0. 4. 3. 0. 0. 0.]\n",
      "   [0. 4. 6. 8. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 1. 8. 4. 0. 0.]\n",
      "   [0. 1. 3. 6. 0. 0.]\n",
      "   [0. 5. 3. 9. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 6. 9. 1. 0. 0.]\n",
      "   [0. 9. 4. 2. 0. 0.]\n",
      "   [0. 6. 7. 8. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.random.randint(0,10, size=(2,2,3,3))\n",
    "\n",
    "pool_size = (2,2) # Kernel size\n",
    "\n",
    "s = (1,2) # strides along height and width\n",
    "\n",
    "Z, mask, Xp = pooling2d_with_channels_batch(X, pool_size, s, p='same', pool_type='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pooling2d_backwards_with_channels_batch(dZ, mask, X, pool_size)` function implements the backpropagation in the maxpooling layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling2d_max_backwards_with_channels_batch(dZ, mask, X, pool_size):\n",
    "    m, Nc, Nh, Nw = X.shape\n",
    "    Kh, Kw = pool_size\n",
    "    dA = np.einsum('i,ijk->ijk', dZ.reshape(-1), mask.reshape(-1,Kh,Kw)).reshape(mask.shape)\n",
    "    strides = (Nc*Nh*Nw, Nh*Nw, Nw, 1)\n",
    "    strides = tuple(i * X.itemsize for i in strides)\n",
    "    dX = np.lib.stride_tricks.as_strided(dA, X.shape, strides)\n",
    "    return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0.,  -1.,   0.,   0.,   0.,   0.],\n",
       "         [ -6.,   0.,   5.,   0.,   0.,   0.],\n",
       "         [  0., -10.,   0.,   0.,   7.,   0.],\n",
       "         [  0.,   0.,   6.,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   7.,   0.,   0.,   0.,  -2.],\n",
       "         [  0.,   0.,  -1.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0., -10.,   0.,   0.],\n",
       "         [  0.,   0.,  -2.,   0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       [[[  0.,  -6.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   9.,   6.,   0.,   0.,   0.],\n",
       "         [  0.,  -6.,   0.,   0.,   0.,   5.],\n",
       "         [  0.,   0.,   1.,   0.,   0.,   0.]],\n",
       "\n",
       "        [[  0.,   1.,   0.,   0.,  -9.,   0.],\n",
       "         [  0.,   0.,  -2.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,  -6.,   0.,   0.],\n",
       "         [  0.,   4.,   7.,   0.,   0.,   0.]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "dZ = np.random.randint(-10, 10, Z.shape) \n",
    "\n",
    "dXp = pooling2d_max_backwards_with_channels_batch(dZ, mask, Xp, pool_size)\n",
    "\n",
    "dXp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a small function such that we can extract the original input errors from the padding ones. This you can consider as **backpropagation through padding operation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding2D_backwards_with_channels_batch(X, Xp, dXp):\n",
    "    m, Nc, Nh, Nw = Xp.shape\n",
    "    m, Nc, Nhx, Nwx = X.shape\n",
    "    ph = Nh - Nhx\n",
    "    pw = Nw - Nwx\n",
    "    pt, pb = ph//2, (ph+1)//2\n",
    "    pl, pr = pw//2, (pw+1)//2\n",
    "    dX = dXp[:, :, pt:pt+Nhx, pl:pl+Nwx]\n",
    "    return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -1.,   0.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         [-10.,   0.,   0.]],\n",
       "\n",
       "        [[  7.,   0.,   0.],\n",
       "         [  0.,  -1.,   0.],\n",
       "         [  0.,   0., -10.]]],\n",
       "\n",
       "\n",
       "       [[[ -6.,   0.,   0.],\n",
       "         [  9.,   6.,   0.],\n",
       "         [ -6.,   0.,   0.]],\n",
       "\n",
       "        [[  1.,   0.,   0.],\n",
       "         [  0.,  -2.,   0.],\n",
       "         [  0.,   0.,  -6.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX = padding2D_backwards_with_channels_batch(X, Xp, dXp)\n",
    "dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Congrats! We have successfully calculated the gradients of the input $dX$ for the maxpooling layer using only numpy (and no for loops)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average pool\n",
    "\n",
    "Now we will be writing the code for computing the gradient in case of average pooling. This code is also written using numpy and it is the most generalized code which runs without for loops and you will hardly find it anywhere on net!\n",
    "\n",
    "I will not be going with the theoretical explaination but if you are interested you can visit [this site](https://lanstonchu.wordpress.com/2018/09/01/convolutional-neural-network-cnn-backward-propagation-of-the-pooling-layers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pooling2d_avg_backwards_with_channels_batch(dZ, s, X, pool_size):\n",
    "    \n",
    "    m, Nc, Nh, Nw = X.shape\n",
    "    sh, sw = s\n",
    "    Kh, Kw = pool_size\n",
    "    \n",
    "    dZp = np.kron(dZ, np.ones((Kh,Kw), dtype=dZ.dtype)) # similar to repelem in matlab\n",
    "\n",
    "    jh, jw = Kh-sh, Kw-sw # jump along height and width\n",
    "\n",
    "    if jw!=0:\n",
    "        L = dZp.shape[-1]-1\n",
    "\n",
    "        l1 = np.arange(sw, L)\n",
    "        l2 = np.arange(sw + jw, L + jw)\n",
    "\n",
    "        mask = np.tile([True]*jw + [False]*jw, len(l1)//jw).astype(bool)\n",
    "\n",
    "        r1 = l1[mask[:len(l1)]]\n",
    "        r2 = l2[mask[:len(l2)]]\n",
    "\n",
    "        dZp[:, :, :, r1] += dZp[:, :, :, r2]\n",
    "        dZp = np.delete(dZp, r2, axis=-1)\n",
    "\n",
    "    if jh!=0:\n",
    "        L = dZp.shape[-2]-1\n",
    "\n",
    "        l1 = np.arange(sh, L)\n",
    "        l2 = np.arange(sh + jh, L + jh)\n",
    "\n",
    "        mask = np.tile([True]*jh + [False]*jh, len(l1)//jh).astype(bool)\n",
    "\n",
    "        r1 = l1[mask[:len(l1)]]\n",
    "        r2 = l2[mask[:len(l2)]]\n",
    "\n",
    "        dZp[:, :, r1, :] += dZp[:, :, r2, :]\n",
    "        dZp = np.delete(dZp, r2, axis=-2)\n",
    "\n",
    "    pw = Nw - dZp.shape[-1]\n",
    "    ph = Nh - dZp.shape[-2]\n",
    "\n",
    "    dXp = pad_input2D_with_channels_batch(dZp, s=s, p=(ph, pw), K_size=pool_size)\n",
    "\n",
    "    return dXp / (Nh*Nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 4, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "dZ = np.random.randint(-10, 10, Z.shape) \n",
    "\n",
    "dXp = pooling2d_avg_backwards_with_channels_batch(dZ, s, Xp, pool_size)\n",
    "\n",
    "dXp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.04166667, -0.25      , -0.25      ],\n",
       "         [-0.45833333,  0.04166667,  0.04166667],\n",
       "         [-0.125     ,  0.20833333,  0.20833333]],\n",
       "\n",
       "        [[-0.41666667,  0.        ,  0.        ],\n",
       "         [-0.66666667,  0.375     ,  0.375     ],\n",
       "         [-0.5       ,  0.58333333,  0.58333333]]],\n",
       "\n",
       "\n",
       "       [[[ 0.04166667, -0.375     , -0.375     ],\n",
       "         [-0.20833333, -0.20833333, -0.20833333],\n",
       "         [ 0.125     ,  0.29166667,  0.29166667]],\n",
       "\n",
       "        [[ 0.125     ,  0.375     ,  0.375     ],\n",
       "         [ 0.20833333,  0.        ,  0.        ],\n",
       "         [ 0.41666667, -0.25      , -0.25      ]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX = padding2D_backwards_with_channels_batch(X, Xp, dXp)\n",
    "dX"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
