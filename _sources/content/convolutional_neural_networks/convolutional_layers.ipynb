{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8p4I3bOm_d1"
   },
   "source": [
    "# 3.2.1. Convolutional layers\n",
    "\n",
    "> This layer creates a **convolution kernel** that is `convolved` with the layer input to produce a tensor of outputs. It is well known for extracting features from images. Let me explain.\n",
    "\n",
    "### A short summary on Convolution and Cross Correlation\n",
    "\n",
    "Before we even try to understand what the above statement means, let us quickly go through the two important and simple mathematical operations namely **Convolution** and **Cross Correlation** which represents the heart of the convolutional layer.\n",
    "\n",
    "#### Cross Correlation operation $\\otimes$\n",
    "\n",
    "Suppose we input an arbitrary big matrix $X$ and we have a smaller matrix $K$ which we call as **kernel** (or **filter**) as shown in the figure below:\n",
    "\n",
    "![](images/x_correlate_k.png)\n",
    "\n",
    "Then, the `cross correlation operation` between the input $X$ and kernel $K$ ($X \\otimes K$) will produce an output matrix $Z$ whose values are obtained by sliding the kernel $K$ on top of the input $X$ as shown in the below gif.\n",
    "\n",
    "![](images/cross_correlation.gif)\n",
    "\n",
    "Let us compute the first output element and the rest of them can be computed in the similar fashion. In the below figure, the shaded portions are the first output element as well as the input and kernel elements used for the output computation: \n",
    "\n",
    "![](images/cross_corr_1.png)\n",
    "\n",
    "$$\n",
    "1*1 + 5*(-1) + 2*2 + 6*0 = 0\n",
    "$$\n",
    "\n",
    "#### Convolution operation ($\\star$)\n",
    "\n",
    "The `convolution operation` between input $X$ and kernel $K$ ($X \\star K$) is the same operation as cross correlation operation except that we have to rotate the kernel by 180 degrees to get a new kernel.\n",
    "\n",
    "![](images/rotate_kernel.png)\n",
    "\n",
    "This rotation will result into the following output matrix $Z$.\n",
    "\n",
    "![](images/convolve.png)\n",
    "\n",
    "In other words, we have the following **relation between convolution and cross-correlation** operation.\n",
    "\n",
    "$$\n",
    "X \\star K = X \\otimes \\text{rot180}(K)\n",
    "$$\n",
    "\n",
    "Now, before we continue further, let us first define some basic operations such as the **padding**, **stride** and **dilation**.\n",
    "\n",
    "#### Padding\n",
    "\n",
    "As we have seen in the `cross correlation operation` above, the pixels on the corner of the image (2D matrix) are less used than the pixels in the middle of the image which means that the information from the edges are not much used. \n",
    "\n",
    "To solve this problem, we often add padding around the image in order to take the pixels on the edges into account. Generally we **padde** the matrix with `zeros` and use the variable $p$ to denote the number of layers of zeros added to the border of the image (see figure below where we have padded the matrix $X$, used earlier, with $p=1$).\n",
    "\n",
    "![](images/padding.png)\n",
    "\n",
    "> **Note:** After padding our $(N, M)$ image becomes $(N + 2p, M + 2p)$ image.\n",
    "\n",
    "Mostly there are only 2 types of paddings used widely: One is **valid** and other is **same**.\n",
    "\n",
    "`valid` means no padding. With this type of padding, there's no \"made-up\" padding inputs. The layer only uses valid input data. \n",
    "\n",
    "`valid` drops the right-most columns (or bottom-most rows) from the data.\n",
    "\n",
    "`same` padding tries to pad evenly left and right columns, but if the amount of columns to be added is odd, it will add the extra column to the right (the same logic applies vertically: there may be an extra row of zeros at the bottom).\n",
    "\n",
    "With `same` padding, if you use a **stride of 1**, the layer's outputs will have the same spatial dimensions as its inputs.\n",
    "\n",
    "#### Stride\n",
    "\n",
    "Stride simply denotes the number of pixels shifts while sliding the kernel $K$ over the input matrix $X$. By default it is one. We denote with $s$ the stride parameter. \n",
    "\n",
    "The following gif illustrates $s=1$\n",
    "\n",
    "![](images/stride_1.gif)\n",
    "\n",
    "and the following gif illustrates $s=2$\n",
    "\n",
    "![](images/stride_2.gif)\n",
    "\n",
    "#### Dilation\n",
    "\n",
    "It is a method in which given a matrix $X$ (for dilation), it is expanded (both horizontally and vertically) by inserting holes between its consecutive elements. In simple terms, we put rows and columns of zeros after every element of $X$ (except the last one) based on the dilation rate $(D_h, D_w)$ along the height and the width of input respectively. Figure below will help you understand better (check dilated matrix for different values of the dilation rate).\n",
    "\n",
    "![](images/dilation_1.png)\n",
    "\n",
    "![](images/dilation_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D, 2D and 3D CNN\n",
    "\n",
    "**1D CNN**\n",
    "\n",
    "In 1D CNN, kernel moves in 1 direction as shown in the [figure](https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610) below. Input and output data of 1D CNN is 2 dimensional. It is mostly used on `Time-Series data`.\n",
    "\n",
    "![](images/cnn_1d.webp)\n",
    "\n",
    "**2D CNN**\n",
    "\n",
    "In 2D CNN, the kernel slides along 2 dimensions on the data as shown in the following [image](https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610). Input and output data of 2D CNN is 3 dimensional. Mostly used on Image data.\n",
    "\n",
    "![](images/cnn_2d.webp)\n",
    "\n",
    "**3D CNN**\n",
    "\n",
    "In 3D CNN, kernel moves in 3 directions (see [figure](https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610) below). Input and output data of 3D CNN is 4 dimensional. Mostly used on 3D Image data (MRI, CT Scans, Video).\n",
    "\n",
    "![](images/cnn_3d.webp)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notations\n",
    "\n",
    "![](images/convolution_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Input`\n",
    "\n",
    "* Denoted by: $X$ (mostly it will be an Image)\n",
    "* Shape: $(m, N_c, N_h, N_w)$\n",
    "    * $m$ is the batch size\n",
    "    * $N_c$ is the number of channels (depth of the input)\n",
    "    * $N_h$ is the height of the input\n",
    "    * $N_w$ is the width of input\n",
    "    \n",
    "`Parameters`\n",
    "\n",
    "`Kernel`\n",
    "\n",
    "* Denoted by: $K$ (also called Kernel or Filter)\n",
    "* Shape: $(F, K_c, K_h, K_w)$\n",
    "    * $F$ is the total number of filters\n",
    "    * $K_c$ is the depth of thw Kernel (it is equal to the depth of input or $N_c$)\n",
    "    * $K_h$ is the height of the Kernel\n",
    "    * $K_w$ is the width of the Kernel\n",
    "    \n",
    "`Bias`\n",
    "\n",
    "* Denoted by: $b$ (also called Bias)\n",
    "* Shape: $(F, O_h, O_w)$\n",
    "    * $F$ is the total number of filters used in Kernel\n",
    "    * $O_h$ is the height of the Output $Z$ (defined below)\n",
    "    * $O_w$ is the width of the Output $Z$\n",
    "\n",
    "`Padding`\n",
    "\n",
    "* Denoted by: $p$ (also called padding type)\n",
    "    * $p$ can be `str` (\"valid\" or \"same\") \n",
    "    * $p$ can be `int` as described above (for symmetrical padding)\n",
    "    \n",
    "`Stride`\n",
    "\n",
    "* Denoted by: $s$ a tuple of the form $(s_h, s_w)$\n",
    "    * $s_h$ is the number of strides along height\n",
    "    * $s_w$ is the number of strides along width\n",
    "    \n",
    "`Output`\n",
    "\n",
    "* Denoted by: $Z$\n",
    "* Shape: $(m, F, O_h, O_w)$\n",
    "    * $m$ is the batch size\n",
    "    * $F$ is the total number of filters used in Kernel\n",
    "    * $O_h$ is the height of the Output $Z$\n",
    "    * $O_w$ is the width of the Output $Z$\n",
    "    \n",
    "**Note**\n",
    "\n",
    "1. Instead of using $p$ (for padding), we can also use $p_h$ and $p_w$ which denotes the number of rows and columns of zeros added to the input $X$ respectively. We can further break $p_h$ and $p_w$ into $(p_t, p_b)$ and $(p_l, p_r)$ respectively where:\n",
    "    * $p_t$: number of rows of zeros padded on top of the input $X$\n",
    "    * $p_b$: number of rows of zeros padded on bottom of the input $X$\n",
    "    * $p_l$: number of columns of zeros padded on left of the input $X$\n",
    "    * $p_r$: number of columns of zeros padded on right of the input $X$\n",
    "<br><br>\n",
    "    \n",
    "2. Shape of Output is calculated using the following formula: <br><br>\n",
    "\n",
    "$$\n",
    "O_h = \\left \\lfloor \\frac{N_h - K_h + p_h}{s_h} \\right \\rfloor + 1\n",
    "$$ \n",
    "\n",
    "$$\n",
    "O_w = \\left \\lfloor \\frac{N_w - K_w + p_w}{s_w} \\right \\rfloor + 1\n",
    "$$\n",
    "    \n",
    "3. Same padding\n",
    "\n",
    "$$\n",
    "p_h = (s_h-1) \\cdot N_h + K_h - s_h\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_w = (s_w-1) \\cdot N_w + K_w - s_w\n",
    "$$\n",
    "    \n",
    "4. Valid padding\n",
    "\n",
    "$$\n",
    "p_h = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_w = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propagation\n",
    "\n",
    "Once we have defined the stride and the padding we can define the convolution product between a Input $X$ (Containing channels, height and width) and a filter $K$.\n",
    "\n",
    "$$\n",
    "Z_{x,y} = \\sum_{i=1}^{N_h} \\sum_{j=1}^{N_w} \\sum_{k=1}^{N_c} K_{k,i,j} X_{k, x+i-1, y+j-1}\n",
    "$$\n",
    "\n",
    "This we do across every batch and all the filters.\n",
    "\n",
    "Don't worry, in our [forward propagation code](https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/forward_propagation_convolution.html), which we will develop from scratch in a step by step manner, we will not be using any for loops and the code will be fully vectorized (written in just few lines using only numpy)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
