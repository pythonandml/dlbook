{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg0Fv6DtgORJ"
   },
   "source": [
    "# 2.12. Numerical example Forward and Back pass\n",
    "\n",
    "Here we present **Numerical example (with code) - Forward pass and Backpropagation (step by step vectorized form)**\n",
    "\n",
    "**Note:** \n",
    "\n",
    "*  The equations (in vectorized form) for forward propagation can be found [here](https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/forward_propagation.html) (link to previous chapter) \n",
    "\n",
    "*  The equations (in vectorized form) for back propagation can be found [here](https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/backpropagation.html) (link to previous chapter) \n",
    "\n",
    "Consider the network shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-ZQawhTIhuY"
   },
   "source": [
    "![](images/neural_nets_architecture_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3IWBqcmo10w"
   },
   "source": [
    "**Given values**\n",
    "\n",
    "Input $x = [1, 4, 5]$, $y = [0.1, 0.05]$\n",
    "\n",
    "$$\n",
    "W_1 = \\begin{bmatrix}\n",
    "0.1 & 0.2\\\\ \n",
    "0.3 & 0.4\\\\ \n",
    "0.5 & 0.6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_1 = \\begin{bmatrix}\n",
    "0.5\\\\ \n",
    "0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_2 = \\begin{bmatrix}\n",
    "0.7 & 0.8\\\\ \n",
    "0.9 & 0.1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_2 = \\begin{bmatrix}\n",
    "0.5\\\\ \n",
    "0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The [activation functions](https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/activation.html) $f_1(z)$ and $f_2(z)$ (link to previous chapter) used here is **sigmoid** (for both the layers) and the [cost function](https://pythonandml.github.io/dlbook/content/multilayer_perceptrons/cost_functions.html) $J(W, b)$ (link to previous chapter) is **MSE**.\n",
    "\n",
    "> **Note:** $\\odot$ means element wise multiplication (also called **Hadamard product**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7Knd6ZwLEAx"
   },
   "source": [
    "Let us write the code simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zfPnbfvLCtD",
    "outputId": "a74b3496-4812-4795-c4a9-4325a87b9ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward and Backpropagation - Numerical example\n",
      "\n",
      "x = [[1 4 5]]\n",
      "\n",
      "y = [[0.1  0.05]]\n",
      "\n",
      "W1 =\n",
      "\n",
      " [[0.1 0.2]\n",
      " [0.3 0.4]\n",
      " [0.5 0.6]]\n",
      "\n",
      "b1 =\n",
      "\n",
      " [[0.5]\n",
      " [0.5]]\n",
      "\n",
      "W2 =\n",
      "\n",
      " [[0.7 0.8]\n",
      " [0.9 0.1]]\n",
      "\n",
      "b2 =\n",
      "\n",
      " [[0.5]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    '''\n",
    "    Parameters\n",
    "    \n",
    "    x: input matrix of shape (m, d) \n",
    "    where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "    and 'd' is the number of features\n",
    "    '''\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    # sigmoid derivative\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "def d_mse(a, y):\n",
    "    '''\n",
    "    dJ/daL\n",
    "    '''\n",
    "    return a - y\n",
    "\n",
    "x = np.array([[1, 4, 5]])\n",
    "y = np.array([[0.1, 0.05]])\n",
    "\n",
    "W1 = np.array([[0.1, 0.2],\n",
    "               [0.3, 0.4],\n",
    "               [0.5, 0.6]])\n",
    "b1 = np.array([[0.5],\n",
    "               [0.5]])\n",
    "\n",
    "W2 = np.array([[0.7, 0.8],\n",
    "               [0.9, 0.1]])\n",
    "b2 = np.array([[0.5],\n",
    "               [0.5]])\n",
    "\n",
    "print(\"Forward and Backpropagation - Numerical example\")\n",
    "print(\"\\nx =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "print(\"\\nW1 =\\n\\n\", W1)\n",
    "print(\"\\nb1 =\\n\\n\", b1)\n",
    "print(\"\\nW2 =\\n\\n\", W2)\n",
    "print(\"\\nb2 =\\n\\n\", b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFDxWU36KfA_"
   },
   "source": [
    "**Fowrard Propagation**\n",
    "\n",
    "For input layer ($l=0$),\n",
    "\n",
    "$$z_0 = a_0 = x$$\n",
    "\n",
    "For hidden layer ($l=1$)\n",
    "\n",
    "$$\n",
    "z_1 = a_0 W_1 + b_1^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore z_1 = \\begin{bmatrix}\n",
    "1 & 4 & 5\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0.1 & 0.2\\\\ \n",
    "0.3 & 0.4\\\\ \n",
    "0.5 & 0.6\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "0.5 & 0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore z_1 = \\begin{bmatrix}\n",
    "3.8 & 4.8\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "0.5 & 0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore z_1 = \\begin{bmatrix}\n",
    "4.3 & 5.3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now, \n",
    "\n",
    "$$a_1 = f_1(z_1) = f_1(\\begin{bmatrix}\n",
    "4.3 & 5.3\n",
    "\\end{bmatrix})$$\n",
    "\n",
    "$$a_1 = \\begin{bmatrix}\n",
    "0.9866 & 0.9950\n",
    "\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlHG3WvnKygF"
   },
   "source": [
    "Let us code the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqpU88uXKxD5",
    "outputId": "f010c4df-4ebe-42ee-c62a-6b6bc4fe9846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 = [[4.3 5.3]]\n",
      "\n",
      "a1 = [[0.98661308 0.9950332 ]]\n"
     ]
    }
   ],
   "source": [
    "z0 = a0 = x.copy()\n",
    "z1 = a0 @ W1 + b1.T\n",
    "a1 = sigmoid(z1)\n",
    "print(\"z1 =\", z1)\n",
    "print(\"\\na1 =\", a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v74WwelRKlJ9"
   },
   "source": [
    "Now for the output layer ($l=2$),\n",
    "\n",
    "$$\n",
    "z_2 = a_1 W_2 + b_2^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore z_2 = \\begin{bmatrix}\n",
    "0.9866 & 0.9950\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0.7 & 0.8\\\\ \n",
    "0.9 & 0.1\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "0.5 & 0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore z_2 = \\begin{bmatrix}\n",
    "2.086 & 1.389\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now, \n",
    "\n",
    "$$a_2 = f_2(z_2) = f_2(\\begin{bmatrix}\n",
    "2.086 & 1.389\n",
    "\\end{bmatrix})$$\n",
    "\n",
    "$$a_2 = \\begin{bmatrix}\n",
    "0.8896 & 0.8004\n",
    "\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "judDzkwPLneW",
    "outputId": "f5f7ef06-1665-49e1-939b-8e946d198a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z2 = [[2.08615904 1.38879379]]\n",
      "\n",
      "a2 = [[0.88955061 0.80039961]]\n"
     ]
    }
   ],
   "source": [
    "z2 = a1 @ W2 + b2.T\n",
    "a2 = sigmoid(z2)\n",
    "print(\"z2 =\", z2)\n",
    "print(\"\\na2 =\", a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2S841V2LdaG"
   },
   "source": [
    "**Backpropagation**\n",
    "\n",
    "Output layer Backpropagation error ($\\delta_2$)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial a_2} = a_2 - y = \\begin{bmatrix}\n",
    "0.8896 & 0.8004\n",
    "\\end{bmatrix} - \\begin{bmatrix}\n",
    "0.1 & 0.05\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial a_2} = \\begin{bmatrix}\n",
    "0.7896 & 0.7504\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f'_2(z_2) = f'_2(\\begin{bmatrix}\n",
    "2.086 & 1.389\n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "0.0983 & 0.1598\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Therefore, \n",
    "\n",
    "$$\n",
    "\\delta_2 = \\frac{\\partial J(W, b)}{\\partial a_2} \\odot f'_2(z_2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_2 = \\begin{bmatrix}\n",
    "0.7896 & 0.7504\n",
    "\\end{bmatrix} \\odot \\begin{bmatrix}\n",
    "0.0983 & 0.1598\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_2 = \\begin{bmatrix}\n",
    "0.0776 & 0.1199\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YK2gFTB1MBEH",
    "outputId": "4da53d02-4da4-409b-9829-e063fcb93a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJda2 = [[0.78955061 0.75039961]]\n",
      "\n",
      "f2'(z2) = [[0.09825032 0.15976008]]\n",
      "\n",
      "d2 = [[0.0775736 0.1198839]]\n"
     ]
    }
   ],
   "source": [
    "dJda2 = d_mse(a2, y)\n",
    "da2dz2 = d_sigmoid(z2)\n",
    "d2 = dJda2 * da2dz2\n",
    "\n",
    "print(\"dJda2 =\",dJda2)\n",
    "print(\"\\nf2'(z2) =\",da2dz2)\n",
    "print(\"\\nd2 =\",d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI4objOGL9V1"
   },
   "source": [
    "Hidden layer Backpropagation error ($\\delta_1$)\n",
    "\n",
    "$$\n",
    "\\delta_1 = (\\delta_2 W_2^T) \\odot f'_1(z_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f'_1(z_1) = f'_1(\\begin{bmatrix}\n",
    "4.3 & 5.3\n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "0.0132 & 0.0049\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\delta_1 = \\begin{bmatrix}\n",
    "0.0776 & 0.1199\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0.7 & 0.9\\\\ \n",
    "0.8 & 0.1\n",
    "\\end{bmatrix} \\odot \\begin{bmatrix}\n",
    "0.0132 & 0.0049\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_1 = \\begin{bmatrix}\n",
    "0.002 & 0.0004\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6n5p6sYNM_S9",
    "outputId": "8a29ded3-ab6d-42c1-a501-3f597579371d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1'(z1) = [[0.01320771 0.00494213]]\n",
      "\n",
      "d1 = [[0.00198391 0.00040429]]\n"
     ]
    }
   ],
   "source": [
    "da1dz1 = d_sigmoid(z1)\n",
    "d1 = (d2 @ W2.T) * da1dz1\n",
    "\n",
    "print(\"f1'(z1) =\",da1dz1)\n",
    "print(\"\\nd1 =\",d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5ypgX-4M2aq"
   },
   "source": [
    "Rate of change of the cost with respect to weights $W_l$\n",
    "\n",
    "For $l=1$,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial W_1} = a_0^T \\delta_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial W_1} = \\begin{bmatrix}\n",
    "1\\\\ \n",
    "4\\\\ \n",
    "5\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0.002 & 0.0004\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial W_1} = \\begin{bmatrix}\n",
    "0.002 & 0.0004 \\\\ \n",
    "0.0079 & 0.0016\\\\ \n",
    "0.0099 & 0.002\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1b6vqqPNfFY",
    "outputId": "f602ede4-5815-4c8a-f8f0-f8bd45352c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLdW1 =\n",
      "\n",
      " [[0.002  0.0004]\n",
      " [0.0079 0.0016]\n",
      " [0.0099 0.002 ]]\n"
     ]
    }
   ],
   "source": [
    "dLdW1 = a0.T @ d1\n",
    "\n",
    "print('dLdW1 =\\n\\n', np.round(dLdW1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnUrHYftNVRe"
   },
   "source": [
    "For $l=2$,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial W_2} = a_1^T \\delta_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial W_2} = \\begin{bmatrix}\n",
    "0.0765 & 0.1183\\\\ \n",
    "0.0772 & 0.1193\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWBr3DEHOJVC",
    "outputId": "2e015848-2679-44c8-9c2f-e3e4aaf8a058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLdW2 =\n",
      "\n",
      " [[0.0765 0.1183]\n",
      " [0.0772 0.1193]]\n"
     ]
    }
   ],
   "source": [
    "dLdW2 = a1.T @ d2\n",
    "print('dLdW2 =\\n\\n', np.round(dLdW2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-ZQY8cQOFPQ"
   },
   "source": [
    "Rate of change of the cost with respect to bias $b_l$\n",
    "\n",
    "Finally, the partial derivative of the cost function $J(W, b)$ with respect to bias of that layer $b_l$ will be:\n",
    "\n",
    "For $l=1$,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial b_1} = \\sum \\delta_1 = \\begin{bmatrix}\n",
    "0.002\\\\ \n",
    "0.0004\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gh3kuDpzOXCH",
    "outputId": "2b62f941-f4ff-4cb2-f7a0-e9b3e7b4ee98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLdb1 =\n",
      "\n",
      " [[0.002 ]\n",
      " [0.0004]]\n"
     ]
    }
   ],
   "source": [
    "dLdb1 = np.sum(d1, axis=0).reshape(-1,1)\n",
    "print('dLdb1 =\\n\\n', np.round(dLdb1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK65ls0GOTe9"
   },
   "source": [
    "For $l=2$,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(W, b)}{\\partial b_2} = \\sum \\delta_2 = \\begin{bmatrix}\n",
    "0.0775\\\\ \n",
    "0.1199\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pww-M7iTOxVC",
    "outputId": "580d81e8-b129-4d4d-d111-1a51716dc001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLdb2 =\n",
      "\n",
      " [[0.0776]\n",
      " [0.1199]]\n"
     ]
    }
   ],
   "source": [
    "dLdb2 = np.sum(d2, axis=0).reshape(-1,1)\n",
    "print('dLdb2 =\\n\\n', np.round(dLdb2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehE7qP6_Oru-"
   },
   "source": [
    "**Update the parameters**\n",
    "\n",
    "> **Note:** Although this has not been introduced yet in our chapters, but just for the sake of completenss, we will show how to update the weights and biases using the partial derivatives obtained. So, if you are not aware of this step then you can skip it for now.\n",
    "\n",
    "Let the learning rate $\\eta = 0.01$.\n",
    "\n",
    "**Updating $W_1$**\n",
    "\n",
    "$$\n",
    "W_1 := W_1 - \\frac{\\eta}{m} \\frac{\\partial J(W, b)}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore W_1 = \\begin{bmatrix}\n",
    "0.1 & 0.2\\\\ \n",
    "0.3 & 0.4\\\\ \n",
    "0.5 & 0.6\n",
    "\\end{bmatrix} - 0.01 \\begin{bmatrix}\n",
    "0.002 & 0.0004 \\\\ \n",
    "0.0079 & 0.0016\\\\ \n",
    "0.0099 & 0.002\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore W_1 = \\begin{bmatrix}\n",
    "0.09998 & 0.1999\\\\ \n",
    "0.29992 & 0.39998\\\\ \n",
    "0.4999 & 0.59998\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Updating $W_2$**\n",
    "\n",
    "$$\n",
    "W_2 := W_2 - \\frac{\\eta}{m} \\frac{\\partial J(W, b)}{\\partial W_2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore W_2 = \\begin{bmatrix}\n",
    "0.7 & 0.8\\\\ \n",
    "0.9 & 0.1\n",
    "\\end{bmatrix} - 0.01 \\begin{bmatrix}\n",
    "0.0765 & 0.1183\\\\ \n",
    "0.0772 & 0.1193\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore W_2 = \\begin{bmatrix}\n",
    "0.6992 & 0.7988\\\\ \n",
    "0.89923 &  0.0988\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Updating $b_1$**\n",
    "\n",
    "$$\n",
    "b_1 := b_1 - \\frac{\\eta}{m} \\frac{\\partial J(W, b)}{\\partial b_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore b_1 = \\begin{bmatrix}\n",
    "0.5\\\\ \n",
    "0.5\n",
    "\\end{bmatrix} - 0.01 \\begin{bmatrix}\n",
    "0.002\\\\ \n",
    "0.0004\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore b_1 = \\begin{bmatrix}\n",
    "0.49998\\\\ \n",
    "0.499995\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Updating $b_2$**\n",
    "\n",
    "$$\n",
    "b_2 := b_2 - \\frac{\\eta}{m} \\frac{\\partial J(W, b)}{\\partial b_2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore b_2 = \\begin{bmatrix}\n",
    "0.5\\\\ \n",
    "0.5\n",
    "\\end{bmatrix} - 0.01 \\begin{bmatrix}\n",
    "0.0775\\\\ \n",
    "0.1199\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore b_2 = \\begin{bmatrix}\n",
    "0.49922\\\\ \n",
    "0.49880\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LhkQqRTPTOm"
   },
   "outputs": [],
   "source": [
    "n = 0.01\n",
    "m = y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXSAK_iSO4tL",
    "outputId": "6d593c62-0aae-4944-976b-75560b39d210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weight W1 =\n",
      "\n",
      " [[0.09998016 0.19999596]\n",
      " [0.29992064 0.39998383]\n",
      " [0.4999008  0.59997979]]\n"
     ]
    }
   ],
   "source": [
    "W1n = W1 - (n/m)*dLdW1\n",
    "print(\"Updated Weight W1 =\\n\\n\", W1n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vud3RHPAPSXp",
    "outputId": "12dfb7a1-9986-4791-c307-3ccd6d796296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weight W2 =\n",
      "\n",
      " [[0.69923465 0.79881721]\n",
      " [0.89922812 0.09880712]]\n"
     ]
    }
   ],
   "source": [
    "W2n = W2 - (n/m)*dLdW2\n",
    "print(\"Updated Weight W2 =\\n\\n\", W2n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRi2ld7fPXjv",
    "outputId": "ef6ad719-806b-4b66-f770-b2456518cfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated bias b1 =\n",
      "\n",
      " [[0.49998016]\n",
      " [0.49999596]]\n"
     ]
    }
   ],
   "source": [
    "b1n = b1 - (n/m)*dLdb1\n",
    "print(\"Updated bias b1 =\\n\\n\", b1n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boHn1BH4Pbxq",
    "outputId": "9a295c60-7dd9-4c64-81f4-61a0ffe27ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated bias b2 =\n",
      "\n",
      " [[0.49922426]\n",
      " [0.49880116]]\n"
     ]
    }
   ],
   "source": [
    "b2n = b2 - (n/m)*dLdb2\n",
    "print(\"Updated bias b2 =\\n\\n\", b2n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7XlFbYfjrYj"
   },
   "source": [
    "The solution (in non-vectorized format) for the given network can be found [here](https://www.anotsorandomwalk.com/backpropagation-example-with-numbers-step-by-step/) (link to an external website). On comparing we find our solution is in complete agreement with that solution! We can easily extend this vectorized format for multiple hidden layers as well as for a batch dataset. You can also repeat this update for many epochs. Complete code is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXByTwYyQQF8",
    "outputId": "8cc4f2ad-8575-4d1f-f523-99bd89b57839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward and Backpropagation - Numerical example\n",
      "\n",
      "x = [[1 4 5]]\n",
      "\n",
      "y = [[0.1  0.05]]\n",
      "\n",
      "W1 =\n",
      "\n",
      " [[0.1 0.2]\n",
      " [0.3 0.4]\n",
      " [0.5 0.6]]\n",
      "\n",
      "b1 =\n",
      "\n",
      " [[0.5]\n",
      " [0.5]]\n",
      "\n",
      "W2 =\n",
      "\n",
      " [[0.7 0.8]\n",
      " [0.9 0.1]]\n",
      "\n",
      "b2 =\n",
      "\n",
      " [[0.5]\n",
      " [0.5]]\n",
      "\n",
      "z1 = [[4.3 5.3]]\n",
      "\n",
      "a1 = [[0.98661308 0.9950332 ]]\n",
      "\n",
      "z2 = [[2.08615904 1.38879379]]\n",
      "\n",
      "a2 = [[0.88955061 0.80039961]]\n",
      "\n",
      "dJda2 = [[0.78955061 0.75039961]]\n",
      "\n",
      "f2'(z2) = [[0.09825032 0.15976008]]\n",
      "\n",
      "d2 = [[0.0775736 0.1198839]]\n",
      "\n",
      "f1'(z1) = [[0.01320771 0.00494213]]\n",
      "\n",
      "d1 = [[0.00198391 0.00040429]]\n",
      "\n",
      "dLdW1 =\n",
      "\n",
      " [[0.002  0.0004]\n",
      " [0.0079 0.0016]\n",
      " [0.0099 0.002 ]]\n",
      "\n",
      "dLdW2 =\n",
      "\n",
      " [[0.0765 0.1183]\n",
      " [0.0772 0.1193]]\n",
      "\n",
      "dLdb1 =\n",
      "\n",
      " [[0.002 ]\n",
      " [0.0004]]\n",
      "\n",
      "dLdb2 =\n",
      "\n",
      " [[0.0776]\n",
      " [0.1199]]\n",
      "\n",
      "Updated Weight W1 =\n",
      "\n",
      " [[0.09998016 0.19999596]\n",
      " [0.29992064 0.39998383]\n",
      " [0.4999008  0.59997979]]\n",
      "\n",
      "Updated Weight W2 =\n",
      "\n",
      " [[0.69923465 0.79881721]\n",
      " [0.89922812 0.09880712]]\n",
      "\n",
      "Updated bias b1 =\n",
      "\n",
      " [[0.49998016]\n",
      " [0.49999596]]\n",
      "\n",
      "Updated bias b2 =\n",
      "\n",
      " [[0.49922426]\n",
      " [0.49880116]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Utility functions for activation, cost and their derivatives\n",
    "\n",
    "def sigmoid(x):\n",
    "    '''\n",
    "    Parameters\n",
    "    \n",
    "    x: input matrix of shape (m, d) \n",
    "    where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "    and 'd' is the number of features\n",
    "    '''\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    # sigmoid derivative\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "def d_mse(a, y):\n",
    "    '''\n",
    "    dJ/daL\n",
    "    '''\n",
    "    return a - y\n",
    "\n",
    "# Given Parameters\n",
    "\n",
    "x = np.array([[1, 4, 5]])\n",
    "y = np.array([[0.1, 0.05]])\n",
    "\n",
    "W1 = np.array([[0.1, 0.2],\n",
    "               [0.3, 0.4],\n",
    "               [0.5, 0.6]])\n",
    "b1 = np.array([[0.5],\n",
    "               [0.5]])\n",
    "\n",
    "W2 = np.array([[0.7, 0.8],\n",
    "               [0.9, 0.1]])\n",
    "b2 = np.array([[0.5],\n",
    "               [0.5]])\n",
    "\n",
    "# Forward Propagation\n",
    "\n",
    "z0 = a0 = x.copy()\n",
    "z1 = a0 @ W1 + b1.T\n",
    "a1 = sigmoid(z1)\n",
    "\n",
    "z2 = a1 @ W2 + b2.T\n",
    "a2 = sigmoid(z2)\n",
    "\n",
    "# Backward Propagation\n",
    "\n",
    "# 1. Output error\n",
    "\n",
    "dJda2 = d_mse(a2, y)\n",
    "da2dz2 = d_sigmoid(z2)\n",
    "d2 = dJda2 * da2dz2\n",
    "\n",
    "# 2. Hidden layer error\n",
    "\n",
    "da1dz1 = d_sigmoid(z1)\n",
    "d1 = (d2 @ W2.T) * da1dz1\n",
    "\n",
    "# 3. dJ/dW\n",
    "\n",
    "dLdW1 = a0.T @ d1\n",
    "dLdW2 = a1.T @ d2\n",
    "\n",
    "# 4. dJ/db\n",
    "\n",
    "dLdb1 = np.sum(d1, axis=0).reshape(-1,1)\n",
    "dLdb2 = np.sum(d2, axis=0).reshape(-1,1)\n",
    "\n",
    "# Update parameters\n",
    "\n",
    "n = 0.01 # Learning rate\n",
    "m = y.shape[0]\n",
    "\n",
    "W1n = W1 - (n/m)*dLdW1\n",
    "W2n = W2 - (n/m)*dLdW2\n",
    "b1n = b1 - (n/m)*dLdb1\n",
    "b2n = b2 - (n/m)*dLdb2\n",
    "\n",
    "# Prints\n",
    "\n",
    "print(\"Forward and Backpropagation - Numerical example\")\n",
    "print(\"\\nx =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "print(\"\\nW1 =\\n\\n\", W1)\n",
    "print(\"\\nb1 =\\n\\n\", b1)\n",
    "print(\"\\nW2 =\\n\\n\", W2)\n",
    "print(\"\\nb2 =\\n\\n\", b2)\n",
    "print(\"\\nz1 =\", z1)\n",
    "print(\"\\na1 =\", a1)\n",
    "print(\"\\nz2 =\", z2)\n",
    "print(\"\\na2 =\", a2)\n",
    "print(\"\\ndJda2 =\",dJda2)\n",
    "print(\"\\nf2'(z2) =\",da2dz2)\n",
    "print(\"\\nd2 =\",d2)\n",
    "print(\"\\nf1'(z1) =\",da1dz1)\n",
    "print(\"\\nd1 =\",d1)\n",
    "print('\\ndLdW1 =\\n\\n', np.round(dLdW1, 4))\n",
    "print('\\ndLdW2 =\\n\\n', np.round(dLdW2, 4))\n",
    "print('\\ndLdb1 =\\n\\n', np.round(dLdb1, 4))\n",
    "print('\\ndLdb2 =\\n\\n', np.round(dLdb2, 4))\n",
    "print(\"\\nUpdated Weight W1 =\\n\\n\", W1n)\n",
    "print(\"\\nUpdated Weight W2 =\\n\\n\", W2n)\n",
    "print(\"\\nUpdated bias b1 =\\n\\n\", b1n)\n",
    "print(\"\\nUpdated bias b2 =\\n\\n\", b2n)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
